{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "320.46px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "neuron_wj2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpKSotM9DJxo",
        "colab_type": "text"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0I7jDO7DJxs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "3a5df35b-948d-4126-a612-fd7d06b119e4"
      },
      "source": [
        "#20200322使用CoLab\n",
        "#LOCATE = 'home'\n",
        "LOCATE='T490'\n",
        "#IDE = 'JUPYTER'\n",
        "IDE='colab'\n",
        "# IDE = 'VS'\n",
        "\n",
        "import time\n",
        "\n",
        "def monotonic():\n",
        "    if LOCATE=='home':\n",
        "        return time.monotonic_ns()\n",
        "    else:\n",
        "        return time.monotonic()\n",
        "# if IDE == 'JUPYTER':\n",
        "    #代码自动完成\n",
        "    # %config IPCompleter.greedy=True \n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "from matplotlib.pyplot import imshow\n",
        "if IDE == 'JUPYTER' or IDE=='colab':\n",
        "    %matplotlib inline\n",
        "#CIFAR_DIR = \"./../../cifar-10-batches-py\"\n",
        "if LOCATE=='home':\n",
        "  CIFAR_DIR = 'V:\\DATA\\cifar-10-batches-py'\n",
        "else:\n",
        "  CIFAR_DIR = 'd:\\Alan\\data\\cifar-10-batches-py'\n",
        "if IDE=='colab':  \n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  path = \"/content/drive/My Drive\"\n",
        "  os.chdir(path)\n",
        "  # print(os.listdir(path))\n",
        "  CIFAR_DIR=path+'/Alan/Data/cifar-10-batches-py'\n",
        "\n",
        "print(os.listdir(CIFAR_DIR))\n",
        "\n",
        "def time_str(t):\n",
        "    return time.strftime(\"%Y%m%d-%H:%M:%S\", t)\n",
        "\n",
        "def time_now(begin_time=0):    \n",
        "    t=time.localtime()\n",
        "    if begin_time==0:\n",
        "        return time_str(t)\n",
        "    else:\n",
        "        end_time=monotonic()\n",
        "        elaps = end_time - begin_time\n",
        "#         elaps_sec = elaps/10**9 if LOCATE=='home' else elaps\n",
        "        return '%s. Time used: %.3f s.'%(time_str(t), elaps/((10**9) if LOCATE=='home' else 1))\n",
        "\n",
        "def get_timestamp():\n",
        "    return monotonic()\n",
        "    \n",
        "print(time_now())\n",
        "t0=get_timestamp()\n",
        "for i in range(1234567):\n",
        "    i=i\n",
        "print(time_now(t0))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n",
            "['batches.meta', 'readme.html', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'test_batch']\n",
            "20200323-01:51:52\n",
            "20200323-01:51:52. Time used: 0.074 s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPHm9-t7Dzre",
        "colab_type": "text"
      },
      "source": [
        "#使用免费的GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6JccGBZD0Hm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0e8b2722-ce22-4961-8886-969308e0a00a"
      },
      "source": [
        "#使用免费的 GPU\n",
        "#在打开的 Jupyter Notebook 中，选择菜单栏“代码执行程序（Runtime）”，“更改运行类型（Change runtime type）”，这时将看到以下弹出窗口：\n",
        "# 确保“硬件加速器（Hardware accelerator）”设置为 GPU（默认为 CPU）。设置完毕后点击保存。\n",
        "#但是，由于在线 GPU 资源有限，有时候可能会出现分配失败的提示。并且，谷歌允许你一次最多持续使用 12 小时的免费 GPU。\n",
        "#检查是否真的开启了 GPU（即当前连接到了GPU实例），可以直接在 Jupyter Notebook 中运行以下命令：\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        " raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAuiAA2pDJyA",
        "colab_type": "text"
      },
      "source": [
        "# display var"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST8OskorDJyC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        },
        "outputId": "cd19fdda-a625-4a87-eb83-7a19d3aaf18f"
      },
      "source": [
        "import inspect\n",
        "import copy\n",
        "def retrieve_name_ex(var,level=0):    \n",
        "    stacks = inspect.stack()    \n",
        "    try:        \n",
        "        callFunc = stacks[level].function        \n",
        "        code = stacks[level+1].code_context[0]        \n",
        "        startIndex = code.index(callFunc)        \n",
        "        startIndex = code.index(\"(\", startIndex + len(callFunc)) + 1        \n",
        "        endIndex = code.index(\")\", startIndex)        \n",
        "        return code[startIndex:endIndex].strip()    \n",
        "    except:        \n",
        "        return \"\"\n",
        "\n",
        "def outputVar(var,level=1,index=-1,end_str='\\n'):               \n",
        "#     print(\"{} [0x{}] = {}\".format(retrieve_name_ex(var,1),var))   \n",
        "    if index==-1:\n",
        "        var_name=retrieve_name_ex(var,level)        \n",
        "    else:\n",
        "        var_name='%s[%d]'%(retrieve_name_ex(var,level),index)\n",
        "    val='{}.'.format(var)\n",
        "    print('%-10s[0x%012lx]=%-15s'%(var_name,id(var),val),end=end_str)\n",
        "    \n",
        "def output_var(var,level=1,index=-1,end_str='\\n'):               \n",
        "    if index==-1:\n",
        "        var_name=retrieve_name_ex(var,level)        \n",
        "    else:\n",
        "        var_name='%s[%d]'%(retrieve_name_ex(var,level),index)\n",
        "    val='{}.'.format(var)\n",
        "    print('%s = %s'%(var_name,val),end=end_str)\n",
        "\n",
        "def getVarName(var,level=1,index=-1):\n",
        "    if index==-1:\n",
        "        var_name=retrieve_name_ex(var,level)        \n",
        "    else:\n",
        "        var_name='%s[%d]'%(retrieve_name_ex(var,level),index)\n",
        "    return var_name\n",
        "\n",
        "def print_var(var,level=1,index=-1):\n",
        "    print(getVarName(var,2),'=',var)\n",
        "    \n",
        "a=[1,2,3]\n",
        "print_var(a)\n",
        "    \n",
        "def output_child(arr):\n",
        "    s=retrieve_name_ex(arr,1)\n",
        "    for i in range(len(arr)):\n",
        "        outputVar(arr[i],2,i,'')\n",
        "    print('\\n',end='')\n",
        "a=[[1,2],[2],[3]]\n",
        "b_sgn=a          # 赋值(相当于C++中的引用)\n",
        "b_spl=a[:]       # 浅拷贝\n",
        "b_dp=copy.deepcopy(a) # 深拷贝\n",
        "outputVar(a)\n",
        "outputVar(b_sgn)\n",
        "outputVar(b_spl)\n",
        "outputVar(b_dp)\n",
        "output_child(a)\n",
        "output_child(b_sgn)\n",
        "output_child(b_spl)\n",
        "output_child(b_dp)\n",
        "a[0].append(3)\n",
        "print('--- After a[0].append(3). ---')\n",
        "outputVar(a)\n",
        "outputVar(b_sgn)\n",
        "outputVar(b_spl)\n",
        "outputVar(b_dp)\n",
        "output_child(a)\n",
        "output_child(b_sgn)\n",
        "output_child(b_spl)\n",
        "output_child(b_dp)\n",
        "\n",
        "a[0]=1\n",
        "print('--- After a[0]=1. ---')\n",
        "outputVar(a)\n",
        "outputVar(b_sgn)\n",
        "outputVar(b_spl)\n",
        "outputVar(b_dp)\n",
        "output_child(a)\n",
        "output_child(b_sgn)\n",
        "output_child(b_spl)\n",
        "output_child(b_dp)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a = [1, 2, 3]\n",
            "a         [0x7fbc08c030c8]=[[1, 2], [2], [3]].\n",
            "b_sgn     [0x7fbc08c030c8]=[[1, 2], [2], [3]].\n",
            "b_spl     [0x7fbc08c03108]=[[1, 2], [2], [3]].\n",
            "b_dp      [0x7fbc0c05b408]=[[1, 2], [2], [3]].\n",
            "a[0]      [0x7fbc08beee88]=[1, 2].        a[1]      [0x7fbc9d9e6348]=[2].           a[2]      [0x7fbc08beef08]=[3].           \n",
            "b_sgn[0]  [0x7fbc08beee88]=[1, 2].        b_sgn[1]  [0x7fbc9d9e6348]=[2].           b_sgn[2]  [0x7fbc08beef08]=[3].           \n",
            "b_spl[0]  [0x7fbc08beee88]=[1, 2].        b_spl[1]  [0x7fbc9d9e6348]=[2].           b_spl[2]  [0x7fbc08beef08]=[3].           \n",
            "b_dp[0]   [0x7fbc08beef88]=[1, 2].        b_dp[1]   [0x7fbc08c031c8]=[2].           b_dp[2]   [0x7fbc08c03188]=[3].           \n",
            "--- After a[0].append(3). ---\n",
            "a         [0x7fbc08c030c8]=[[1, 2, 3], [2], [3]].\n",
            "b_sgn     [0x7fbc08c030c8]=[[1, 2, 3], [2], [3]].\n",
            "b_spl     [0x7fbc08c03108]=[[1, 2, 3], [2], [3]].\n",
            "b_dp      [0x7fbc0c05b408]=[[1, 2], [2], [3]].\n",
            "a[0]      [0x7fbc08beee88]=[1, 2, 3].     a[1]      [0x7fbc9d9e6348]=[2].           a[2]      [0x7fbc08beef08]=[3].           \n",
            "b_sgn[0]  [0x7fbc08beee88]=[1, 2, 3].     b_sgn[1]  [0x7fbc9d9e6348]=[2].           b_sgn[2]  [0x7fbc08beef08]=[3].           \n",
            "b_spl[0]  [0x7fbc08beee88]=[1, 2, 3].     b_spl[1]  [0x7fbc9d9e6348]=[2].           b_spl[2]  [0x7fbc08beef08]=[3].           \n",
            "b_dp[0]   [0x7fbc08beef88]=[1, 2].        b_dp[1]   [0x7fbc08c031c8]=[2].           b_dp[2]   [0x7fbc08c03188]=[3].           \n",
            "--- After a[0]=1. ---\n",
            "a         [0x7fbc08c030c8]=[1, [2], [3]]. \n",
            "b_sgn     [0x7fbc08c030c8]=[1, [2], [3]]. \n",
            "b_spl     [0x7fbc08c03108]=[[1, 2, 3], [2], [3]].\n",
            "b_dp      [0x7fbc0c05b408]=[[1, 2], [2], [3]].\n",
            "a[0]      [0x000000a68ac0]=1.             a[1]      [0x7fbc9d9e6348]=[2].           a[2]      [0x7fbc08beef08]=[3].           \n",
            "b_sgn[0]  [0x000000a68ac0]=1.             b_sgn[1]  [0x7fbc9d9e6348]=[2].           b_sgn[2]  [0x7fbc08beef08]=[3].           \n",
            "b_spl[0]  [0x7fbc08beee88]=[1, 2, 3].     b_spl[1]  [0x7fbc9d9e6348]=[2].           b_spl[2]  [0x7fbc08beef08]=[3].           \n",
            "b_dp[0]   [0x7fbc08beef88]=[1, 2].        b_dp[1]   [0x7fbc08c031c8]=[2].           b_dp[2]   [0x7fbc08c03188]=[3].           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u9a80QjDJyH",
        "colab_type": "text"
      },
      "source": [
        "$ P(A \\mid B) = \\frac{P(B \\mid A) , P(A)}{P(B)} $\n",
        "\n",
        "$ \\frac 1 2 $\n",
        "$\\vec{x}\\stackrel{\\mathrm{def}}{=} (x_1, ..., x_n)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4cohITNDJyL",
        "colab_type": "text"
      },
      "source": [
        "## tag_print"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7CMTt9oDJyN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "4fd3ffa2-4bf2-4a76-9658-fb56c8f235dc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def remove_sufix(s, redundance_flag):\n",
        "    '''去除字符串尾部多余的部分'''\n",
        "    index = s.find(redundance_flag)\n",
        "    if index >= 0:\n",
        "        return s[0:index-1]\n",
        "    else:\n",
        "        return s\n",
        "    \n",
        "def add_match_parentheses(s):\n",
        "    left_pt_cnt=0\n",
        "    right_pt_cnt=0\n",
        "    for c in s:\n",
        "        if c=='(':\n",
        "            left_pt_cnt += 1\n",
        "        elif c==')':\n",
        "            right_pt_cnt += 1\n",
        "    if left_pt_cnt - right_pt_cnt <=0:\n",
        "        return s\n",
        "    for i in range(left_pt_cnt - right_pt_cnt):\n",
        "        s += ')'\n",
        "    return s\n",
        "\n",
        "g_print_flag = False\n",
        "\n",
        "def tag_print(var, memo='', tag='', level_plus=0, display=True, big_list=False):\n",
        "    if display == False:\n",
        "        return\n",
        "    if tag == '':\n",
        "        tag = getVarName(var,level=2+level_plus)\n",
        "        if g_print_flag:\n",
        "            print('getVarName=',tag)\n",
        "        tag = remove_sufix(tag,getVarName(var))\n",
        "        tag = remove_sufix(tag,getVarName(memo))\n",
        "        tag = remove_sufix(tag,getVarName(display))\n",
        "        tag = remove_sufix(tag,getVarName(big_list))\n",
        "        tag = add_match_parentheses(tag)\n",
        "    enter_str_after_var = ''  \n",
        "    shape_str = '{shape}\\t'.format(shape= '-' )\n",
        "    if type(var) == np.ndarray or type(var) == np.matrix:\n",
        "        shape_str = '{shape}\\t'.format(shape=var.shape)        \n",
        "        if(len(var.shape) > 1 and var.shape[0] > 1):\n",
        "            enter_str_after_var = '\\n'  \n",
        "    if memo != '':\n",
        "        memo = '\\n' + memo\n",
        "    type_str = '{type}\\t'.format(type=type(var))\n",
        "      \n",
        "    print('{memo}\\n{type_str}{shape_str}{tag} = {enter}{mat}'.\n",
        "          format(memo=memo,type_str=type_str,shape_str=shape_str,tag=tag,mat=var,type=type(var),enter=enter_str_after_var))\n",
        "    \n",
        "def tp(var, memo='', tag='', level_plus=0, display=True, big_list=False):\n",
        "    tag_print(var=var, memo=memo, tag=tag, level_plus=1, display=display, big_list=big_list)\n",
        "    \n",
        "def tags_print(**vars):\n",
        "    for first_part,second_part in vars.items():\n",
        "        tag_print(tag=first_part,var=second_part)\n",
        "        \n",
        "def tps(**vars):\n",
        "    for first_part,second_part in vars.items():\n",
        "        tag_print(tag=first_part,var=second_part)\n",
        "    \n",
        "z0=0.5\n",
        "tp(z0)\n",
        "tp(np.mat(z0))\n",
        "a=np.array([[1,2,3],[4,5,6]])\n",
        "tp(a)\n",
        "tp(a*a)\n",
        "\n",
        "tp(a.dot(a.T))\n",
        "tp(a.T.dot(a))\n",
        "\n",
        "c=[[1,2],[3,4]]\n",
        "tp(c)\n",
        "mc=np.mat(c)\n",
        "tp(mc)\n",
        "tp(mc**2)\n",
        "b=list(range(10))\n",
        "ma=np.mat(a)\n",
        "tp(np.mat(a))\n",
        "mb=np.mat(b)\n",
        "# c=ma*ma.T\n",
        "tp(ma*ma.T)\n",
        "tp(ma.T*ma)\n",
        "tp(np.array(ma))\n",
        "tags_print(b=b,a=a)\n",
        "\n",
        "# def total(a=5,  **phonebook):\n",
        "# #     print('a', a)\n",
        "#     #遍历元组中的所有项目\n",
        "# #     for single_item in numbers:\n",
        "# #         print('single_item', single_item)\n",
        "#     #遍历字典中的所有项目\n",
        "#     for first_part, second_part in phonebook.items():\n",
        "#         print(first_part,second_part)\n",
        "# print(total(10,Jack=1123,John=2231,Inge=1560))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'float'>\t-\tz0 = 0.5\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tnp.mat(z0) = [[0.5]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\ta = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\ta*a = \n",
            "[[ 1  4  9]\n",
            " [16 25 36]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 2)\ta.dot(a.T) = \n",
            "[[14 32]\n",
            " [32 77]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(3, 3)\ta.T.dot(a) = \n",
            "[[17 22 27]\n",
            " [22 29 36]\n",
            " [27 36 45]]\n",
            "\n",
            "<class 'list'>\t-\tc = [[1, 2], [3, 4]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tmc = \n",
            "[[1 2]\n",
            " [3 4]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tmc**2 = \n",
            "[[ 7 10]\n",
            " [15 22]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 3)\tnp.mat(a) = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tma*ma.T = \n",
            "[[14 32]\n",
            " [32 77]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 3)\tma.T*ma = \n",
            "[[17 22 27]\n",
            " [22 29 36]\n",
            " [27 36 45]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\tnp.array(ma) = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "<class 'list'>\t-\tb = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\ta = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvbmHbQWDJyY",
        "colab_type": "text"
      },
      "source": [
        "# class CifarData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux8dBekCDJyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(filename):\n",
        "    \"\"\"read data from data file.\"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = pickle.load(f, encoding='bytes')\n",
        "        return data[b'data'], data[b'labels']\n",
        "\n",
        "# tensorflow.Dataset.\n",
        "class CifarData:\n",
        "    def __init__(self, filenames, need_shuffle):\n",
        "        all_data = []\n",
        "        all_labels = []\n",
        "        for filename in filenames:\n",
        "            data, labels = load_data(filename)\n",
        "            for item, label in zip(data, labels):\n",
        "                if label in [0, 1]:\n",
        "                    all_data.append(item)\n",
        "                    all_labels.append(label)\n",
        "        self._data = np.vstack(all_data)\n",
        "        self.orignal_data = self._data\n",
        "        self._data = self._data / 127.5 - 1\n",
        "        self._labels = np.hstack(all_labels)\n",
        "#         print(\"data.shape:  \",self._data.shape)\n",
        "#         print(\"labels.shape:\",self._labels.shape)\n",
        "        \n",
        "        self._num_examples = self._data.shape[0]\n",
        "        self._need_shuffle = need_shuffle\n",
        "        self._indicator = 0\n",
        "        if self._need_shuffle:\n",
        "            self._shuffle_data()            \n",
        "        self.len=self._num_examples\n",
        "            \n",
        "    def _shuffle_data(self):\n",
        "        # [0,1,2,3,4,5] -> [5,3,2,4,0,1]\n",
        "        p = np.random.permutation(self._num_examples)\n",
        "        self._data = self._data[p]\n",
        "        self._labels = self._labels[p]\n",
        "    \n",
        "    def next_batch(self, batch_size):\n",
        "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
        "        end_indicator = self._indicator + batch_size\n",
        "        if end_indicator > self._num_examples:\n",
        "            if self._need_shuffle:\n",
        "                self._shuffle_data()\n",
        "                self._indicator = 0\n",
        "                end_indicator = batch_size\n",
        "            else:\n",
        "                raise Exception(\"have no more examples\")\n",
        "        if end_indicator > self._num_examples:\n",
        "            raise Exception(\"batch size is larger than all examples\")\n",
        "        batch_data = self._data[self._indicator: end_indicator]\n",
        "        batch_labels = self._labels[self._indicator: end_indicator]\n",
        "        self._indicator = end_indicator\n",
        "        return batch_data, batch_labels    \n",
        "    \n",
        "    def show_img(self,index):\n",
        "        if index>=self.len:\n",
        "            print('索引越界')\n",
        "            return\n",
        "        img=self.orignal_data[index]\n",
        "        img2=img.reshape((3,32,32))\n",
        "        img3=img2.transpose((1,2,0))\n",
        "#         imshow(img3)\n",
        "#         _img_=img.reshape((3,32,32))\n",
        "        plt.imshow(img3)\n",
        "        plt.show()\n",
        "        return    \n",
        "    \n",
        "import os\n",
        "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
        "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
        "\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "class_names=[\"airplane\",\"auto\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"];\n",
        "\n",
        "def TEST_class_CifarData_and_show_img():\n",
        "    for i in range(1):\n",
        "        print('\\nNo. %d: label[%d] %s' % (i, test_data._labels[i], class_names[test_data._labels[i]]))\n",
        "        test_data.show_img(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIbVvKyiDJyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# print(w)\n",
        "s=np.array([2,3,1])\n",
        "w=dict()\n",
        "for i in range(0,len(s)-1):\n",
        "    a=s[i+1]\n",
        "    b=s[i]\n",
        "    w[i]=np.random.rand(a,b)\n",
        "# print(w)\n",
        "z=dict()\n",
        "z[1]=np.random.rand(2,3)\n",
        "i=1\n",
        "# print('z[{i}]=\\n{zi}'.format(i=i,zi=z[i]))\n",
        "# print('a={a}'.format(a=3))\n",
        "a=np.random.rand(1,3)\n",
        "b=np.random.rand(3,2)\n",
        "c=a.dot(b)\n",
        "tag_print(c)\n",
        "a=list(range(5,0,-1))\n",
        "output_var(a)\n",
        "a[1]=np.zeros(2)\n",
        "output_var(a)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39xTY2WtDJyr",
        "colab_type": "text"
      },
      "source": [
        "# BP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8PdRVSwDJyt",
        "colab_type": "text"
      },
      "source": [
        "## sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lw_LRFwDJyx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sigmoid(x):\n",
        "    y=1/(1+np.exp(-x))\n",
        "    return y\n",
        "\n",
        "def sigmoid_diff(x):\n",
        "    f=sigmoid(x)\n",
        "    diff=f-f*f\n",
        "    return diff\n",
        "\n",
        "x=np.array([[1,2,3]])\n",
        "print(x.shape)\n",
        "print(sigmoid(x))\n",
        "print(sigmoid_diff(x))\n",
        "print(np.transpose(x).shape)\n",
        "print(np.transpose(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72lQGT2fDJy9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "d=dict()\n",
        "d[1]=1\n",
        "not(1 in d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C7gLv1vDJzD",
        "colab_type": "text"
      },
      "source": [
        "## show_fun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGNiiR3nDJzE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DATA_DICT='data_dict'\n",
        "FIG_LABEL='label'\n",
        "X_LABEL='x'\n",
        "Y_LABEL='y'\n",
        "COLOR='color'\n",
        "\n",
        "    \n",
        "def show_dicts(dicts, figsize = (12,9), in_one_figure = True):\n",
        "    if in_one_figure:\n",
        "        plt.figure(figsize=figsize)\n",
        "    index = 0\n",
        "    plots=[]\n",
        "    plot_tags=[]\n",
        "    for d in dicts:       \n",
        "        if type(d)!=dict or not(DATA_DICT in d) or type(d[DATA_DICT])!=dict or len(d[DATA_DICT].items())==0:\n",
        "            continue\n",
        "        plt.plot(d[DATA_DICT].keys(), d[DATA_DICT].values(),color=d[COLOR],label=d[Y_LABEL])  \n",
        "        \n",
        "        if not in_one_figure:\n",
        "            if X_LABEL in d:\n",
        "                plt.xlabel(d[X_LABEL])\n",
        "            if Y_LABEL in d:\n",
        "                plt.ylabel(d[Y_LABEL])\n",
        "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=0,ncol=3, borderaxespad=0.)\n",
        "\n",
        "def show_dict(d,figsize=(12,9),color='blue',y_label='Y'):\n",
        "    tmp_d=dict()\n",
        "    tmp_d[DATA_DICT]=d\n",
        "    tmp_d[COLOR]=color\n",
        "    tmp_d[Y_LABEL]=y_label\n",
        "    dicts=[0]\n",
        "    dicts[0]=tmp_d\n",
        "    show_dicts(dicts,figsize=figsize)\n",
        "    \n",
        "def draw_axis(x_from,x_to,y_from,y_to):\n",
        "    color='black'\n",
        "    linewidth=0.5    \n",
        "    plt.vlines(0,y_to,y_from,color = color, linewidth = linewidth)\n",
        "    plt.hlines(0,x_from,x_to,color = color, linewidth = linewidth)\n",
        "\n",
        "def init_func_dicts(n):\n",
        "    y=list(range(n))\n",
        "    for i in range(n):\n",
        "        y[i]=dict()\n",
        "        y[i][DATA_DICT]=dict()\n",
        "    return y\n",
        "\n",
        "def TEST_show_fun():\n",
        "    y = init_func_dicts(5)\n",
        "    for x in np.linspace(-0.5,0.999,100):\n",
        "        y[0][DATA_DICT][x] = -np.log(1 - x)\n",
        "    y[0][COLOR] = 'red'\n",
        "    y[0][Y_LABEL] = 'y=-np.log(1-x)'\n",
        "    for x in np.linspace(0.001,1.5,100):\n",
        "        y[1][DATA_DICT][x] = -np.log(x)\n",
        "    y[1][COLOR] = 'blue'\n",
        "    y[1][Y_LABEL] = 'y=-np.log(x)'\n",
        "\n",
        "    show_dicts(y,figsize=(7,4))\n",
        "    aux_color = 'black'\n",
        "    aux_linewidth = 0.5\n",
        "    aux_linestyle = '-.'\n",
        "    draw_axis(-0.5,1.5,-1,7)\n",
        "    plt.vlines(1,-0.5,7,color = aux_color, linewidth = aux_linewidth, linestyle=aux_linestyle)\n",
        "    plt.annotate(\"x=1\",(1,-0.5),xytext=(0.95,-1))\n",
        "    plt.show()\n",
        "\n",
        "    y = init_func_dicts(5)\n",
        "    x_from = -7\n",
        "    x_to = 7\n",
        "    for x in np.linspace(x_from,x_to,1000):\n",
        "        y[0][DATA_DICT][x] = 1 / (1 + np.exp(-x))\n",
        "    y[0][COLOR] = 'green'\n",
        "    y[0][Y_LABEL] = 'sigmoid(x)=1/(1+exp(-x))'\n",
        "    show_dicts([y[0]],figsize=(7,4),in_one_figure=True)\n",
        "    draw_axis(x_from,x_to,-0.5,1.5)\n",
        "    plt.hlines(1,x_from,x_to,color = aux_color, linewidth = aux_linewidth, linestyle=aux_linestyle)\n",
        "    plt.annotate(\"y=1\",(-5,1) ,xytext=(-6.5,0.9))\n",
        "    plt.show()\n",
        "\n",
        "if IDE == 'JUPYTER':\n",
        "    TEST_show_fun()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb-4szmhDJzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=np.array([1,2,3])\n",
        "tp(a*a)\n",
        "b=np.array([[1,2,3],[3,4,5]])\n",
        "# ma_1=np.mat([1,2,3])\n",
        "# tp(ma_1)\n",
        "# tp(ma_1[0,2])\n",
        "# ma=np.mat(a).T\n",
        "# mb=np.mat(b[1]).T\n",
        "# tp(ma)\n",
        "# tp(mb)\n",
        "# tp(ma/mb)\n",
        "\n",
        "# ya = np.mat(b[:,2])\n",
        "# tp(np.mat(b))\n",
        "\n",
        "tp(b)\n",
        "tp(np.mat(b[:,1]))\n",
        "mb=np.mat(b)\n",
        "tp(mb)\n",
        "tp(np.mat(mb[:,1]))\n",
        "# df_dev_dx = np.zeros([2,3])\n",
        "# tp(df_dev_dx)\n",
        "# tp(ma**2)#矩阵乘幂\n",
        "# tp(a)\n",
        "# tp(a*a)\n",
        "# tp(a.T*a)\n",
        "# tp(ma)\n",
        "# tp(np.array(ma))\n",
        "# tp(np.array(ma.tolist()))\n",
        "# c=np.array(ma.tolist())\n",
        "# tp(c)\n",
        "# tp(c*c)\n",
        "# tp(c.T*c)\n",
        "# tp(c*c.T)\n",
        "# tp(c.T.dot(c))\n",
        "# tp(c.dot(c.T))\n",
        "\n",
        "# tp(mb)\n",
        "# tp(np.diag(ma*mb.T))\n",
        "# tp(np.array(ma))\n",
        "# tp(np.array(mb).T)\n",
        "# tp((np.array(ma)*np.array(mb).T))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYVoC7odDJzN",
        "colab_type": "text"
      },
      "source": [
        "## 函数求导"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWKNmb7rDJzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# 计算损失函数求导\n",
        "# from sympy import *\n",
        "import sympy as sy\n",
        "\n",
        "def sigmoid_sy(x):\n",
        "    y = 1 / (1 + sy.exp(-x))\n",
        "    return y\n",
        "\n",
        "def sigmoid_diff(x):\n",
        "    f = sigmoid(x)\n",
        "    diff = f - f * f\n",
        "    return diff\n",
        "\n",
        "# def covert_sigle_to_array(x):\n",
        "#     '''将单个数转换成矩阵形式'''\n",
        "#     x = np.array(x)\n",
        "#     if len(x.shape)==0:\n",
        "#         x=np.array([x])\n",
        "#     return x\n",
        "\n",
        "x = sy.symbols(\"x\")  # 符号x，自变量\n",
        "y = x ** 2 + 3 * x\n",
        "dify = sy.diff(y,x) #求导\n",
        "# print(dify) #打印导数#给定x值，求对应导数的值\n",
        "                # print(dify.subs('x',1))\n",
        "z = sy.symbols('z')\n",
        "y = sy.symbols('y')\n",
        "L = sy.symbols('L')\n",
        "\n",
        "L = -y * sy.log(sigmoid_sy(z)) - (1 - y) * (sy.log(1 - sigmoid_sy(z)))\n",
        "dL_python = sy.diff(L,z)\n",
        "\n",
        "tp(L)\n",
        "tp(sy.diff(L,z))\n",
        "\n",
        "# dL_alan=-y*(1-sigmoid(z))+(1-y)*sigmoid(z)\n",
        "\n",
        "z0=0.7\n",
        "y0=1\n",
        "\n",
        "z1 = np.mat([0.7,0.2,0.5]).T\n",
        "y1 = np.mat([1,0,1]).T\n",
        "\n",
        "z2 = np.mat([[0.7,0.2,0.5],[0.6,0.3,0.8]]).T\n",
        "y2 = np.mat([[1,0,1],[1,1,0]]).T\n",
        "\n",
        "tags_print(z0=z0,y0=y0,z1=z1,y1=y1,z2=z2,y2=y2)\n",
        "\n",
        "def multiply_pow(a,n):\n",
        "    a=np.mat(a)\n",
        "    r=1\n",
        "    for i in range(abs(n)):\n",
        "        r = np.multiply(r, a)\n",
        "    if n<0:\n",
        "        r=1/r\n",
        "    return r\n",
        "\n",
        "# tp(multiply_pow([1,2,3],3))\n",
        "    \n",
        "def dLdz_py(y,z):\n",
        "    y=np.mat(y)\n",
        "    z=np.mat(z)\n",
        "    r = np.multiply(-y, np.exp(-z)/(1 + np.exp(-z))) \\\n",
        "        + np.multiply(1-y, \\\n",
        "                       np.exp(-z)/(np.multiply(1 - 1/(1 + np.exp(-z)), \\\n",
        "                                            multiply_pow(1 + np.exp(-z), 2))))\n",
        "#     -y*exp(-z)/(1 + exp(-z)) \\\n",
        "#         + (-y + 1) * \\\n",
        "#             exp(-z) / \\\n",
        "#                 ((1 - 1/(1 + exp(-z))) * (1 + exp(-z))**2)\n",
        "    return r\n",
        "\n",
        "def dLdz_alan(y,z):\n",
        "    y=np.mat(y)\n",
        "    z=np.mat(z)\n",
        "    dldz = np.multiply(-y, 1 - sigmoid(z)) + np.multiply(1 - y, sigmoid(z))\n",
        "    return dldz\n",
        "\n",
        "def Loss(y,z, get_average=False):\n",
        "    y = np.mat(y)\n",
        "    z = np.mat(z)\n",
        "    a = sigmoid(z)    \n",
        "    r = -y.T * (np.log(sigmoid(z))) - (1 - y.T) * (np.log(1 - sigmoid(z)))\n",
        "    if get_average:\n",
        "        r=np.average(r)\n",
        "    return r\n",
        "\n",
        "tag_print(Loss(y0,z0))\n",
        "tag_print(L.subs(y,y0).subs(z,z0))\n",
        "          \n",
        "tag_print(Loss(y1,z1))\n",
        "\n",
        "\n",
        "def dydz(f, x, rate,need_print=False): \n",
        "    '''通过[f(x1)-f(x1+delta)]/delta (delta为微量，一般取 0.0001*x1 或更小)这种近似方式求f在x1处的导数，以验证求导公式'''\n",
        "    \n",
        "    # x是自变量组成的向量或矩阵(一个样本的输入x构成一个列向量；\n",
        "    # 多个样本的输入构成一个矩阵，其中一列表示一个样本的输入)\n",
        "    x = np.mat(x)\n",
        "    f1 = f(x)\n",
        "    if need_print:\n",
        "        tps(x=x,f1=f1)\n",
        "\n",
        "    row = x.shape[0]\n",
        "    col = x.shape[1]\n",
        "    df_dev_dx = np.zeros([row,col])\n",
        "    for j in range(col):# x的每一列代表一个样本的输入，此处按列逐样本计算损失函数对自变量的导数\n",
        "        \n",
        "        # 列向量的每个元素是一个未知数，通过(f2-f1)/(x2-x1)这种方式近似计算f在x1处的导数，\n",
        "        # 一次只能计算f对一个自变量的导数 (因为f是多个自变量的函数，如果多个自变量同时变化，\n",
        "        # 则没法区分出f的变化与具体某个变量的关系)。所以需要逐变量(此处为列向量中的每一行)计算近似导数\n",
        "        for i in range(row):\n",
        "            if need_print:                \n",
        "                print('\\nBefore df_dev_dx.i,j=[{i},{j}]\\n'.format(i=i,j=j))\n",
        "            x1=np.mat(x[:,j]);# 列向量矩阵\n",
        "            if need_print:\n",
        "                tp(x1)\n",
        "            x2 = copy.deepcopy(x1)\n",
        "            if need_print:                                \n",
        "                tp(x2)\n",
        "            x2[i,0] = x2[i, 0] * (1 + rate)\n",
        "            f2 = f(x2, col = j)# x的每一列代表一个样本的输入，此处逐样本计算损失函数，所以只需输入其中一列即可\n",
        "            df = f2[0,0] - f1[j,0]\n",
        "            dx = x2 - x1\n",
        "            if need_print:                                \n",
        "                tps(x2=x2,f2=f2,df=df,dx=dx)\n",
        "            df_dev_dx[i, j] = (df / dx[i,0])\n",
        "            if need_print:                \n",
        "                tps(df_dev_dx=df_dev_dx)                \n",
        "    return np.mat(df_dev_dx)\n",
        "    \n",
        "    \n",
        "def fun_loss(y, need_print=False):        \n",
        "    def loss(z, col=-1):\n",
        "        ya=np.mat(y)\n",
        "        if need_print:\n",
        "            tp(ya,memo='in loss()')\n",
        "        if col>=0:\n",
        "            ya = np.mat(ya[:,col])\n",
        "            if need_print:\n",
        "                tp(ya,memo='in loss() after ya = np.mat(ya[:,col])')\n",
        "        z = np.mat(z)\n",
        "        a = sigmoid(z)   \n",
        "        r = -ya.T * (np.log(a)) - (1 - ya.T) * (np.log(1 - a))\n",
        "        r_diag = np.mat(np.diag(r)).T\n",
        "        return r_diag\n",
        "    return loss\n",
        "\n",
        "rate = 0.000001\n",
        "\n",
        "\n",
        "print('\\n------------- y2 z2 -------------')\n",
        "tp(dLdz_py(y2,z2))\n",
        "tp(dLdz_alan(y2,z2))\n",
        "tp(dydz(fun_loss(y2,need_print=False),z2,rate,need_print=False), tag='dydz(fun_loss(y2),z2,rate)')\n",
        "\n",
        "\n",
        "print('\\n------------- y1 z1 -------------')\n",
        "tp(dLdz_py(y1,z1))\n",
        "tp(dLdz_alan(y1,z1))\n",
        "tp(dLdz_alan(y2[:,1],z2[:,1]), tag='dLdz_alan(y2[:,1]),z2[:,1])')\n",
        "tp(dydz(fun_loss(y1),z1,rate), tag='dydz(fun_loss(y1),z1,rate)')\n",
        "tp(dydz(fun_loss(y2[:,1]),z2[:,1],rate), tag='dydz(fun_loss(y2[:,1]),z2[:,1],rate)')\n",
        "\n",
        "print('\\n------------- y0 z0 -------------')\n",
        "tp(dLdz_py(y0,z0))\n",
        "tp(dLdz_alan(y0,z0))\n",
        "tp(dydz(fun_loss(y0),z0,rate))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxXRS6j7DJzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=np.array([[1,2],[3,4]])\n",
        "tag_print(a.dot(a))\n",
        "tag_print(a[1]*a[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_JBPpFCDJzT",
        "colab_type": "text"
      },
      "source": [
        "## BP反向推导算法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQEXpqToDJzU",
        "colab_type": "text"
      },
      "source": [
        "### FP前向推导"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56nS2yNGDJzZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "   \n",
        "def gene_input_data(sample_count, x_size, y_size, x_min=10, x_max=99, y_min=0, y_max=1):\n",
        "    x=np.mat(np.random.randint(x_min,x_max+1,(sample_count,x_size)))\n",
        "    y=np.mat(np.random.randint(y_min,y_max+1,(sample_count,y_size)))\n",
        "    return x,y\n",
        "\n",
        "\n",
        "def gene_rand_w(nn_struct): \n",
        "    w_n=len(nn_struct)-1\n",
        "    weights=list(range(0,w_n))\n",
        "    for i in range(0,w_n):\n",
        "        weights[i]=np.mat(np.random.rand(nn_struct[i+1],nn_struct[i]))\n",
        "    return weights\n",
        "\n",
        "def nn_fp(input_x, n, w, need_print=False):    \n",
        "    z=list(range(0,n))\n",
        "    a=list(range(0,n))\n",
        "    z[0]=copy.deepcopy(input_x)    \n",
        "    a[0]=copy.deepcopy(input_x)\n",
        "    if need_print:\n",
        "        tag_print(z[0])\n",
        "        tag_print(a[0])\n",
        "    for i in range(1,n):\n",
        "        z[i]=w[i-1] * (a[i-1])\n",
        "        a[i]=sigmoid(z[i])        \n",
        "        if need_print:\n",
        "            print('\\n--------- i = {i}---------'.format(i=i))\n",
        "            tag_print(w[i-1],tag='w[{i}]'.format(i=i-1))\n",
        "            tag_print(a[i-1],tag='a[{i}]'.format(i=i-1))\n",
        "            tag_print(z[i],tag='z[{i}]'.format(i=i))\n",
        "            tag_print(a[i],tag='a[{i}]'.format(i=i))\n",
        "    return z,a;\n",
        "\n",
        "def get_data(data,row_from,row_cnt):\n",
        "    return (np.mat(data)[row_from:row_from+row_cnt, :]).T\n",
        "\n",
        "def show_list(the_list):\n",
        "    tag = getVarName(the_list,level=2)\n",
        "    for i in range(len(the_list)):\n",
        "        tp(the_list[i],tag='{tag}[{i}]'.format(tag=tag, i=i))\n",
        "    return\n",
        "\n",
        "sample_count=2\n",
        "x_size=3\n",
        "y_size=2\n",
        "data_x,data_y=gene_input_data(sample_count=sample_count, x_size=x_size, y_size=y_size, x_min=10,x_max=12)\n",
        "tps(data_x=data_x, data_y=data_y)\n",
        "        \n",
        "nn_node_of_layels=np.array([data_x.shape[1],4,2,data_y.shape[0]])\n",
        "nn_layels_count=len(nn_node_of_layels)\n",
        "tp(nn_node_of_layels)\n",
        "\n",
        "sample_from=0\n",
        "sample_cnt=sample_count\n",
        "x_in=get_data(data_x,sample_from,sample_cnt)\n",
        "y_in=get_data(data_y,sample_from,sample_cnt)\n",
        "weights=gene_rand_w(nn_node_of_layels)\n",
        "if False:\n",
        "    show_list(weights)\n",
        "    tps(x_in=x_in,y_in=y_in)\n",
        "z,a=nn_fp(input_x=x_in, n=nn_layels_count, w=weights, need_print=False);\n",
        "if False:\n",
        "    show_list(z)\n",
        "    show_list(a)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k__X4-0DDJzi",
        "colab_type": "text"
      },
      "source": [
        "### BP算法相关公式\n",
        "\n",
        "为便于书写，下列公式均按照神经网络从1层开始编号，输出层为n层，与程序代码中0至n-1编号略有不同\n",
        "\n",
        "${{\\bf{\\delta }}^{(n)}} = \\frac{{d\\,{\\mathop{\\rm Loss}\\nolimits} }}{{d{{\\bf{z}}^{(n)}}}} =  - {\\bf{y}} \\circ (1 - {\\mathop{\\rm sigmoid}\\nolimits} {{\\bf{z}}^{(n)}}) + (1 - {\\bf{y}}) \\circ {\\mathop{\\rm sigmoid}\\nolimits} {{\\bf{z}}^{(n)}}$\n",
        "\n",
        "${{\\mathbf{\\delta }}^{(i)}}=[f({{\\mathbf{z}}^{(i)}})-{{f}^{2}}({{\\mathbf{z}}^{(i)}})]\\circ {{[{{({{\\mathbf{\\delta }}^{(i+1)}})}^{\\operatorname{T}}}{{\\mathbf{W}}^{(i)}}]}^{\\operatorname{T}}}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial {{\\mathbf{W}}^{(i)}}}=\\left[ \\begin{matrix}\n",
        "   \\frac{\\partial L}{\\partial w_{11}^{(i)}} & \\cdots  & \\frac{\\partial L}{\\partial w_{1{{s}_{i}}}^{(i)}}  \\\\\n",
        "   \\vdots  & \\ddots  & \\vdots   \\\\\n",
        "   \\frac{\\partial L}{\\partial w_{{{s}_{i+1}}1}^{(i)}} & \\cdots  & \\frac{\\partial L}{\\partial w_{{{s}_{i+1}}{{s}_{i}}}^{(i)}}  \\\\\n",
        "\\end{matrix} \\right]=\\left[ \\begin{matrix}\n",
        "   \\delta _{1}^{(i+1)}a_{1}^{(i)} & \\cdots  & \\delta _{1}^{(i+1)}a_{{{s}_{i}}}^{(i)}  \\\\\n",
        "   \\vdots  & \\ddots  & \\vdots   \\\\\n",
        "   \\delta _{{{s}_{i+1}}}^{(i+1)}a_{1}^{(i)} & \\cdots  & \\delta _{{{s}_{i+1}}}^{(i+1)}a_{{{s}_{i}}}^{(i)}  \\\\\n",
        "\\end{matrix} \\right]={{\\mathbf{\\delta }}^{(i+1)}}{{[{{\\mathbf{a}}^{(i)}}]}^{\\operatorname{T}}}\\in \\mathbb{R}({{s}_{i+1}}\\times 1)(1\\times {{s}_{i}})=\\mathbb{R}({{s}_{i+1}}\\times {{s}_{i}})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2oi-YWpDJzi",
        "colab_type": "text"
      },
      "source": [
        "### BP算法代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvIIhFTHDJzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### 函数\n",
        "tp(dLdz_alan(y2,z2))\n",
        "tp(dydz(fun_loss(y2,need_print=False),z2,rate,need_print=False), tag='dydz(fun_loss(y2),z2,rate)')\n",
        "\n",
        "def nn_bp(y, z, a, w, n, learn_rate, need_print=False):    \n",
        "    delta=list(range(0,n)) # 误差因子\n",
        "    dLdw=list(range(0,n-1))\n",
        "    \n",
        "    delta[n-1]=dLdz_alan(y, z[n-1])\n",
        "    if need_print:\n",
        "        tp(delta[n-1],tag='delta[{i}]'.format(i=n-1))\n",
        "    for i in range(n-2,-1,-1): # 相当于 n-2 至 0\n",
        "        # 计算顺序：误差因子delta(i)、损失函数对权重w(i)的偏导数dLdw、按梯度下降法更新w(i)\n",
        "        \n",
        "        if need_print:  \n",
        "            print('\\n\\n')\n",
        "            tps(i=i)\n",
        "            tp(delta[i+1],tag='delta[{i}]'.format(i=i+1))\n",
        "            tp(w[i],tag='w[{i}]'.format(i=i))            \n",
        "        # 误差因子delta(i)\n",
        "        dz  = sigmoid(z[i]) - multiply_pow(sigmoid(z[i]), 2)\n",
        "        delta_multi_w = delta[i+1].T * w[i] # 注意此处不能先更新w，再使用其来计算误差因子\n",
        "        if need_print:            \n",
        "            tp(dz, tag='dz  = sigmoid(z[i]) - multiply_pow(sigmoid(z[i]), 2)')\n",
        "            tp(delta_multi_w, tag= 'delta[i+1].T * w[i]')\n",
        "        delta[i]= np.multiply(dz, delta_multi_w.T)\n",
        "    \n",
        "        if need_print:            \n",
        "            tp(delta[i], tag='delta[i]= np.multiply(dz, delta_multi_w)')\n",
        "        \n",
        "        # 损失函数对权重w(i)的偏导数dLdw\n",
        "        dLdw[i] = delta[i+1] * a[i].T\n",
        "        \n",
        "        # 按梯度下降法更新w(i)\n",
        "        w[i] = w[i] - learn_rate * dLdw[i]\n",
        "        \n",
        "    return w\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "def nn_train(data_x, data_y, nn_node_of_layels, train_steps, learn_rate=0.05, display_times=10, need_print=False):\n",
        "    nn_layels_count=len(nn_node_of_layels)\n",
        "    sample_from = 0\n",
        "    sample_cnt = sample_count\n",
        "    x_in=get_data(data_x, sample_from, sample_cnt)\n",
        "    y_in=get_data(data_y, sample_from, sample_cnt)\n",
        "    weights = gene_rand_w(nn_node_of_layels)\n",
        "    if False:\n",
        "        tps(x_in=x_in,y_in=y_in)\n",
        "    step_loss=dict()\n",
        "    z, a = nn_fp(input_x=x_in, n=nn_layels_count, w=weights, need_print=False);\n",
        "    if False:\n",
        "        tp(z[nn_layels_count-1])\n",
        "    step_loss[0] = Loss(y_in, z[nn_layels_count-1], get_average=True)\n",
        "    for step in range(1, train_steps+1):\n",
        "        weights = nn_bp(y=y_in, z=z, a=a, w=weights, n=nn_layels_count, learn_rate=learn_rate, need_print=False)\n",
        "        z, a = nn_fp(input_x=x_in, w=weights, n=nn_layels_count, need_print=False);\n",
        "        loss = Loss(y_in, z[nn_layels_count-1], get_average=True)\n",
        "        step_loss[step] = loss\n",
        "        \n",
        "        if step % (train_steps/display_times)==0:\n",
        "            tp(step_loss[step],tag='step_loss[{i}]'.format(i=step))\n",
        "        \n",
        "        if False:\n",
        "            show_list(z)\n",
        "            show_list(a)\n",
        "    if need_print:\n",
        "        for step in range(len(step_loss)):\n",
        "            tp(step_loss[step],tag='step_loss[{i}]'.format(i=step))\n",
        "    show_dict(step_loss,y_label='Loss')\n",
        "    if need_print:\n",
        "        tp(step_loss[train_steps])\n",
        "    return step_loss\n",
        "\n",
        "\n",
        "sample_count=50\n",
        "x_size=15\n",
        "y_size=2\n",
        "data_x,data_y = gene_input_data(sample_count=sample_count, x_size=x_size, y_size=y_size, x_min=10,x_max=50)\n",
        "# tps(data_x=data_x, data_y=data_y)\n",
        "        \n",
        "nn_node_of_layels=np.array([data_x.shape[1],10,10,10,data_y.shape[1]])\n",
        "tp(nn_node_of_layels)\n",
        "\n",
        "\n",
        "step_loss = nn_train(data_x = data_x, data_y = data_y, nn_node_of_layels = nn_node_of_layels, \n",
        "         train_steps = 60, learn_rate = 0.05, need_print=False)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqQn-Kx6DJzl",
        "colab_type": "text"
      },
      "source": [
        "# nn_tensorflow_graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhiyxCaZDJzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wj 20190524\n",
        "tf.reset_default_graph()\n",
        "# x_in: (None,3072)\n",
        "x_in=tf.placeholder(tf.float32,[None,3072])\n",
        "# y_in: (None)\n",
        "y_in=tf.placeholder(tf.int32,[None])\n",
        "w=tf.get_variable('w',[x_in.shape[-1],1],initializer=tf.random_normal_initializer(0,1))\n",
        "b=tf.get_variable('b',[1],initializer=tf.constant_initializer(0.0))\n",
        "# y_out: (None,3072)*(3072,1)=(None,1)\n",
        "y_out=tf.matmul(x_in,w)+b\n",
        "py=tf.nn.sigmoid(y_out)\n",
        "# py_reshaped: (None)\n",
        "py_reshaped=tf.reshape(py,[-1])\n",
        "loss=tf.reduce_mean(tf.square(py_reshaped-tf.cast(y_in,tf.float32)))\n",
        "predict=py_reshaped>0.5\n",
        "predict_correct=tf.equal(tf.cast(predict,tf.int32),y_in)\n",
        "accuracy=tf.reduce_mean(tf.cast(predict_correct,tf.float32))\n",
        "\n",
        "with tf.name_scope('train_op'):\n",
        "    train_op=tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
        "    \n",
        "init=tf.global_variables_initializer()\n",
        "\n",
        "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
        "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
        "\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "class_names=[\"airplane\",\"auto\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"];\n",
        "print(time_now())\n",
        "# train_steps=10000\n",
        "# xs=20\n",
        "# min_train_batch_size=1\n",
        "# # train_batch_size= train_data.len*xs//train_steps\n",
        "# train_batch_size=128\n",
        "# train_batch_size= (train_batch_size>train_data.len)and train_data.len or train_batch_size\n",
        "# train_batch_size= (train_batch_size<min_train_batch_size)and min_train_batch_size or train_batch_size\n",
        "# # print('train_batch_size = ',train_batch_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGNclu9qDJzo",
        "colab_type": "text"
      },
      "source": [
        "## show_dicts 曲线图"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmMyPJbGDJzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DICT_KEY='dic'\n",
        "FIG_LABEL='label'\n",
        "X_LABEL='x'\n",
        "Y_LABEL='y'\n",
        "\n",
        "def show_dicts(dicts, figsize = (12,9), in_one_figure = True):\n",
        "    if in_one_figure:\n",
        "        plt.figure(figsize=figsize)\n",
        "    index = 0\n",
        "    for d in dicts:          \n",
        "        if not in_one_figure:\n",
        "            index += 1\n",
        "            plt.figure(num=index,figsize=figsize)\n",
        "        plt.plot(d[DICT_KEY].keys(), d[DICT_KEY].values())\n",
        "        if not in_one_figure:\n",
        "            if X_LABEL in d:\n",
        "                plt.xlabel(d[X_LABEL])\n",
        "            if Y_LABEL in d:\n",
        "                plt.ylabel(d[Y_LABEL])\n",
        "    plt.show()\n",
        "\n",
        "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
        "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "def train_1(train_steps, batch_size, \n",
        "            watch_times = 10, test_times = 50, max_not_progress = 3, print_watch = False):\n",
        "    if print_watch :\n",
        "        print('----- Start at %s'%(time_now()))\n",
        "        print('Train steps: %lu, Train batch size: %lu, Test times: %lu' % \n",
        "              (train_steps, batch_size, test_times))\n",
        "    time_begin=monotonic()\n",
        "    loss_dict = dict()\n",
        "    acc_dict = dict()\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for i in range(1, train_steps + 1):\n",
        "            # Train\n",
        "            batch_data, batch_labels = train_data.next_batch(batch_size)            \n",
        "            [loss_val, acc_val, _] = sess.run([loss, accuracy, train_op], feed_dict = {\n",
        "                x_in: batch_data, y_in: batch_labels})\n",
        "            if i % (train_steps // test_times) == 0:\n",
        "                # Test\n",
        "                test_data = CifarData(test_filenames, False)\n",
        "                test_batch_data, test_batch_labels = test_data.next_batch(test_data.len)                \n",
        "                [loss_val, acc_val] = sess.run([loss, accuracy], feed_dict = {\n",
        "                    x_in: test_batch_data, y_in: test_batch_labels})\n",
        "                if i % (train_steps // watch_times) == 0:\n",
        "                    if print_watch :\n",
        "                        print('curr_step: %-6lu, loss_val: %5.4f, acc_val: %5.4f'%(i, loss_val, acc_val))\n",
        "                loss_dict[i] = loss_val\n",
        "                acc_dict[i]  = acc_val\n",
        "    if print_watch :\n",
        "        print('----- End at %s'%(time_now(time_begin)))\n",
        "    time_end = monotonic()\n",
        "    elaps = time_end - time_begin\n",
        "    return loss_dict, acc_dict, elaps\n",
        "\n",
        "def TEST_train_1():\n",
        "    loss_dict, acc_dict, elaps = train_1(train_steps = 5000, batch_size = 20, test_times = 6, watch_times = 2, print_watch = True)\n",
        "    dicts = [dict([(DICT_KEY, loss_dict), (FIG_LABEL, 'loss_fig'), (X_LABEL, 'step'), (Y_LABEL, 'loss')]), \n",
        "           dict([(DICT_KEY, acc_dict),  (FIG_LABEL, 'acc_fig'),  (X_LABEL, 'step'), (Y_LABEL, 'accuracy')])]\n",
        "    show_dicts(dicts = dicts, figsize = (16,5), in_one_figure = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml6nwzIaDJzr",
        "colab_type": "text"
      },
      "source": [
        "## train_and_analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh9qFY7ZDJzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_analysis(train_steps,batch_size,test_times,\n",
        "                       watch_times=10,figsize=(9,12),in_one_figure=True):\n",
        "    \n",
        "    loss_dict, acc_dict, elaps = train_1(train_steps = train_steps, batch_size = batch_size, \n",
        "                                  watch_times = watch_times, test_times = test_times, print_watch = True)\n",
        "    \n",
        "    dicts=[dict([(DICT_KEY, loss_dict), (FIG_LABEL, 'loss_fig'), (X_LABEL, 'step'), (Y_LABEL, 'loss')]), \n",
        "           dict([(DICT_KEY, acc_dict),  (FIG_LABEL, 'acc_fig'),  (X_LABEL, 'step'), (Y_LABEL, 'accuracy')])]\n",
        "    \n",
        "    show_dicts(dicts = dicts, figsize = figsize, in_one_figure = in_one_figure)\n",
        "\n",
        "    return loss_dict,acc_dict\n",
        "\n",
        "# train_steps=100000\n",
        "# batch_size=4\n",
        "# test_times=200\n",
        "# train_and_analysis(train_steps = train_steps, batch_size = batch_size, test_times = test_times)\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "def TEST_train_and_analysis():\n",
        "    for i in range(4,5):\n",
        "        epoch = 1\n",
        "        batch_size = 2 ** i\n",
        "        train_steps = int(epoch * train_data.len / batch_size * (math.log(batch_size) if batch_size > 3 else 1))\n",
        "        test_times = 4\n",
        "        watch_times = 2\n",
        "        loss_dict,acc_dict = train_and_analysis(train_steps = train_steps, batch_size = batch_size, \n",
        "                                                test_times = test_times, watch_times = watch_times,\n",
        "                                                figsize = (16,6), in_one_figure = False)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrHhZBItDJzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#wj\n",
        "def train(train_steps,batch_size,watch_times=10,max_not_progress=3,print_watch=False):\n",
        "    time_begin=monotonic()\n",
        "    watch_period = train_steps//watch_times\n",
        "    accuracy_dict=dict()\n",
        "    not_progress = 0\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        if print_watch :\n",
        "            print('***** Start at %s'%(time_now()))\n",
        "            print('Train steps: %6u \\t Train batch size: %6u' % (train_steps, batch_size))    \n",
        "        for i in range(1,train_steps+1):        \n",
        "            data,labels=train_data.next_batch(batch_size)\n",
        "            loss_val,accuracy_val,_=sess.run([loss,accuracy,train_op],feed_dict={x_in:data,y_in:labels})            \n",
        "            \n",
        "            if i % ((watch_period==0)and 1 or watch_period) ==0 or i==train_steps :    \n",
        "                if print_watch :\n",
        "                    print('Train: No. %5u, accuracy = %4.5f, loss_val = %4.5f' % (i,accuracy_val,loss_val))    \n",
        "                test_data = CifarData(test_filenames, False)\n",
        "                data,labels=test_data.next_batch(test_data.len)\n",
        "                his_max = (0 if (len(accuracy_dict)==0) else max(accuracy_dict.values()))\n",
        "                accuracy_dict[i],_ = sess.run([accuracy,loss],feed_dict={x_in:data, y_in:labels})\n",
        "                if print_watch :\n",
        "                    print('Test:  No. %5u, accuracy = %4.5f ***' % (i,accuracy_dict[i]))    \n",
        "                if accuracy_dict[i] <= his_max:\n",
        "                    not_progress+=1\n",
        "                if max_not_progress != 0 and not_progress >= max_not_progress:\n",
        "                    break\n",
        "    if print_watch :\n",
        "        print('***** End at %s'%(time_now()))\n",
        "    time_end=monotonic()\n",
        "    elaps = time_end - time_begin\n",
        "    return max(accuracy_dict.values()),elaps,accuracy_dict\n",
        "\n",
        "def TEST_train():\n",
        "    print('--------- BEGIN %s---------' % (time_now()))\n",
        "    begin_time = get_timestamp()\n",
        "    for i in range(6,7):\n",
        "        batch_size_para = 2 ** i\n",
        "    #     steps = 100 * 10000\n",
        "        steps = 2000\n",
        "        acc,elaps,accuracy_dict = train(train_steps=steps,batch_size=batch_size_para,watch_times=50,max_not_progress=20,print_watch=False)\n",
        "        print('batch_size=%3d,acc=%4.5f,use_steps=%7d,elaps=%5ds' % (batch_size_para, acc, max(accuracy_dict.keys()), elaps / ((10 ** 9) if LOCATE == 'home' else 1)))\n",
        "    print('---------- END %s----------' % (time_now(begin_time)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQ0v8VHDJzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=[5,1.2,5.2,1.5,4.4,3]\n",
        "a=tf.nn.softmax(x)\n",
        "aa = tf.Session().run(a)\n",
        "print(aa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTUwYpg_DJz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=range(12)\n",
        "print('a.type',type(a))\n",
        "a=list(a)\n",
        "print('a.type',type(a))\n",
        "na=np.array(a)\n",
        "ta=tf.convert_to_tensor(a)\n",
        "print('ta.type',type(ta),ta.shape)\n",
        "ta2=tf.reshape(ta,(-1,1))\n",
        "print('ta2.type',type(ta2),ta2.shape)\n",
        "ta3=tf.reshape(ta2,[-1])\n",
        "print('ta3.type',type(ta3),ta3.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzUvkZnLDJz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=1\n",
        "my_list=['Jie','Kate','Jing']\n",
        "print(my_list,a)\n",
        "def func_20190525(the_list,a):\n",
        "    a=2\n",
        "    the_list[0]='Alan'\n",
        "    print(the_list,a)\n",
        "func_20190525(my_list,a)\n",
        "print(my_list,a)\n",
        "list2=my_list\n",
        "print('list2:',list2)\n",
        "print('my_list:',my_list)\n",
        "list2.append('Alan K. Wen')\n",
        "print('list2:',list2)\n",
        "print('my_list:',my_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwG4JUYpDJz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "a=[[1,2],[2],[3]]\n",
        "b0=a # 赋值\n",
        "b1=a[:] # 浅拷贝\n",
        "b2=deepcopy(a) # 深拷贝\n",
        "print('addr a,b0,b1,b2',[id(x) for x in [a,b0,b1,b2]])\n",
        "print('addr a[i]',[id(x) for x in a])\n",
        "print('addr b0[i]',[id(x) for x in b0])\n",
        "print('addr b1[i]',[id(x) for x in b1])\n",
        "print('addr b2[i]',[id(x) for x in b2])\n",
        "a[0].append(1)\n",
        "'''不可变的对象修改会开辟新的空间，可变的对象修改不会开辟新空间。也进一步证明了浅拷贝仅仅是复制了容器中元素的地址。'''\n",
        "# 　　1. 赋值是将一个对象的地址赋值给一个变量，让变量指向该地址（旧瓶装旧酒）。\n",
        "# 　　2. 浅拷贝是在另一块地址中创建一个新的变量或容器，但是容器内的元素的地址均是源对象的元素的地址的拷贝。也就是说新的容器中指向了旧的元素（新瓶装旧酒）。\n",
        "# 　　3. 深拷贝是在另一块地址中创建一个新的变量或容器，同时容器内的元素的地址也是新开辟的，仅仅是值相同而已，是完全的副本。也就是说（新瓶装新酒）。\n",
        "print('--- After a[0].append(1). ---')\n",
        "print('a:',a)\n",
        "print('b0:',b0)\n",
        "print('b1:',b1)\n",
        "print('b2:',b2)\n",
        "print('addr a[i]',[id(x) for x in a])\n",
        "print('addr b0[i]',[id(x) for x in b0])\n",
        "print('addr b1[i]',[id(x) for x in b1])\n",
        "print('addr b2[i]',[id(x) for x in b2])\n",
        "a[0]=1\n",
        "print('--- After a[0]=1. ---')\n",
        "print('a:',a)\n",
        "print('b0:',b0)\n",
        "print('b1:',b1)\n",
        "print('b2:',b2)\n",
        "print('addr a[i]',[id(x) for x in a])\n",
        "print('addr b0[i]',[id(x) for x in b0])\n",
        "print('addr b1[i]',[id(x) for x in b1])\n",
        "print('addr b2[i]',[id(x) for x in b2])\n",
        "print('\\n',time_now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWlCeVpaDJ0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n----------END---------{time}-------------\\n'.format(time=time_now()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDRJt-51DJ0E",
        "colab_type": "text"
      },
      "source": [
        "# END"
      ]
    }
  ]
}