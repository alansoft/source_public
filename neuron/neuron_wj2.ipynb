{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "320.46px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "neuron_wj2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpKSotM9DJxo",
        "colab_type": "text"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0I7jDO7DJxs",
        "colab_type": "code",
        "outputId": "4b33cc90-fec3-4882-c883-dfb96b35201c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#20200322使用CoLab\n",
        "#LOCATE = 'home'\n",
        "LOCATE='T490'\n",
        "#IDE = 'JUPYTER'\n",
        "IDE='colab'\n",
        "# IDE = 'VS'\n",
        "\n",
        "import time\n",
        "\n",
        "def monotonic():\n",
        "    if LOCATE=='home':\n",
        "        return time.monotonic_ns()\n",
        "    else:\n",
        "        return time.monotonic()\n",
        "# if IDE == 'JUPYTER':\n",
        "    #代码自动完成\n",
        "    # %config IPCompleter.greedy=True\n",
        "if IDE == 'colab': \n",
        "  %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "from matplotlib.pyplot import imshow\n",
        "if IDE == 'JUPYTER' or IDE=='colab':\n",
        "    %matplotlib inline\n",
        "#CIFAR_DIR = \"./../../cifar-10-batches-py\"\n",
        "if LOCATE=='home':\n",
        "  CIFAR_DIR = 'V:\\DATA\\cifar-10-batches-py'\n",
        "else:\n",
        "  CIFAR_DIR = 'd:\\Alan\\data\\cifar-10-batches-py'\n",
        "if IDE=='colab':  \n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  path = \"/content/drive/My Drive\"\n",
        "  os.chdir(path)\n",
        "  # print(os.listdir(path))\n",
        "  CIFAR_DIR=path+'/Alan/Data/cifar-10-batches-py'\n",
        "\n",
        "print(os.listdir(CIFAR_DIR))\n",
        "\n",
        "def time_str(t):\n",
        "    return time.strftime(\"%Y%m%d-%H:%M:%S\", t)\n",
        "\n",
        "def time_now(begin_time=0):    \n",
        "    t=time.localtime()\n",
        "    if begin_time==0:\n",
        "        return time_str(t)\n",
        "    else:\n",
        "        end_time=monotonic()\n",
        "        elaps = end_time - begin_time\n",
        "#         elaps_sec = elaps/10**9 if LOCATE=='home' else elaps\n",
        "        return '%s. Time used: %.3f s.'%(time_str(t), elaps/((10**9) if LOCATE=='home' else 1))\n",
        "\n",
        "def get_timestamp():\n",
        "    return monotonic()\n",
        "    \n",
        "print(time_now())\n",
        "t0=get_timestamp()\n",
        "for i in range(1234567):\n",
        "    i=i\n",
        "print(time_now(t0))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['batches.meta', 'readme.html', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'test_batch']\n",
            "20200323-02:05:13\n",
            "20200323-02:05:13. Time used: 0.085 s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPHm9-t7Dzre",
        "colab_type": "text"
      },
      "source": [
        "#使用免费的GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6JccGBZD0Hm",
        "colab_type": "code",
        "outputId": "0e8b2722-ce22-4961-8886-969308e0a00a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "if IDE == 'colab':\n",
        "  #使用免费的 GPU\n",
        "  #在打开的 Jupyter Notebook 中，选择菜单栏“代码执行程序（Runtime）”，“更改运行类型（Change runtime type）”，这时将看到以下弹出窗口：\n",
        "  # 确保“硬件加速器（Hardware accelerator）”设置为 GPU（默认为 CPU）。设置完毕后点击保存。\n",
        "  #但是，由于在线 GPU 资源有限，有时候可能会出现分配失败的提示。并且，谷歌允许你一次最多持续使用 12 小时的免费 GPU。\n",
        "  #检查是否真的开启了 GPU（即当前连接到了GPU实例），可以直接在 Jupyter Notebook 中运行以下命令：\n",
        "  %tensorflow_version 2.x\n",
        "  import tensorflow as tf\n",
        "  device_name = tf.test.gpu_device_name()\n",
        "  if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "  print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAuiAA2pDJyA",
        "colab_type": "text"
      },
      "source": [
        "# display var"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST8OskorDJyC",
        "colab_type": "code",
        "outputId": "7d1fe92f-d829-4785-b197-a6e90444efd8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "import inspect\n",
        "import copy\n",
        "def retrieve_name_ex(var,level=0):    \n",
        "    stacks = inspect.stack()    \n",
        "    try:        \n",
        "        callFunc = stacks[level].function        \n",
        "        code = stacks[level+1].code_context[0]        \n",
        "        startIndex = code.index(callFunc)        \n",
        "        startIndex = code.index(\"(\", startIndex + len(callFunc)) + 1        \n",
        "        endIndex = code.index(\")\", startIndex)        \n",
        "        return code[startIndex:endIndex].strip()    \n",
        "    except:        \n",
        "        return \"\"\n",
        "\n",
        "def outputVar(var,level=1,index=-1,end_str='\\n'):               \n",
        "#     print(\"{} [0x{}] = {}\".format(retrieve_name_ex(var,1),var))   \n",
        "    if index==-1:\n",
        "        var_name=retrieve_name_ex(var,level)        \n",
        "    else:\n",
        "        var_name='%s[%d]'%(retrieve_name_ex(var,level),index)\n",
        "    val='{}.'.format(var)\n",
        "    print('%-10s[0x%012lx]=%-15s'%(var_name,id(var),val),end=end_str)\n",
        "    \n",
        "def output_var(var,level=1,index=-1,end_str='\\n'):               \n",
        "    if index==-1:\n",
        "        var_name=retrieve_name_ex(var,level)        \n",
        "    else:\n",
        "        var_name='%s[%d]'%(retrieve_name_ex(var,level),index)\n",
        "    val='{}.'.format(var)\n",
        "    print('%s = %s'%(var_name,val),end=end_str)\n",
        "\n",
        "def getVarName(var,level=1,index=-1):\n",
        "    if index==-1:\n",
        "        var_name=retrieve_name_ex(var,level)        \n",
        "    else:\n",
        "        var_name='%s[%d]'%(retrieve_name_ex(var,level),index)\n",
        "    return var_name\n",
        "\n",
        "def print_var(var,level=1,index=-1):\n",
        "    print(getVarName(var,2),'=',var)\n",
        "    \n",
        "a=[1,2,3]\n",
        "print_var(a)\n",
        "    \n",
        "def output_child(arr):\n",
        "    s=retrieve_name_ex(arr,1)\n",
        "    for i in range(len(arr)):\n",
        "        outputVar(arr[i],2,i,'')\n",
        "    print('\\n',end='')\n",
        "a=[[1,2],[2],[3]]\n",
        "b_sgn=a          # 赋值(相当于C++中的引用)\n",
        "b_spl=a[:]       # 浅拷贝\n",
        "b_dp=copy.deepcopy(a) # 深拷贝\n",
        "outputVar(a)\n",
        "outputVar(b_sgn)\n",
        "outputVar(b_spl)\n",
        "outputVar(b_dp)\n",
        "output_child(a)\n",
        "output_child(b_sgn)\n",
        "output_child(b_spl)\n",
        "output_child(b_dp)\n",
        "a[0].append(3)\n",
        "print('--- After a[0].append(3). ---')\n",
        "outputVar(a)\n",
        "outputVar(b_sgn)\n",
        "outputVar(b_spl)\n",
        "outputVar(b_dp)\n",
        "output_child(a)\n",
        "output_child(b_sgn)\n",
        "output_child(b_spl)\n",
        "output_child(b_dp)\n",
        "\n",
        "a[0]=1\n",
        "print('--- After a[0]=1. ---')\n",
        "outputVar(a)\n",
        "outputVar(b_sgn)\n",
        "outputVar(b_spl)\n",
        "outputVar(b_dp)\n",
        "output_child(a)\n",
        "output_child(b_sgn)\n",
        "output_child(b_spl)\n",
        "output_child(b_dp)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a = [1, 2, 3]\n",
            "a         [0x7fbc08ba0a48]=[[1, 2], [2], [3]].\n",
            "b_sgn     [0x7fbc08ba0a48]=[[1, 2], [2], [3]].\n",
            "b_spl     [0x7fbc08ba0848]=[[1, 2], [2], [3]].\n",
            "b_dp      [0x7fbc08c030c8]=[[1, 2], [2], [3]].\n",
            "a[0]      [0x7fbc1a5b6b08]=[1, 2].        a[1]      [0x7fbc08ba0f48]=[2].           a[2]      [0x7fbc08ba0c48]=[3].           \n",
            "b_sgn[0]  [0x7fbc1a5b6b08]=[1, 2].        b_sgn[1]  [0x7fbc08ba0f48]=[2].           b_sgn[2]  [0x7fbc08ba0c48]=[3].           \n",
            "b_spl[0]  [0x7fbc1a5b6b08]=[1, 2].        b_spl[1]  [0x7fbc08ba0f48]=[2].           b_spl[2]  [0x7fbc08ba0c48]=[3].           \n",
            "b_dp[0]   [0x7fbc08beee88]=[1, 2].        b_dp[1]   [0x7fbc1a131108]=[2].           b_dp[2]   [0x7fbc08beef08]=[3].           \n",
            "--- After a[0].append(3). ---\n",
            "a         [0x7fbc08ba0a48]=[[1, 2, 3], [2], [3]].\n",
            "b_sgn     [0x7fbc08ba0a48]=[[1, 2, 3], [2], [3]].\n",
            "b_spl     [0x7fbc08ba0848]=[[1, 2, 3], [2], [3]].\n",
            "b_dp      [0x7fbc08c030c8]=[[1, 2], [2], [3]].\n",
            "a[0]      [0x7fbc1a5b6b08]=[1, 2, 3].     a[1]      [0x7fbc08ba0f48]=[2].           a[2]      [0x7fbc08ba0c48]=[3].           \n",
            "b_sgn[0]  [0x7fbc1a5b6b08]=[1, 2, 3].     b_sgn[1]  [0x7fbc08ba0f48]=[2].           b_sgn[2]  [0x7fbc08ba0c48]=[3].           \n",
            "b_spl[0]  [0x7fbc1a5b6b08]=[1, 2, 3].     b_spl[1]  [0x7fbc08ba0f48]=[2].           b_spl[2]  [0x7fbc08ba0c48]=[3].           \n",
            "b_dp[0]   [0x7fbc08beee88]=[1, 2].        b_dp[1]   [0x7fbc1a131108]=[2].           b_dp[2]   [0x7fbc08beef08]=[3].           \n",
            "--- After a[0]=1. ---\n",
            "a         [0x7fbc08ba0a48]=[1, [2], [3]]. \n",
            "b_sgn     [0x7fbc08ba0a48]=[1, [2], [3]]. \n",
            "b_spl     [0x7fbc08ba0848]=[[1, 2, 3], [2], [3]].\n",
            "b_dp      [0x7fbc08c030c8]=[[1, 2], [2], [3]].\n",
            "a[0]      [0x000000a68ac0]=1.             a[1]      [0x7fbc08ba0f48]=[2].           a[2]      [0x7fbc08ba0c48]=[3].           \n",
            "b_sgn[0]  [0x000000a68ac0]=1.             b_sgn[1]  [0x7fbc08ba0f48]=[2].           b_sgn[2]  [0x7fbc08ba0c48]=[3].           \n",
            "b_spl[0]  [0x7fbc1a5b6b08]=[1, 2, 3].     b_spl[1]  [0x7fbc08ba0f48]=[2].           b_spl[2]  [0x7fbc08ba0c48]=[3].           \n",
            "b_dp[0]   [0x7fbc08beee88]=[1, 2].        b_dp[1]   [0x7fbc1a131108]=[2].           b_dp[2]   [0x7fbc08beef08]=[3].           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u9a80QjDJyH",
        "colab_type": "text"
      },
      "source": [
        "$ P(A \\mid B) = \\frac{P(B \\mid A) , P(A)}{P(B)} $\n",
        "\n",
        "$ \\frac 1 2 $\n",
        "$\\vec{x}\\stackrel{\\mathrm{def}}{=} (x_1, ..., x_n)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4cohITNDJyL",
        "colab_type": "text"
      },
      "source": [
        "## tag_print"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7CMTt9oDJyN",
        "colab_type": "code",
        "outputId": "a2742592-a742-4a26-9a9f-92d0b430dd54",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def remove_sufix(s, redundance_flag):\n",
        "    '''去除字符串尾部多余的部分'''\n",
        "    index = s.find(redundance_flag)\n",
        "    if index >= 0:\n",
        "        return s[0:index-1]\n",
        "    else:\n",
        "        return s\n",
        "    \n",
        "def add_match_parentheses(s):\n",
        "    left_pt_cnt=0\n",
        "    right_pt_cnt=0\n",
        "    for c in s:\n",
        "        if c=='(':\n",
        "            left_pt_cnt += 1\n",
        "        elif c==')':\n",
        "            right_pt_cnt += 1\n",
        "    if left_pt_cnt - right_pt_cnt <=0:\n",
        "        return s\n",
        "    for i in range(left_pt_cnt - right_pt_cnt):\n",
        "        s += ')'\n",
        "    return s\n",
        "\n",
        "g_print_flag = False\n",
        "\n",
        "def tag_print(var, memo='', tag='', level_plus=0, display=True, big_list=False):\n",
        "    if display == False:\n",
        "        return\n",
        "    if tag == '':\n",
        "        tag = getVarName(var,level=2+level_plus)\n",
        "        if g_print_flag:\n",
        "            print('getVarName=',tag)\n",
        "        tag = remove_sufix(tag,getVarName(var))\n",
        "        tag = remove_sufix(tag,getVarName(memo))\n",
        "        tag = remove_sufix(tag,getVarName(display))\n",
        "        tag = remove_sufix(tag,getVarName(big_list))\n",
        "        tag = add_match_parentheses(tag)\n",
        "    enter_str_after_var = ''  \n",
        "    shape_str = '{shape}\\t'.format(shape= '-' )\n",
        "    if type(var) == np.ndarray or type(var) == np.matrix:\n",
        "        shape_str = '{shape}\\t'.format(shape=var.shape)        \n",
        "        if(len(var.shape) > 1 and var.shape[0] > 1):\n",
        "            enter_str_after_var = '\\n'  \n",
        "    if memo != '':\n",
        "        memo = '\\n' + memo\n",
        "    type_str = '{type}\\t'.format(type=type(var))\n",
        "      \n",
        "    print('{memo}\\n{type_str}{shape_str}{tag} = {enter}{mat}'.\n",
        "          format(memo=memo,type_str=type_str,shape_str=shape_str,tag=tag,mat=var,type=type(var),enter=enter_str_after_var))\n",
        "    \n",
        "def tp(var, memo='', tag='', level_plus=0, display=True, big_list=False):\n",
        "    tag_print(var=var, memo=memo, tag=tag, level_plus=1, display=display, big_list=big_list)\n",
        "    \n",
        "def tags_print(**vars):\n",
        "    for first_part,second_part in vars.items():\n",
        "        tag_print(tag=first_part,var=second_part)\n",
        "        \n",
        "def tps(**vars):\n",
        "    for first_part,second_part in vars.items():\n",
        "        tag_print(tag=first_part,var=second_part)\n",
        "    \n",
        "z0=0.5\n",
        "tp(z0)\n",
        "tp(np.mat(z0))\n",
        "a=np.array([[1,2,3],[4,5,6]])\n",
        "tp(a)\n",
        "tp(a*a)\n",
        "\n",
        "tp(a.dot(a.T))\n",
        "tp(a.T.dot(a))\n",
        "\n",
        "c=[[1,2],[3,4]]\n",
        "tp(c)\n",
        "mc=np.mat(c)\n",
        "tp(mc)\n",
        "tp(mc**2)\n",
        "b=list(range(10))\n",
        "ma=np.mat(a)\n",
        "tp(np.mat(a))\n",
        "mb=np.mat(b)\n",
        "# c=ma*ma.T\n",
        "tp(ma*ma.T)\n",
        "tp(ma.T*ma)\n",
        "tp(np.array(ma))\n",
        "tags_print(b=b,a=a)\n",
        "\n",
        "# def total(a=5,  **phonebook):\n",
        "# #     print('a', a)\n",
        "#     #遍历元组中的所有项目\n",
        "# #     for single_item in numbers:\n",
        "# #         print('single_item', single_item)\n",
        "#     #遍历字典中的所有项目\n",
        "#     for first_part, second_part in phonebook.items():\n",
        "#         print(first_part,second_part)\n",
        "# print(total(10,Jack=1123,John=2231,Inge=1560))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'float'>\t-\tz0 = 0.5\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tnp.mat(z0) = [[0.5]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\ta = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\ta*a = \n",
            "[[ 1  4  9]\n",
            " [16 25 36]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 2)\ta.dot(a.T) = \n",
            "[[14 32]\n",
            " [32 77]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(3, 3)\ta.T.dot(a) = \n",
            "[[17 22 27]\n",
            " [22 29 36]\n",
            " [27 36 45]]\n",
            "\n",
            "<class 'list'>\t-\tc = [[1, 2], [3, 4]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tmc = \n",
            "[[1 2]\n",
            " [3 4]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tmc**2 = \n",
            "[[ 7 10]\n",
            " [15 22]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 3)\tnp.mat(a) = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tma*ma.T = \n",
            "[[14 32]\n",
            " [32 77]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 3)\tma.T*ma = \n",
            "[[17 22 27]\n",
            " [22 29 36]\n",
            " [27 36 45]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\tnp.array(ma) = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "<class 'list'>\t-\tb = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\ta = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvbmHbQWDJyY",
        "colab_type": "text"
      },
      "source": [
        "# class CifarData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux8dBekCDJyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(filename):\n",
        "    \"\"\"read data from data file.\"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = pickle.load(f, encoding='bytes')\n",
        "        return data[b'data'], data[b'labels']\n",
        "\n",
        "# tensorflow.Dataset.\n",
        "class CifarData:\n",
        "    def __init__(self, filenames, need_shuffle):\n",
        "        all_data = []\n",
        "        all_labels = []\n",
        "        for filename in filenames:\n",
        "            data, labels = load_data(filename)\n",
        "            for item, label in zip(data, labels):\n",
        "                if label in [0, 1]:\n",
        "                    all_data.append(item)\n",
        "                    all_labels.append(label)\n",
        "        self._data = np.vstack(all_data)\n",
        "        self.orignal_data = self._data\n",
        "        self._data = self._data / 127.5 - 1\n",
        "        self._labels = np.hstack(all_labels)\n",
        "#         print(\"data.shape:  \",self._data.shape)\n",
        "#         print(\"labels.shape:\",self._labels.shape)\n",
        "        \n",
        "        self._num_examples = self._data.shape[0]\n",
        "        self._need_shuffle = need_shuffle\n",
        "        self._indicator = 0\n",
        "        if self._need_shuffle:\n",
        "            self._shuffle_data()            \n",
        "        self.len=self._num_examples\n",
        "            \n",
        "    def _shuffle_data(self):\n",
        "        # [0,1,2,3,4,5] -> [5,3,2,4,0,1]\n",
        "        p = np.random.permutation(self._num_examples)\n",
        "        self._data = self._data[p]\n",
        "        self._labels = self._labels[p]\n",
        "    \n",
        "    def next_batch(self, batch_size):\n",
        "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
        "        end_indicator = self._indicator + batch_size\n",
        "        if end_indicator > self._num_examples:\n",
        "            if self._need_shuffle:\n",
        "                self._shuffle_data()\n",
        "                self._indicator = 0\n",
        "                end_indicator = batch_size\n",
        "            else:\n",
        "                raise Exception(\"have no more examples\")\n",
        "        if end_indicator > self._num_examples:\n",
        "            raise Exception(\"batch size is larger than all examples\")\n",
        "        batch_data = self._data[self._indicator: end_indicator]\n",
        "        batch_labels = self._labels[self._indicator: end_indicator]\n",
        "        self._indicator = end_indicator\n",
        "        return batch_data, batch_labels    \n",
        "    \n",
        "    def show_img(self,index):\n",
        "        if index>=self.len:\n",
        "            print('索引越界')\n",
        "            return\n",
        "        img=self.orignal_data[index]\n",
        "        img2=img.reshape((3,32,32))\n",
        "        img3=img2.transpose((1,2,0))\n",
        "#         imshow(img3)\n",
        "#         _img_=img.reshape((3,32,32))\n",
        "        plt.imshow(img3)\n",
        "        plt.show()\n",
        "        return    \n",
        "    \n",
        "import os\n",
        "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
        "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
        "\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "class_names=[\"airplane\",\"auto\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"];\n",
        "\n",
        "def TEST_class_CifarData_and_show_img():\n",
        "    for i in range(1):\n",
        "        print('\\nNo. %d: label[%d] %s' % (i, test_data._labels[i], class_names[test_data._labels[i]]))\n",
        "        test_data.show_img(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIbVvKyiDJyn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# print(w)\n",
        "s=np.array([2,3,1])\n",
        "w=dict()\n",
        "for i in range(0,len(s)-1):\n",
        "    a=s[i+1]\n",
        "    b=s[i]\n",
        "    w[i]=np.random.rand(a,b)\n",
        "# print(w)\n",
        "z=dict()\n",
        "z[1]=np.random.rand(2,3)\n",
        "i=1\n",
        "# print('z[{i}]=\\n{zi}'.format(i=i,zi=z[i]))\n",
        "# print('a={a}'.format(a=3))\n",
        "a=np.random.rand(1,3)\n",
        "b=np.random.rand(3,2)\n",
        "c=a.dot(b)\n",
        "tag_print(c)\n",
        "a=list(range(5,0,-1))\n",
        "output_var(a)\n",
        "a[1]=np.zeros(2)\n",
        "output_var(a)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39xTY2WtDJyr",
        "colab_type": "text"
      },
      "source": [
        "# BP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8PdRVSwDJyt",
        "colab_type": "text"
      },
      "source": [
        "## sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lw_LRFwDJyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "da3ba415-a990-45e1-9d1b-0e35e9a66931"
      },
      "source": [
        "def sigmoid(x):\n",
        "    y=1/(1+np.exp(-x))\n",
        "    return y\n",
        "\n",
        "def sigmoid_diff(x):\n",
        "    f=sigmoid(x)\n",
        "    diff=f-f*f\n",
        "    return diff\n",
        "\n",
        "x=np.array([[1,2,3]])\n",
        "print(x.shape)\n",
        "print(sigmoid(x))\n",
        "print(sigmoid_diff(x))\n",
        "print(np.transpose(x).shape)\n",
        "print(np.transpose(x))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3)\n",
            "[[0.73105858 0.88079708 0.95257413]]\n",
            "[[0.19661193 0.10499359 0.04517666]]\n",
            "(3, 1)\n",
            "[[1]\n",
            " [2]\n",
            " [3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72lQGT2fDJy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e7dbdaf0-0705-4533-965f-af7c4397de7b"
      },
      "source": [
        "d=dict()\n",
        "d[1]=1\n",
        "not(1 in d)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C7gLv1vDJzD",
        "colab_type": "text"
      },
      "source": [
        "## show_fun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGNiiR3nDJzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "outputId": "1cd311ed-a4af-4d0f-f1b0-b2884408c265"
      },
      "source": [
        "DATA_DICT='data_dict'\n",
        "FIG_LABEL='label'\n",
        "X_LABEL='x'\n",
        "Y_LABEL='y'\n",
        "COLOR='color'\n",
        "\n",
        "    \n",
        "def show_dicts(dicts, figsize = (12,9), in_one_figure = True):\n",
        "    if in_one_figure:\n",
        "        plt.figure(figsize=figsize)\n",
        "    index = 0\n",
        "    plots=[]\n",
        "    plot_tags=[]\n",
        "    for d in dicts:       \n",
        "        if type(d)!=dict or not(DATA_DICT in d) or type(d[DATA_DICT])!=dict or len(d[DATA_DICT].items())==0:\n",
        "            continue\n",
        "        tp(d)\n",
        "        tp(d[DATA_DICT])\n",
        "        tp(d[DATA_DICT].keys())\n",
        "        tp(d[DATA_DICT].values())\n",
        "        plt.plot(d[DATA_DICT].keys(), d[DATA_DICT].values(),color=d[COLOR],label=d[Y_LABEL])  \n",
        "        \n",
        "        if not in_one_figure:\n",
        "            if X_LABEL in d:\n",
        "                plt.xlabel(d[X_LABEL])\n",
        "            if Y_LABEL in d:\n",
        "                plt.ylabel(d[Y_LABEL])\n",
        "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=0,ncol=3, borderaxespad=0.)\n",
        "\n",
        "def show_dict(d,figsize=(12,9),color='blue',y_label='Y'):\n",
        "    tmp_d=dict()\n",
        "    tmp_d[DATA_DICT]=d\n",
        "    tmp_d[COLOR]=color\n",
        "    tmp_d[Y_LABEL]=y_label\n",
        "    dicts=[0]\n",
        "    dicts[0]=tmp_d\n",
        "    show_dicts(dicts,figsize=figsize)\n",
        "    \n",
        "def draw_axis(x_from,x_to,y_from,y_to):\n",
        "    color='black'\n",
        "    linewidth=0.5    \n",
        "    plt.vlines(0,y_to,y_from,color = color, linewidth = linewidth)\n",
        "    plt.hlines(0,x_from,x_to,color = color, linewidth = linewidth)\n",
        "\n",
        "def init_func_dicts(n):\n",
        "    y=list(range(n))\n",
        "    for i in range(n):\n",
        "        y[i]=dict()\n",
        "        y[i][DATA_DICT]=dict()\n",
        "    return y\n",
        "\n",
        "def TEST_show_fun():\n",
        "    y = init_func_dicts(5)\n",
        "    for x in np.linspace(-0.5,0.999,100):\n",
        "        y[0][DATA_DICT][x] = -np.log(1 - x)\n",
        "    y[0][COLOR] = 'red'\n",
        "    y[0][Y_LABEL] = 'y=-np.log(1-x)'\n",
        "    for x in np.linspace(0.001,1.5,100):\n",
        "        y[1][DATA_DICT][x] = -np.log(x)\n",
        "    y[1][COLOR] = 'blue'\n",
        "    y[1][Y_LABEL] = 'y=-np.log(x)'\n",
        "\n",
        "    show_dicts(y,figsize=(7,4))\n",
        "    aux_color = 'black'\n",
        "    aux_linewidth = 0.5\n",
        "    aux_linestyle = '-.'\n",
        "    draw_axis(-0.5,1.5,-1,7)\n",
        "    plt.vlines(1,-0.5,7,color = aux_color, linewidth = aux_linewidth, linestyle=aux_linestyle)\n",
        "    plt.annotate(\"x=1\",(1,-0.5),xytext=(0.95,-1))\n",
        "    plt.show()\n",
        "\n",
        "    y = init_func_dicts(5)\n",
        "    x_from = -7\n",
        "    x_to = 7\n",
        "    for x in np.linspace(x_from,x_to,1000):\n",
        "        y[0][DATA_DICT][x] = 1 / (1 + np.exp(-x))\n",
        "    y[0][COLOR] = 'green'\n",
        "    y[0][Y_LABEL] = 'sigmoid(x)=1/(1+exp(-x))'\n",
        "    show_dicts([y[0]],figsize=(7,4),in_one_figure=True)\n",
        "    draw_axis(x_from,x_to,-0.5,1.5)\n",
        "    plt.hlines(1,x_from,x_to,color = aux_color, linewidth = aux_linewidth, linestyle=aux_linestyle)\n",
        "    plt.annotate(\"y=1\",(-5,1) ,xytext=(-6.5,0.9))\n",
        "    plt.show()\n",
        "\n",
        "if IDE == 'JUPYTER' or IDE=='colab':\n",
        "    TEST_show_fun()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'dict'>\t-\td = {'data_dict': {-0.5: -0.4054651081081644, -0.4848585858585859: -0.3953195393420964, -0.4697171717171717: -0.3850699820869533, -0.4545757575757576: -0.3747142825577332, -0.4394343434343434: -0.36425021935559393, -0.4242929292929293: -0.35367550060775993, -0.40915151515151515: -0.3429877609545827, -0.39401010101010103: -0.3321845583738449, -0.37886868686868685: -0.32126337083164735, -0.3637272727272727: -0.3102215927483827, -0.34858585858585855: -0.29905653126741366, -0.33344444444444443: -0.2877654023130849, -0.3183030303030303: -0.2763453264236347, -0.30316161616161613: -0.2647933243434019, -0.288020202020202: -0.25310631235745024, -0.27287878787878783: -0.2412810973503303, -0.2577373737373737: -0.22931437156917328, -0.2425959595959596: -0.21720270706962835, -0.2274545454545454: -0.2049425498213081, -0.2123131313131313: -0.19253021344739008, -0.1971717171717171: -0.1799618725707745, -0.182030303030303: -0.16723355573675672, -0.16688888888888886: -0.15434113787944814, -0.1517474747474747: -0.14128033229619136, -0.13660606060606056: -0.1280466820908985, -0.12146464646464644: -0.11463555104357608, -0.10632323232323226: -0.10104211385923084, -0.09118181818181814: -0.08726134574483699, -0.07604040404040402: -0.07328801125802459, -0.06089898989898984: -0.0591166523655555, -0.04575757575757572: -0.044741575643431716, -0.03061616161616154: -0.030156838543504035, -0.015474747474747419: -0.015356234643682787, -0.0003333333333332966: -0.0003332777901203345, 0.014808080808080826: 0.014918814970042889, 0.02994949494949506: 0.03040714177777476, 0.04509090909090918: 0.046139135797875576, 0.060232323232323304: 0.062122586640080996, 0.07537373737373743: 0.07836566352006938, 0.09051515151515155: 0.09487694033276581, 0.10565656565656578: 0.1116654228305951, 0.1207979797979799: 0.12874057812236703, 0.13593939393939403: 0.14611236673471115, 0.15108080808080815: 0.16379127750791714, 0.16622222222222227: 0.1817883656322959, 0.1813636363636364: 0.20011529417045118, 0.19650505050505063: 0.21878437945599916, 0.21164646464646475: 0.23780864081128897, 0.22678787878787887: 0.25720185508677146, 0.241929292929293: 0.27697861659425677, 0.2570707070707071: 0.29715440308714347, 0.27221212121212135: 0.31774564853485443, 0.28735353535353547: 0.33876982354871044, 0.3024949494949496: 0.36024552444537555, 0.3176363636363637: 0.3821925720855416, 0.33277777777777784: 0.4046321218042726, 0.34791919191919196: 0.42758678596101396, 0.3630606060606062: 0.4510807708886375, 0.3782020202020203: 0.47514003032065844, 0.39334343434343444: 0.49979243773466897, 0.40848484848484856: 0.5250679804815339, 0.4236262626262627: 0.5509989790909572, 0.4387676767676769: 0.5776203357760976, 0.45390909090909104: 0.6049698169303465, 0.46905050505050516: 0.6330883753531985, 0.4841919191919193: 0.6620205191045279, 0.4993333333333334: 0.6918147353261669, 0.5144747474747475: 0.7225239791631367, 0.5296161616161617: 0.7542062401651556, 0.5447575757575758: 0.7869252013861937, 0.5598989898989901: 0.8207510100052396, 0.5750404040404042: 0.8557611829073632, 0.5901818181818184: 0.8920416766208411, 0.6053232323232325: 0.9296881587582174, 0.6204646464646466: 0.9688075282894831, 0.6356060606060607: 1.0095197454746556, 0.6507474747474749: 1.0519600503700601, 0.665888888888889: 1.0962816733298277, 0.6810303030303031: 1.1426591745348933, 0.6961717171717172: 1.1912925962864187, 0.7113131313131316: 1.2424126776328694, 0.7264545454545457: 1.2962874751504632, 0.7415959595959598: 1.3532308709573893, 0.7567373737373739: 1.4136136527363938, 0.771878787878788: 1.4778781591834025, 0.7870202020202022: 1.5465579629360675, 0.8021616161616163: 1.620304824835988, 0.8173030303030304: 1.6999264019592124, 0.8324444444444445: 1.7864403077504556, 0.8475858585858587: 1.881153848603076, 0.8627272727272728: 1.985785621971538, 0.8778686868686871: 2.1026584759424822, 0.8930101010101013: 2.23502085093994, 0.9081515151515154: 2.3876149633908166, 0.9232929292929295: 2.567761388324982, 0.9384343434343436: 2.787651087201358, 0.9535757575757577: 3.069933490148084, 0.9687171717171719: 3.464685949143529, 0.983858585858586: 4.126367002790515, 0.999: 6.907755278982136}, 'color': 'red', 'y': 'y=-np.log(1-x)'}\n",
            "\n",
            "<class 'dict'>\t-\td[DATA_DICT] = {-0.5: -0.4054651081081644, -0.4848585858585859: -0.3953195393420964, -0.4697171717171717: -0.3850699820869533, -0.4545757575757576: -0.3747142825577332, -0.4394343434343434: -0.36425021935559393, -0.4242929292929293: -0.35367550060775993, -0.40915151515151515: -0.3429877609545827, -0.39401010101010103: -0.3321845583738449, -0.37886868686868685: -0.32126337083164735, -0.3637272727272727: -0.3102215927483827, -0.34858585858585855: -0.29905653126741366, -0.33344444444444443: -0.2877654023130849, -0.3183030303030303: -0.2763453264236347, -0.30316161616161613: -0.2647933243434019, -0.288020202020202: -0.25310631235745024, -0.27287878787878783: -0.2412810973503303, -0.2577373737373737: -0.22931437156917328, -0.2425959595959596: -0.21720270706962835, -0.2274545454545454: -0.2049425498213081, -0.2123131313131313: -0.19253021344739008, -0.1971717171717171: -0.1799618725707745, -0.182030303030303: -0.16723355573675672, -0.16688888888888886: -0.15434113787944814, -0.1517474747474747: -0.14128033229619136, -0.13660606060606056: -0.1280466820908985, -0.12146464646464644: -0.11463555104357608, -0.10632323232323226: -0.10104211385923084, -0.09118181818181814: -0.08726134574483699, -0.07604040404040402: -0.07328801125802459, -0.06089898989898984: -0.0591166523655555, -0.04575757575757572: -0.044741575643431716, -0.03061616161616154: -0.030156838543504035, -0.015474747474747419: -0.015356234643682787, -0.0003333333333332966: -0.0003332777901203345, 0.014808080808080826: 0.014918814970042889, 0.02994949494949506: 0.03040714177777476, 0.04509090909090918: 0.046139135797875576, 0.060232323232323304: 0.062122586640080996, 0.07537373737373743: 0.07836566352006938, 0.09051515151515155: 0.09487694033276581, 0.10565656565656578: 0.1116654228305951, 0.1207979797979799: 0.12874057812236703, 0.13593939393939403: 0.14611236673471115, 0.15108080808080815: 0.16379127750791714, 0.16622222222222227: 0.1817883656322959, 0.1813636363636364: 0.20011529417045118, 0.19650505050505063: 0.21878437945599916, 0.21164646464646475: 0.23780864081128897, 0.22678787878787887: 0.25720185508677146, 0.241929292929293: 0.27697861659425677, 0.2570707070707071: 0.29715440308714347, 0.27221212121212135: 0.31774564853485443, 0.28735353535353547: 0.33876982354871044, 0.3024949494949496: 0.36024552444537555, 0.3176363636363637: 0.3821925720855416, 0.33277777777777784: 0.4046321218042726, 0.34791919191919196: 0.42758678596101396, 0.3630606060606062: 0.4510807708886375, 0.3782020202020203: 0.47514003032065844, 0.39334343434343444: 0.49979243773466897, 0.40848484848484856: 0.5250679804815339, 0.4236262626262627: 0.5509989790909572, 0.4387676767676769: 0.5776203357760976, 0.45390909090909104: 0.6049698169303465, 0.46905050505050516: 0.6330883753531985, 0.4841919191919193: 0.6620205191045279, 0.4993333333333334: 0.6918147353261669, 0.5144747474747475: 0.7225239791631367, 0.5296161616161617: 0.7542062401651556, 0.5447575757575758: 0.7869252013861937, 0.5598989898989901: 0.8207510100052396, 0.5750404040404042: 0.8557611829073632, 0.5901818181818184: 0.8920416766208411, 0.6053232323232325: 0.9296881587582174, 0.6204646464646466: 0.9688075282894831, 0.6356060606060607: 1.0095197454746556, 0.6507474747474749: 1.0519600503700601, 0.665888888888889: 1.0962816733298277, 0.6810303030303031: 1.1426591745348933, 0.6961717171717172: 1.1912925962864187, 0.7113131313131316: 1.2424126776328694, 0.7264545454545457: 1.2962874751504632, 0.7415959595959598: 1.3532308709573893, 0.7567373737373739: 1.4136136527363938, 0.771878787878788: 1.4778781591834025, 0.7870202020202022: 1.5465579629360675, 0.8021616161616163: 1.620304824835988, 0.8173030303030304: 1.6999264019592124, 0.8324444444444445: 1.7864403077504556, 0.8475858585858587: 1.881153848603076, 0.8627272727272728: 1.985785621971538, 0.8778686868686871: 2.1026584759424822, 0.8930101010101013: 2.23502085093994, 0.9081515151515154: 2.3876149633908166, 0.9232929292929295: 2.567761388324982, 0.9384343434343436: 2.787651087201358, 0.9535757575757577: 3.069933490148084, 0.9687171717171719: 3.464685949143529, 0.983858585858586: 4.126367002790515, 0.999: 6.907755278982136}\n",
            "\n",
            "<class 'dict_keys'>\t-\td[DATA_DICT].keys() = dict_keys([-0.5, -0.4848585858585859, -0.4697171717171717, -0.4545757575757576, -0.4394343434343434, -0.4242929292929293, -0.40915151515151515, -0.39401010101010103, -0.37886868686868685, -0.3637272727272727, -0.34858585858585855, -0.33344444444444443, -0.3183030303030303, -0.30316161616161613, -0.288020202020202, -0.27287878787878783, -0.2577373737373737, -0.2425959595959596, -0.2274545454545454, -0.2123131313131313, -0.1971717171717171, -0.182030303030303, -0.16688888888888886, -0.1517474747474747, -0.13660606060606056, -0.12146464646464644, -0.10632323232323226, -0.09118181818181814, -0.07604040404040402, -0.06089898989898984, -0.04575757575757572, -0.03061616161616154, -0.015474747474747419, -0.0003333333333332966, 0.014808080808080826, 0.02994949494949506, 0.04509090909090918, 0.060232323232323304, 0.07537373737373743, 0.09051515151515155, 0.10565656565656578, 0.1207979797979799, 0.13593939393939403, 0.15108080808080815, 0.16622222222222227, 0.1813636363636364, 0.19650505050505063, 0.21164646464646475, 0.22678787878787887, 0.241929292929293, 0.2570707070707071, 0.27221212121212135, 0.28735353535353547, 0.3024949494949496, 0.3176363636363637, 0.33277777777777784, 0.34791919191919196, 0.3630606060606062, 0.3782020202020203, 0.39334343434343444, 0.40848484848484856, 0.4236262626262627, 0.4387676767676769, 0.45390909090909104, 0.46905050505050516, 0.4841919191919193, 0.4993333333333334, 0.5144747474747475, 0.5296161616161617, 0.5447575757575758, 0.5598989898989901, 0.5750404040404042, 0.5901818181818184, 0.6053232323232325, 0.6204646464646466, 0.6356060606060607, 0.6507474747474749, 0.665888888888889, 0.6810303030303031, 0.6961717171717172, 0.7113131313131316, 0.7264545454545457, 0.7415959595959598, 0.7567373737373739, 0.771878787878788, 0.7870202020202022, 0.8021616161616163, 0.8173030303030304, 0.8324444444444445, 0.8475858585858587, 0.8627272727272728, 0.8778686868686871, 0.8930101010101013, 0.9081515151515154, 0.9232929292929295, 0.9384343434343436, 0.9535757575757577, 0.9687171717171719, 0.983858585858586, 0.999])\n",
            "\n",
            "<class 'dict_values'>\t-\td[DATA_DICT].values() = dict_values([-0.4054651081081644, -0.3953195393420964, -0.3850699820869533, -0.3747142825577332, -0.36425021935559393, -0.35367550060775993, -0.3429877609545827, -0.3321845583738449, -0.32126337083164735, -0.3102215927483827, -0.29905653126741366, -0.2877654023130849, -0.2763453264236347, -0.2647933243434019, -0.25310631235745024, -0.2412810973503303, -0.22931437156917328, -0.21720270706962835, -0.2049425498213081, -0.19253021344739008, -0.1799618725707745, -0.16723355573675672, -0.15434113787944814, -0.14128033229619136, -0.1280466820908985, -0.11463555104357608, -0.10104211385923084, -0.08726134574483699, -0.07328801125802459, -0.0591166523655555, -0.044741575643431716, -0.030156838543504035, -0.015356234643682787, -0.0003332777901203345, 0.014918814970042889, 0.03040714177777476, 0.046139135797875576, 0.062122586640080996, 0.07836566352006938, 0.09487694033276581, 0.1116654228305951, 0.12874057812236703, 0.14611236673471115, 0.16379127750791714, 0.1817883656322959, 0.20011529417045118, 0.21878437945599916, 0.23780864081128897, 0.25720185508677146, 0.27697861659425677, 0.29715440308714347, 0.31774564853485443, 0.33876982354871044, 0.36024552444537555, 0.3821925720855416, 0.4046321218042726, 0.42758678596101396, 0.4510807708886375, 0.47514003032065844, 0.49979243773466897, 0.5250679804815339, 0.5509989790909572, 0.5776203357760976, 0.6049698169303465, 0.6330883753531985, 0.6620205191045279, 0.6918147353261669, 0.7225239791631367, 0.7542062401651556, 0.7869252013861937, 0.8207510100052396, 0.8557611829073632, 0.8920416766208411, 0.9296881587582174, 0.9688075282894831, 1.0095197454746556, 1.0519600503700601, 1.0962816733298277, 1.1426591745348933, 1.1912925962864187, 1.2424126776328694, 1.2962874751504632, 1.3532308709573893, 1.4136136527363938, 1.4778781591834025, 1.5465579629360675, 1.620304824835988, 1.6999264019592124, 1.7864403077504556, 1.881153848603076, 1.985785621971538, 2.1026584759424822, 2.23502085093994, 2.3876149633908166, 2.567761388324982, 2.787651087201358, 3.069933490148084, 3.464685949143529, 4.126367002790515, 6.907755278982136])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-01dc36612a55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mIDE\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'JUPYTER'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mIDE\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'colab'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m     \u001b[0mTEST_show_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-01dc36612a55>\u001b[0m in \u001b[0;36mTEST_show_fun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_LABEL\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'y=-np.log(x)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mshow_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0maux_color\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'black'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0maux_linewidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-01dc36612a55>\u001b[0m in \u001b[0;36mshow_dicts\u001b[0;34m(dicts, figsize, in_one_figure)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_DICT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_DICT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_DICT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_DICT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCOLOR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_LABEL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_one_figure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_autoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1848\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1870\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \"\"\"\n\u001b[0;32m-> 1872\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \"\"\"\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mxconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_xunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict_keys'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbMAAAD8CAYAAAD9lEqKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb-4szmhDJzK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=np.array([1,2,3])\n",
        "tp(a*a)\n",
        "b=np.array([[1,2,3],[3,4,5]])\n",
        "# ma_1=np.mat([1,2,3])\n",
        "# tp(ma_1)\n",
        "# tp(ma_1[0,2])\n",
        "# ma=np.mat(a).T\n",
        "# mb=np.mat(b[1]).T\n",
        "# tp(ma)\n",
        "# tp(mb)\n",
        "# tp(ma/mb)\n",
        "\n",
        "# ya = np.mat(b[:,2])\n",
        "# tp(np.mat(b))\n",
        "\n",
        "tp(b)\n",
        "tp(np.mat(b[:,1]))\n",
        "mb=np.mat(b)\n",
        "tp(mb)\n",
        "tp(np.mat(mb[:,1]))\n",
        "# df_dev_dx = np.zeros([2,3])\n",
        "# tp(df_dev_dx)\n",
        "# tp(ma**2)#矩阵乘幂\n",
        "# tp(a)\n",
        "# tp(a*a)\n",
        "# tp(a.T*a)\n",
        "# tp(ma)\n",
        "# tp(np.array(ma))\n",
        "# tp(np.array(ma.tolist()))\n",
        "# c=np.array(ma.tolist())\n",
        "# tp(c)\n",
        "# tp(c*c)\n",
        "# tp(c.T*c)\n",
        "# tp(c*c.T)\n",
        "# tp(c.T.dot(c))\n",
        "# tp(c.dot(c.T))\n",
        "\n",
        "# tp(mb)\n",
        "# tp(np.diag(ma*mb.T))\n",
        "# tp(np.array(ma))\n",
        "# tp(np.array(mb).T)\n",
        "# tp((np.array(ma)*np.array(mb).T))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYVoC7odDJzN",
        "colab_type": "text"
      },
      "source": [
        "## 函数求导"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWKNmb7rDJzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "45d1879f-0dd9-4768-9ead-792a0018b796"
      },
      "source": [
        "\n",
        "# 计算损失函数求导\n",
        "# from sympy import *\n",
        "import sympy as sy\n",
        "\n",
        "def sigmoid_sy(x):\n",
        "    y = 1 / (1 + sy.exp(-x))\n",
        "    return y\n",
        "\n",
        "def sigmoid_diff(x):\n",
        "    f = sigmoid(x)\n",
        "    diff = f - f * f\n",
        "    return diff\n",
        "\n",
        "# def covert_sigle_to_array(x):\n",
        "#     '''将单个数转换成矩阵形式'''\n",
        "#     x = np.array(x)\n",
        "#     if len(x.shape)==0:\n",
        "#         x=np.array([x])\n",
        "#     return x\n",
        "\n",
        "x = sy.symbols(\"x\")  # 符号x，自变量\n",
        "y = x ** 2 + 3 * x\n",
        "dify = sy.diff(y,x) #求导\n",
        "# print(dify) #打印导数#给定x值，求对应导数的值\n",
        "                # print(dify.subs('x',1))\n",
        "z = sy.symbols('z')\n",
        "y = sy.symbols('y')\n",
        "L = sy.symbols('L')\n",
        "\n",
        "L = -y * sy.log(sigmoid_sy(z)) - (1 - y) * (sy.log(1 - sigmoid_sy(z)))\n",
        "dL_python = sy.diff(L,z)\n",
        "\n",
        "tp(L)\n",
        "tp(sy.diff(L,z))\n",
        "\n",
        "# dL_alan=-y*(1-sigmoid(z))+(1-y)*sigmoid(z)\n",
        "\n",
        "z0=0.7\n",
        "y0=1\n",
        "\n",
        "z1 = np.mat([0.7,0.2,0.5]).T\n",
        "y1 = np.mat([1,0,1]).T\n",
        "\n",
        "z2 = np.mat([[0.7,0.2,0.5],[0.6,0.3,0.8]]).T\n",
        "y2 = np.mat([[1,0,1],[1,1,0]]).T\n",
        "\n",
        "tags_print(z0=z0,y0=y0,z1=z1,y1=y1,z2=z2,y2=y2)\n",
        "\n",
        "def multiply_pow(a,n):\n",
        "    a=np.mat(a)\n",
        "    r=1\n",
        "    for i in range(abs(n)):\n",
        "        r = np.multiply(r, a)\n",
        "    if n<0:\n",
        "        r=1/r\n",
        "    return r\n",
        "\n",
        "# tp(multiply_pow([1,2,3],3))\n",
        "    \n",
        "def dLdz_py(y,z):\n",
        "    y=np.mat(y)\n",
        "    z=np.mat(z)\n",
        "    r = np.multiply(-y, np.exp(-z)/(1 + np.exp(-z))) \\\n",
        "        + np.multiply(1-y, \\\n",
        "                       np.exp(-z)/(np.multiply(1 - 1/(1 + np.exp(-z)), \\\n",
        "                                            multiply_pow(1 + np.exp(-z), 2))))\n",
        "#     -y*exp(-z)/(1 + exp(-z)) \\\n",
        "#         + (-y + 1) * \\\n",
        "#             exp(-z) / \\\n",
        "#                 ((1 - 1/(1 + exp(-z))) * (1 + exp(-z))**2)\n",
        "    return r\n",
        "\n",
        "def dLdz_alan(y,z):\n",
        "    y=np.mat(y)\n",
        "    z=np.mat(z)\n",
        "    dldz = np.multiply(-y, 1 - sigmoid(z)) + np.multiply(1 - y, sigmoid(z))\n",
        "    return dldz\n",
        "\n",
        "def Loss(y,z, get_average=False):\n",
        "    y = np.mat(y)\n",
        "    z = np.mat(z)\n",
        "    a = sigmoid(z)    \n",
        "    r = -y.T * (np.log(sigmoid(z))) - (1 - y.T) * (np.log(1 - sigmoid(z)))\n",
        "    if get_average:\n",
        "        r=np.average(r)\n",
        "    return r\n",
        "\n",
        "tag_print(Loss(y0,z0))\n",
        "tag_print(L.subs(y,y0).subs(z,z0))\n",
        "          \n",
        "tag_print(Loss(y1,z1))\n",
        "\n",
        "\n",
        "def dydz(f, x, rate,need_print=False): \n",
        "    '''通过[f(x1)-f(x1+delta)]/delta (delta为微量，一般取 0.0001*x1 或更小)这种近似方式求f在x1处的导数，以验证求导公式'''\n",
        "    \n",
        "    # x是自变量组成的向量或矩阵(一个样本的输入x构成一个列向量；\n",
        "    # 多个样本的输入构成一个矩阵，其中一列表示一个样本的输入)\n",
        "    x = np.mat(x)\n",
        "    f1 = f(x)\n",
        "    if need_print:\n",
        "        tps(x=x,f1=f1)\n",
        "\n",
        "    row = x.shape[0]\n",
        "    col = x.shape[1]\n",
        "    df_dev_dx = np.zeros([row,col])\n",
        "    for j in range(col):# x的每一列代表一个样本的输入，此处按列逐样本计算损失函数对自变量的导数\n",
        "        \n",
        "        # 列向量的每个元素是一个未知数，通过(f2-f1)/(x2-x1)这种方式近似计算f在x1处的导数，\n",
        "        # 一次只能计算f对一个自变量的导数 (因为f是多个自变量的函数，如果多个自变量同时变化，\n",
        "        # 则没法区分出f的变化与具体某个变量的关系)。所以需要逐变量(此处为列向量中的每一行)计算近似导数\n",
        "        for i in range(row):\n",
        "            if need_print:                \n",
        "                print('\\nBefore df_dev_dx.i,j=[{i},{j}]\\n'.format(i=i,j=j))\n",
        "            x1=np.mat(x[:,j]);# 列向量矩阵\n",
        "            if need_print:\n",
        "                tp(x1)\n",
        "            x2 = copy.deepcopy(x1)\n",
        "            if need_print:                                \n",
        "                tp(x2)\n",
        "            x2[i,0] = x2[i, 0] * (1 + rate)\n",
        "            f2 = f(x2, col = j)# x的每一列代表一个样本的输入，此处逐样本计算损失函数，所以只需输入其中一列即可\n",
        "            df = f2[0,0] - f1[j,0]\n",
        "            dx = x2 - x1\n",
        "            if need_print:                                \n",
        "                tps(x2=x2,f2=f2,df=df,dx=dx)\n",
        "            df_dev_dx[i, j] = (df / dx[i,0])\n",
        "            if need_print:                \n",
        "                tps(df_dev_dx=df_dev_dx)                \n",
        "    return np.mat(df_dev_dx)\n",
        "    \n",
        "    \n",
        "def fun_loss(y, need_print=False):        \n",
        "    def loss(z, col=-1):\n",
        "        ya=np.mat(y)\n",
        "        if need_print:\n",
        "            tp(ya,memo='in loss()')\n",
        "        if col>=0:\n",
        "            ya = np.mat(ya[:,col])\n",
        "            if need_print:\n",
        "                tp(ya,memo='in loss() after ya = np.mat(ya[:,col])')\n",
        "        z = np.mat(z)\n",
        "        a = sigmoid(z)   \n",
        "        r = -ya.T * (np.log(a)) - (1 - ya.T) * (np.log(1 - a))\n",
        "        r_diag = np.mat(np.diag(r)).T\n",
        "        return r_diag\n",
        "    return loss\n",
        "\n",
        "rate = 0.000001\n",
        "\n",
        "\n",
        "print('\\n------------- y2 z2 -------------')\n",
        "tp(dLdz_py(y2,z2))\n",
        "tp(dLdz_alan(y2,z2))\n",
        "tp(dydz(fun_loss(y2,need_print=False),z2,rate,need_print=False), tag='dydz(fun_loss(y2),z2,rate)')\n",
        "\n",
        "\n",
        "print('\\n------------- y1 z1 -------------')\n",
        "tp(dLdz_py(y1,z1))\n",
        "tp(dLdz_alan(y1,z1))\n",
        "tp(dLdz_alan(y2[:,1],z2[:,1]), tag='dLdz_alan(y2[:,1]),z2[:,1])')\n",
        "tp(dydz(fun_loss(y1),z1,rate), tag='dydz(fun_loss(y1),z1,rate)')\n",
        "tp(dydz(fun_loss(y2[:,1]),z2[:,1],rate), tag='dydz(fun_loss(y2[:,1]),z2[:,1],rate)')\n",
        "\n",
        "print('\\n------------- y0 z0 -------------')\n",
        "tp(dLdz_py(y0,z0))\n",
        "tp(dLdz_alan(y0,z0))\n",
        "tp(dydz(fun_loss(y0),z0,rate))\n",
        "\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'sympy.core.add.Add'>\t-\tL = -y*log(1/(1 + exp(-z))) - (-y + 1)*log(1 - 1/(1 + exp(-z)))\n",
            "\n",
            "<class 'sympy.core.add.Add'>\t-\tsy.diff(L,z) = -y*exp(-z)/(1 + exp(-z)) + (-y + 1)*exp(-z)/((1 - 1/(1 + exp(-z)))*(1 + exp(-z))**2)\n",
            "\n",
            "<class 'float'>\t-\tz0 = 0.7\n",
            "\n",
            "<class 'int'>\t-\ty0 = 1\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tz1 = \n",
            "[[0.7]\n",
            " [0.2]\n",
            " [0.5]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\ty1 = \n",
            "[[1]\n",
            " [0]\n",
            " [1]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tz2 = \n",
            "[[0.7 0.6]\n",
            " [0.2 0.3]\n",
            " [0.5 0.8]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\ty2 = \n",
            "[[1 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tLoss(y0,z0) = [[0.40318605]]\n",
            "\n",
            "<class 'sympy.core.numbers.Float'>\t-\tL.subs(y,y0) = 0.403186048885458\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tLoss(y1,z1) = [[1.6754019]]\n",
            "\n",
            "------------- y2 z2 -------------\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdLdz_py(y2,z2) = \n",
            "[[-0.33181223 -0.35434369]\n",
            " [ 0.549834   -0.42555748]\n",
            " [-0.37754067  0.68997448]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdLdz_alan(y2,z2) = \n",
            "[[-0.33181223 -0.35434369]\n",
            " [ 0.549834   -0.42555748]\n",
            " [-0.37754067  0.68997448]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdydz(fun_loss(y2),z2,rate) = \n",
            "[[-0.33181215 -0.35434363]\n",
            " [ 0.54983402 -0.42555745]\n",
            " [-0.37754061  0.68997457]]\n",
            "\n",
            "------------- y1 z1 -------------\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdLdz_py(y1,z1) = \n",
            "[[-0.33181223]\n",
            " [ 0.549834  ]\n",
            " [-0.37754067]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdLdz_alan(y1,z1) = \n",
            "[[-0.33181223]\n",
            " [ 0.549834  ]\n",
            " [-0.37754067]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdLdz_alan(y2[:,1]),z2[:,1]) = \n",
            "[[-0.35434369]\n",
            " [-0.42555748]\n",
            " [ 0.68997448]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdydz(fun_loss(y1),z1,rate) = \n",
            "[[-0.33181215]\n",
            " [ 0.54983402]\n",
            " [-0.37754061]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdydz(fun_loss(y2[:,1]),z2[:,1],rate) = \n",
            "[[-0.35434363]\n",
            " [-0.42555745]\n",
            " [ 0.68997457]]\n",
            "\n",
            "------------- y0 z0 -------------\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tdLdz_py(y0,z0) = [[-0.33181223]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tdLdz_alan(y0,z0) = [[-0.33181223]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tdydz(fun_loss(y0)) = [[-0.33181215]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxXRS6j7DJzR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=np.array([[1,2],[3,4]])\n",
        "tag_print(a.dot(a))\n",
        "tag_print(a[1]*a[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_JBPpFCDJzT",
        "colab_type": "text"
      },
      "source": [
        "## BP反向推导算法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQEXpqToDJzU",
        "colab_type": "text"
      },
      "source": [
        "### FP前向推导"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56nS2yNGDJzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d75ecc9d-095c-4bd5-fd11-889b15695726"
      },
      "source": [
        "\n",
        "   \n",
        "def gene_input_data(sample_count, x_size, y_size, x_min=10, x_max=99, y_min=0, y_max=1):\n",
        "    x=np.mat(np.random.randint(x_min,x_max+1,(sample_count,x_size)))\n",
        "    y=np.mat(np.random.randint(y_min,y_max+1,(sample_count,y_size)))\n",
        "    return x,y\n",
        "\n",
        "\n",
        "def gene_rand_w(nn_struct): \n",
        "    w_n=len(nn_struct)-1\n",
        "    weights=list(range(0,w_n))\n",
        "    for i in range(0,w_n):\n",
        "        weights[i]=np.mat(np.random.rand(nn_struct[i+1],nn_struct[i]))\n",
        "    return weights\n",
        "\n",
        "def nn_fp(input_x, n, w, need_print=False):    \n",
        "    z=list(range(0,n))\n",
        "    a=list(range(0,n))\n",
        "    z[0]=copy.deepcopy(input_x)    \n",
        "    a[0]=copy.deepcopy(input_x)\n",
        "    if need_print:\n",
        "        tag_print(z[0])\n",
        "        tag_print(a[0])\n",
        "    for i in range(1,n):\n",
        "        z[i]=w[i-1] * (a[i-1])\n",
        "        a[i]=sigmoid(z[i])        \n",
        "        if need_print:\n",
        "            print('\\n--------- i = {i}---------'.format(i=i))\n",
        "            tag_print(w[i-1],tag='w[{i}]'.format(i=i-1))\n",
        "            tag_print(a[i-1],tag='a[{i}]'.format(i=i-1))\n",
        "            tag_print(z[i],tag='z[{i}]'.format(i=i))\n",
        "            tag_print(a[i],tag='a[{i}]'.format(i=i))\n",
        "    return z,a;\n",
        "\n",
        "def get_data(data,row_from,row_cnt):\n",
        "    return (np.mat(data)[row_from:row_from+row_cnt, :]).T\n",
        "\n",
        "def show_list(the_list):\n",
        "    tag = getVarName(the_list,level=2)\n",
        "    for i in range(len(the_list)):\n",
        "        tp(the_list[i],tag='{tag}[{i}]'.format(tag=tag, i=i))\n",
        "    return\n",
        "\n",
        "sample_count=2\n",
        "x_size=3\n",
        "y_size=2\n",
        "data_x,data_y=gene_input_data(sample_count=sample_count, x_size=x_size, y_size=y_size, x_min=10,x_max=12)\n",
        "tps(data_x=data_x, data_y=data_y)\n",
        "        \n",
        "nn_node_of_layels=np.array([data_x.shape[1],4,2,data_y.shape[0]])\n",
        "nn_layels_count=len(nn_node_of_layels)\n",
        "tp(nn_node_of_layels)\n",
        "\n",
        "sample_from=0\n",
        "sample_cnt=sample_count\n",
        "x_in=get_data(data_x,sample_from,sample_cnt)\n",
        "y_in=get_data(data_y,sample_from,sample_cnt)\n",
        "weights=gene_rand_w(nn_node_of_layels)\n",
        "if False:\n",
        "    show_list(weights)\n",
        "    tps(x_in=x_in,y_in=y_in)\n",
        "z,a=nn_fp(input_x=x_in, n=nn_layels_count, w=weights, need_print=False);\n",
        "if False:\n",
        "    show_list(z)\n",
        "    show_list(a)\n"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'numpy.matrix'>\t(2, 3)\tdata_x = \n",
            "[[11 12 11]\n",
            " [11 10 10]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tdata_y = \n",
            "[[0 1]\n",
            " [0 0]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(4,)\tnn_node_of_layels = [3 4 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k__X4-0DDJzi",
        "colab_type": "text"
      },
      "source": [
        "### BP算法相关公式\n",
        "\n",
        "为便于书写，下列公式均按照神经网络从1层开始编号，输出层为n层，与程序代码中0至n-1编号略有不同\n",
        "\n",
        "${{\\bf{\\delta }}^{(n)}} = \\frac{{d\\,{\\mathop{\\rm Loss}\\nolimits} }}{{d{{\\bf{z}}^{(n)}}}} =  - {\\bf{y}} \\circ (1 - {\\mathop{\\rm sigmoid}\\nolimits} {{\\bf{z}}^{(n)}}) + (1 - {\\bf{y}}) \\circ {\\mathop{\\rm sigmoid}\\nolimits} {{\\bf{z}}^{(n)}}$\n",
        "\n",
        "${{\\mathbf{\\delta }}^{(i)}}=[f({{\\mathbf{z}}^{(i)}})-{{f}^{2}}({{\\mathbf{z}}^{(i)}})]\\circ {{[{{({{\\mathbf{\\delta }}^{(i+1)}})}^{\\operatorname{T}}}{{\\mathbf{W}}^{(i)}}]}^{\\operatorname{T}}}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial {{\\mathbf{W}}^{(i)}}}=\\left[ \\begin{matrix}\n",
        "   \\frac{\\partial L}{\\partial w_{11}^{(i)}} & \\cdots  & \\frac{\\partial L}{\\partial w_{1{{s}_{i}}}^{(i)}}  \\\\\n",
        "   \\vdots  & \\ddots  & \\vdots   \\\\\n",
        "   \\frac{\\partial L}{\\partial w_{{{s}_{i+1}}1}^{(i)}} & \\cdots  & \\frac{\\partial L}{\\partial w_{{{s}_{i+1}}{{s}_{i}}}^{(i)}}  \\\\\n",
        "\\end{matrix} \\right]=\\left[ \\begin{matrix}\n",
        "   \\delta _{1}^{(i+1)}a_{1}^{(i)} & \\cdots  & \\delta _{1}^{(i+1)}a_{{{s}_{i}}}^{(i)}  \\\\\n",
        "   \\vdots  & \\ddots  & \\vdots   \\\\\n",
        "   \\delta _{{{s}_{i+1}}}^{(i+1)}a_{1}^{(i)} & \\cdots  & \\delta _{{{s}_{i+1}}}^{(i+1)}a_{{{s}_{i}}}^{(i)}  \\\\\n",
        "\\end{matrix} \\right]={{\\mathbf{\\delta }}^{(i+1)}}{{[{{\\mathbf{a}}^{(i)}}]}^{\\operatorname{T}}}\\in \\mathbb{R}({{s}_{i+1}}\\times 1)(1\\times {{s}_{i}})=\\mathbb{R}({{s}_{i+1}}\\times {{s}_{i}})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2oi-YWpDJzi",
        "colab_type": "text"
      },
      "source": [
        "### BP算法代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvIIhFTHDJzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "14a63273-78e9-489b-cdff-38e787eae033"
      },
      "source": [
        "### 函数\n",
        "tp(dLdz_alan(y2,z2))\n",
        "tp(dydz(fun_loss(y2,need_print=False),z2,rate,need_print=False), tag='dydz(fun_loss(y2),z2,rate)')\n",
        "\n",
        "def nn_bp(y, z, a, w, n, learn_rate, need_print=False):    \n",
        "    delta=list(range(0,n)) # 误差因子\n",
        "    dLdw=list(range(0,n-1))\n",
        "    \n",
        "    delta[n-1]=dLdz_alan(y, z[n-1])\n",
        "    if need_print:\n",
        "        tp(delta[n-1],tag='delta[{i}]'.format(i=n-1))\n",
        "    for i in range(n-2,-1,-1): # 相当于 n-2 至 0\n",
        "        # 计算顺序：误差因子delta(i)、损失函数对权重w(i)的偏导数dLdw、按梯度下降法更新w(i)\n",
        "        \n",
        "        if need_print:  \n",
        "            print('\\n\\n')\n",
        "            tps(i=i)\n",
        "            tp(delta[i+1],tag='delta[{i}]'.format(i=i+1))\n",
        "            tp(w[i],tag='w[{i}]'.format(i=i))            \n",
        "        # 误差因子delta(i)\n",
        "        dz  = sigmoid(z[i]) - multiply_pow(sigmoid(z[i]), 2)\n",
        "        delta_multi_w = delta[i+1].T * w[i] # 注意此处不能先更新w，再使用其来计算误差因子\n",
        "        if need_print:            \n",
        "            tp(dz, tag='dz  = sigmoid(z[i]) - multiply_pow(sigmoid(z[i]), 2)')\n",
        "            tp(delta_multi_w, tag= 'delta[i+1].T * w[i]')\n",
        "        delta[i]= np.multiply(dz, delta_multi_w.T)\n",
        "    \n",
        "        if need_print:            \n",
        "            tp(delta[i], tag='delta[i]= np.multiply(dz, delta_multi_w)')\n",
        "        \n",
        "        # 损失函数对权重w(i)的偏导数dLdw\n",
        "        dLdw[i] = delta[i+1] * a[i].T\n",
        "        \n",
        "        # 按梯度下降法更新w(i)\n",
        "        w[i] = w[i] - learn_rate * dLdw[i]\n",
        "        \n",
        "    return w\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "def nn_train(data_x, data_y, nn_node_of_layels, train_steps, learn_rate=0.05, display_times=10, need_print=False):\n",
        "    nn_layels_count=len(nn_node_of_layels)\n",
        "    sample_from = 0\n",
        "    sample_cnt = sample_count\n",
        "    x_in=get_data(data_x, sample_from, sample_cnt)\n",
        "    y_in=get_data(data_y, sample_from, sample_cnt)\n",
        "    weights = gene_rand_w(nn_node_of_layels)\n",
        "    if False:\n",
        "        tps(x_in=x_in,y_in=y_in)\n",
        "    step_loss=dict()\n",
        "    z, a = nn_fp(input_x=x_in, n=nn_layels_count, w=weights, need_print=False);\n",
        "    if False:\n",
        "        tp(z[nn_layels_count-1])\n",
        "    step_loss[0] = Loss(y_in, z[nn_layels_count-1], get_average=True)\n",
        "    for step in range(1, train_steps+1):\n",
        "        weights = nn_bp(y=y_in, z=z, a=a, w=weights, n=nn_layels_count, learn_rate=learn_rate, need_print=False)\n",
        "        z, a = nn_fp(input_x=x_in, w=weights, n=nn_layels_count, need_print=False);\n",
        "        loss = Loss(y_in, z[nn_layels_count-1], get_average=True)\n",
        "        step_loss[step] = loss\n",
        "        \n",
        "        if step % (train_steps/display_times)==0:\n",
        "            tp(step_loss[step],tag='step_loss[{i}]'.format(i=step))\n",
        "        \n",
        "        if False:\n",
        "            show_list(z)\n",
        "            show_list(a)\n",
        "    if need_print:\n",
        "        for step in range(len(step_loss)):\n",
        "            tp(step_loss[step],tag='step_loss[{i}]'.format(i=step))\n",
        "    show_dict(step_loss,y_label='Loss')\n",
        "    if need_print:\n",
        "        tp(step_loss[train_steps])\n",
        "    return step_loss\n",
        "\n",
        "\n",
        "sample_count=50\n",
        "x_size=15\n",
        "y_size=2\n",
        "data_x,data_y = gene_input_data(sample_count=sample_count, x_size=x_size, y_size=y_size, x_min=10,x_max=50)\n",
        "# tps(data_x=data_x, data_y=data_y)\n",
        "        \n",
        "nn_node_of_layels=np.array([data_x.shape[1],10,10,10,data_y.shape[1]])\n",
        "tp(nn_node_of_layels)\n",
        "\n",
        "\n",
        "step_loss = nn_train(data_x = data_x, data_y = data_y, nn_node_of_layels = nn_node_of_layels, train_steps = 60, learn_rate = 0.05, need_print=False)\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdLdz_alan(y2,z2) = \n",
            "[[-0.33181223 -0.35434369]\n",
            " [ 0.549834   -0.42555748]\n",
            " [-0.37754067  0.68997448]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdydz(fun_loss(y2),z2,rate) = \n",
            "[[-0.33181215 -0.35434363]\n",
            " [ 0.54983402 -0.42555745]\n",
            " [-0.37754061  0.68997457]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(5,)\tnn_node_of_layels = [15 10 10 10  2]\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[6] = 4.950531586420082\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[12] = 2.861662089856606\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[18] = 3.3471330554641363\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[24] = 2.4739945204364284\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[30] = 2.1830089164737836\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[36] = 1.4276743384670647\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[42] = 1.3763605000788282\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[48] = 1.3685161947517002\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[54] = 1.3668479748719125\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[60] = 1.3664170478928044\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-87d9f65625d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m \u001b[0mstep_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_node_of_layels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_node_of_layels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearn_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.05\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mneed_print\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-87d9f65625d9>\u001b[0m in \u001b[0;36mnn_train\u001b[0;34m(data_x, data_y, nn_node_of_layels, train_steps, learn_rate, display_times, need_print)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'step_loss[{i}]'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m     \u001b[0mshow_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_loss\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mneed_print\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0mtp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_steps\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-58b04c164835>\u001b[0m in \u001b[0;36mshow_dict\u001b[0;34m(d, figsize, color, y_label)\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mdicts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0mdicts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtmp_d\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m     \u001b[0mshow_dicts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdraw_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_from\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_from\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_to\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-16-58b04c164835>\u001b[0m in \u001b[0;36mshow_dicts\u001b[0;34m(dicts, figsize, in_one_figure)\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDATA_DICT\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_DICT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0mdict\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_DICT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_DICT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mDATA_DICT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCOLOR\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mY_LABEL\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0min_one_figure\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1646\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1647\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1648\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1649\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_request_autoscale_view\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscalex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaley\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscaley\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36madd_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1848\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_clip_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1850\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_line_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1851\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1852\u001b[0m             \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_line%d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_update_line_limits\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m   1870\u001b[0m         \u001b[0mFigures\u001b[0m \u001b[0mout\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mdata\u001b[0m \u001b[0mlimit\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgiven\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdating\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataLim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1871\u001b[0m         \"\"\"\n\u001b[0;32m-> 1872\u001b[0;31m         \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1873\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvertices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1874\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mget_path\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \"\"\"\n\u001b[1;32m   1026\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidy\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/lines.py\u001b[0m in \u001b[0;36mrecache\u001b[0;34m(self, always)\u001b[0m\n\u001b[1;32m    668\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0malways\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_invalidx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m             \u001b[0mxconv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_xunits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_xorig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxconv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/matplotlib/cbook/__init__.py\u001b[0m in \u001b[0;36m_to_unmasked_float_array\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1315\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'dict_keys'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsoAAAIMCAYAAADsJ4rpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noQwAAAOhDAAAA6EMAAADoQwAAIP/A9FZsiikT1dFAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqQn-Kx6DJzl",
        "colab_type": "text"
      },
      "source": [
        "# nn_tensorflow_graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhiyxCaZDJzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# wj 20190524\n",
        "tf.reset_default_graph()\n",
        "# x_in: (None,3072)\n",
        "x_in=tf.placeholder(tf.float32,[None,3072])\n",
        "# y_in: (None)\n",
        "y_in=tf.placeholder(tf.int32,[None])\n",
        "w=tf.get_variable('w',[x_in.shape[-1],1],initializer=tf.random_normal_initializer(0,1))\n",
        "b=tf.get_variable('b',[1],initializer=tf.constant_initializer(0.0))\n",
        "# y_out: (None,3072)*(3072,1)=(None,1)\n",
        "y_out=tf.matmul(x_in,w)+b\n",
        "py=tf.nn.sigmoid(y_out)\n",
        "# py_reshaped: (None)\n",
        "py_reshaped=tf.reshape(py,[-1])\n",
        "loss=tf.reduce_mean(tf.square(py_reshaped-tf.cast(y_in,tf.float32)))\n",
        "predict=py_reshaped>0.5\n",
        "predict_correct=tf.equal(tf.cast(predict,tf.int32),y_in)\n",
        "accuracy=tf.reduce_mean(tf.cast(predict_correct,tf.float32))\n",
        "\n",
        "with tf.name_scope('train_op'):\n",
        "    train_op=tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
        "    \n",
        "init=tf.global_variables_initializer()\n",
        "\n",
        "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
        "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
        "\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "class_names=[\"airplane\",\"auto\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"];\n",
        "print(time_now())\n",
        "# train_steps=10000\n",
        "# xs=20\n",
        "# min_train_batch_size=1\n",
        "# # train_batch_size= train_data.len*xs//train_steps\n",
        "# train_batch_size=128\n",
        "# train_batch_size= (train_batch_size>train_data.len)and train_data.len or train_batch_size\n",
        "# train_batch_size= (train_batch_size<min_train_batch_size)and min_train_batch_size or train_batch_size\n",
        "# # print('train_batch_size = ',train_batch_size)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGNclu9qDJzo",
        "colab_type": "text"
      },
      "source": [
        "## show_dicts 曲线图"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmMyPJbGDJzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DICT_KEY='dic'\n",
        "FIG_LABEL='label'\n",
        "X_LABEL='x'\n",
        "Y_LABEL='y'\n",
        "\n",
        "def show_dicts(dicts, figsize = (12,9), in_one_figure = True):\n",
        "    if in_one_figure:\n",
        "        plt.figure(figsize=figsize)\n",
        "    index = 0\n",
        "    for d in dicts:          \n",
        "        if not in_one_figure:\n",
        "            index += 1\n",
        "            plt.figure(num=index,figsize=figsize)\n",
        "        plt.plot(d[DICT_KEY].keys(), d[DICT_KEY].values())\n",
        "        if not in_one_figure:\n",
        "            if X_LABEL in d:\n",
        "                plt.xlabel(d[X_LABEL])\n",
        "            if Y_LABEL in d:\n",
        "                plt.ylabel(d[Y_LABEL])\n",
        "    plt.show()\n",
        "\n",
        "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
        "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "def train_1(train_steps, batch_size, \n",
        "            watch_times = 10, test_times = 50, max_not_progress = 3, print_watch = False):\n",
        "    if print_watch :\n",
        "        print('----- Start at %s'%(time_now()))\n",
        "        print('Train steps: %lu, Train batch size: %lu, Test times: %lu' % \n",
        "              (train_steps, batch_size, test_times))\n",
        "    time_begin=monotonic()\n",
        "    loss_dict = dict()\n",
        "    acc_dict = dict()\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for i in range(1, train_steps + 1):\n",
        "            # Train\n",
        "            batch_data, batch_labels = train_data.next_batch(batch_size)            \n",
        "            [loss_val, acc_val, _] = sess.run([loss, accuracy, train_op], feed_dict = {\n",
        "                x_in: batch_data, y_in: batch_labels})\n",
        "            if i % (train_steps // test_times) == 0:\n",
        "                # Test\n",
        "                test_data = CifarData(test_filenames, False)\n",
        "                test_batch_data, test_batch_labels = test_data.next_batch(test_data.len)                \n",
        "                [loss_val, acc_val] = sess.run([loss, accuracy], feed_dict = {\n",
        "                    x_in: test_batch_data, y_in: test_batch_labels})\n",
        "                if i % (train_steps // watch_times) == 0:\n",
        "                    if print_watch :\n",
        "                        print('curr_step: %-6lu, loss_val: %5.4f, acc_val: %5.4f'%(i, loss_val, acc_val))\n",
        "                loss_dict[i] = loss_val\n",
        "                acc_dict[i]  = acc_val\n",
        "    if print_watch :\n",
        "        print('----- End at %s'%(time_now(time_begin)))\n",
        "    time_end = monotonic()\n",
        "    elaps = time_end - time_begin\n",
        "    return loss_dict, acc_dict, elaps\n",
        "\n",
        "def TEST_train_1():\n",
        "    loss_dict, acc_dict, elaps = train_1(train_steps = 5000, batch_size = 20, test_times = 6, watch_times = 2, print_watch = True)\n",
        "    dicts = [dict([(DICT_KEY, loss_dict), (FIG_LABEL, 'loss_fig'), (X_LABEL, 'step'), (Y_LABEL, 'loss')]), \n",
        "           dict([(DICT_KEY, acc_dict),  (FIG_LABEL, 'acc_fig'),  (X_LABEL, 'step'), (Y_LABEL, 'accuracy')])]\n",
        "    show_dicts(dicts = dicts, figsize = (16,5), in_one_figure = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml6nwzIaDJzr",
        "colab_type": "text"
      },
      "source": [
        "## train_and_analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh9qFY7ZDJzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_analysis(train_steps,batch_size,test_times,\n",
        "                       watch_times=10,figsize=(9,12),in_one_figure=True):\n",
        "    \n",
        "    loss_dict, acc_dict, elaps = train_1(train_steps = train_steps, batch_size = batch_size, \n",
        "                                  watch_times = watch_times, test_times = test_times, print_watch = True)\n",
        "    \n",
        "    dicts=[dict([(DICT_KEY, loss_dict), (FIG_LABEL, 'loss_fig'), (X_LABEL, 'step'), (Y_LABEL, 'loss')]), \n",
        "           dict([(DICT_KEY, acc_dict),  (FIG_LABEL, 'acc_fig'),  (X_LABEL, 'step'), (Y_LABEL, 'accuracy')])]\n",
        "    \n",
        "    show_dicts(dicts = dicts, figsize = figsize, in_one_figure = in_one_figure)\n",
        "\n",
        "    return loss_dict,acc_dict\n",
        "\n",
        "# train_steps=100000\n",
        "# batch_size=4\n",
        "# test_times=200\n",
        "# train_and_analysis(train_steps = train_steps, batch_size = batch_size, test_times = test_times)\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "def TEST_train_and_analysis():\n",
        "    for i in range(4,5):\n",
        "        epoch = 1\n",
        "        batch_size = 2 ** i\n",
        "        train_steps = int(epoch * train_data.len / batch_size * (math.log(batch_size) if batch_size > 3 else 1))\n",
        "        test_times = 4\n",
        "        watch_times = 2\n",
        "        loss_dict,acc_dict = train_and_analysis(train_steps = train_steps, batch_size = batch_size, \n",
        "                                                test_times = test_times, watch_times = watch_times,\n",
        "                                                figsize = (16,6), in_one_figure = False)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrHhZBItDJzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#wj\n",
        "def train(train_steps,batch_size,watch_times=10,max_not_progress=3,print_watch=False):\n",
        "    time_begin=monotonic()\n",
        "    watch_period = train_steps//watch_times\n",
        "    accuracy_dict=dict()\n",
        "    not_progress = 0\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        if print_watch :\n",
        "            print('***** Start at %s'%(time_now()))\n",
        "            print('Train steps: %6u \\t Train batch size: %6u' % (train_steps, batch_size))    \n",
        "        for i in range(1,train_steps+1):        \n",
        "            data,labels=train_data.next_batch(batch_size)\n",
        "            loss_val,accuracy_val,_=sess.run([loss,accuracy,train_op],feed_dict={x_in:data,y_in:labels})            \n",
        "            \n",
        "            if i % ((watch_period==0)and 1 or watch_period) ==0 or i==train_steps :    \n",
        "                if print_watch :\n",
        "                    print('Train: No. %5u, accuracy = %4.5f, loss_val = %4.5f' % (i,accuracy_val,loss_val))    \n",
        "                test_data = CifarData(test_filenames, False)\n",
        "                data,labels=test_data.next_batch(test_data.len)\n",
        "                his_max = (0 if (len(accuracy_dict)==0) else max(accuracy_dict.values()))\n",
        "                accuracy_dict[i],_ = sess.run([accuracy,loss],feed_dict={x_in:data, y_in:labels})\n",
        "                if print_watch :\n",
        "                    print('Test:  No. %5u, accuracy = %4.5f ***' % (i,accuracy_dict[i]))    \n",
        "                if accuracy_dict[i] <= his_max:\n",
        "                    not_progress+=1\n",
        "                if max_not_progress != 0 and not_progress >= max_not_progress:\n",
        "                    break\n",
        "    if print_watch :\n",
        "        print('***** End at %s'%(time_now()))\n",
        "    time_end=monotonic()\n",
        "    elaps = time_end - time_begin\n",
        "    return max(accuracy_dict.values()),elaps,accuracy_dict\n",
        "\n",
        "def TEST_train():\n",
        "    print('--------- BEGIN %s---------' % (time_now()))\n",
        "    begin_time = get_timestamp()\n",
        "    for i in range(6,7):\n",
        "        batch_size_para = 2 ** i\n",
        "    #     steps = 100 * 10000\n",
        "        steps = 2000\n",
        "        acc,elaps,accuracy_dict = train(train_steps=steps,batch_size=batch_size_para,watch_times=50,max_not_progress=20,print_watch=False)\n",
        "        print('batch_size=%3d,acc=%4.5f,use_steps=%7d,elaps=%5ds' % (batch_size_para, acc, max(accuracy_dict.keys()), elaps / ((10 ** 9) if LOCATE == 'home' else 1)))\n",
        "    print('---------- END %s----------' % (time_now(begin_time)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQ0v8VHDJzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=[5,1.2,5.2,1.5,4.4,3]\n",
        "a=tf.nn.softmax(x)\n",
        "aa = tf.Session().run(a)\n",
        "print(aa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTUwYpg_DJz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=range(12)\n",
        "print('a.type',type(a))\n",
        "a=list(a)\n",
        "print('a.type',type(a))\n",
        "na=np.array(a)\n",
        "ta=tf.convert_to_tensor(a)\n",
        "print('ta.type',type(ta),ta.shape)\n",
        "ta2=tf.reshape(ta,(-1,1))\n",
        "print('ta2.type',type(ta2),ta2.shape)\n",
        "ta3=tf.reshape(ta2,[-1])\n",
        "print('ta3.type',type(ta3),ta3.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzUvkZnLDJz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=1\n",
        "my_list=['Jie','Kate','Jing']\n",
        "print(my_list,a)\n",
        "def func_20190525(the_list,a):\n",
        "    a=2\n",
        "    the_list[0]='Alan'\n",
        "    print(the_list,a)\n",
        "func_20190525(my_list,a)\n",
        "print(my_list,a)\n",
        "list2=my_list\n",
        "print('list2:',list2)\n",
        "print('my_list:',my_list)\n",
        "list2.append('Alan K. Wen')\n",
        "print('list2:',list2)\n",
        "print('my_list:',my_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwG4JUYpDJz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "a=[[1,2],[2],[3]]\n",
        "b0=a # 赋值\n",
        "b1=a[:] # 浅拷贝\n",
        "b2=deepcopy(a) # 深拷贝\n",
        "print('addr a,b0,b1,b2',[id(x) for x in [a,b0,b1,b2]])\n",
        "print('addr a[i]',[id(x) for x in a])\n",
        "print('addr b0[i]',[id(x) for x in b0])\n",
        "print('addr b1[i]',[id(x) for x in b1])\n",
        "print('addr b2[i]',[id(x) for x in b2])\n",
        "a[0].append(1)\n",
        "'''不可变的对象修改会开辟新的空间，可变的对象修改不会开辟新空间。也进一步证明了浅拷贝仅仅是复制了容器中元素的地址。'''\n",
        "# 　　1. 赋值是将一个对象的地址赋值给一个变量，让变量指向该地址（旧瓶装旧酒）。\n",
        "# 　　2. 浅拷贝是在另一块地址中创建一个新的变量或容器，但是容器内的元素的地址均是源对象的元素的地址的拷贝。也就是说新的容器中指向了旧的元素（新瓶装旧酒）。\n",
        "# 　　3. 深拷贝是在另一块地址中创建一个新的变量或容器，同时容器内的元素的地址也是新开辟的，仅仅是值相同而已，是完全的副本。也就是说（新瓶装新酒）。\n",
        "print('--- After a[0].append(1). ---')\n",
        "print('a:',a)\n",
        "print('b0:',b0)\n",
        "print('b1:',b1)\n",
        "print('b2:',b2)\n",
        "print('addr a[i]',[id(x) for x in a])\n",
        "print('addr b0[i]',[id(x) for x in b0])\n",
        "print('addr b1[i]',[id(x) for x in b1])\n",
        "print('addr b2[i]',[id(x) for x in b2])\n",
        "a[0]=1\n",
        "print('--- After a[0]=1. ---')\n",
        "print('a:',a)\n",
        "print('b0:',b0)\n",
        "print('b1:',b1)\n",
        "print('b2:',b2)\n",
        "print('addr a[i]',[id(x) for x in a])\n",
        "print('addr b0[i]',[id(x) for x in b0])\n",
        "print('addr b1[i]',[id(x) for x in b1])\n",
        "print('addr b2[i]',[id(x) for x in b2])\n",
        "print('\\n',time_now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWlCeVpaDJ0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n----------END---------{time}-------------\\n'.format(time=time_now()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDRJt-51DJ0E",
        "colab_type": "text"
      },
      "source": [
        "# END"
      ]
    }
  ]
}