{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "320.46px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "colab": {
      "name": "neuron_wj2.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpKSotM9DJxo",
        "colab_type": "text"
      },
      "source": [
        "# import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o0I7jDO7DJxs",
        "colab_type": "code",
        "outputId": "7417ad49-737a-49c6-b352-dc429f9c9773",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#20200322使用CoLab\n",
        "#LOCATE = 'home'\n",
        "LOCATE='T490'\n",
        "#IDE = 'JUPYTER'\n",
        "IDE='colab'\n",
        "# IDE = 'VS'\n",
        "\n",
        "import time\n",
        "\n",
        "def monotonic():\n",
        "    if LOCATE=='home':\n",
        "        return time.monotonic_ns()\n",
        "    else:\n",
        "        return time.monotonic()\n",
        "# if IDE == 'JUPYTER':\n",
        "    #代码自动完成\n",
        "    # %config IPCompleter.greedy=True\n",
        "if IDE == 'colab': \n",
        "  %tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import pickle\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import math\n",
        "from matplotlib.pyplot import imshow\n",
        "if IDE == 'JUPYTER' or IDE=='colab':\n",
        "    %matplotlib inline\n",
        "#CIFAR_DIR = \"./../../cifar-10-batches-py\"\n",
        "if LOCATE=='home':\n",
        "  CIFAR_DIR = 'V:\\DATA\\cifar-10-batches-py'\n",
        "else:\n",
        "  CIFAR_DIR = 'd:\\Alan\\data\\cifar-10-batches-py'\n",
        "if IDE=='colab':  \n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  path = \"/content/drive/My Drive\"\n",
        "  os.chdir(path)\n",
        "  # print(os.listdir(path))\n",
        "  CIFAR_DIR=path+'/Alan/Data/cifar-10-batches-py'\n",
        "\n",
        "print(os.listdir(CIFAR_DIR))\n",
        "\n",
        "def time_str(t):\n",
        "    return time.strftime(\"%Y%m%d-%H:%M:%S\", t)\n",
        "\n",
        "def time_now(begin_time=0):    \n",
        "    t=time.localtime()\n",
        "    if begin_time==0:\n",
        "        return time_str(t)\n",
        "    else:\n",
        "        end_time=monotonic()\n",
        "        elaps = end_time - begin_time\n",
        "#         elaps_sec = elaps/10**9 if LOCATE=='home' else elaps\n",
        "        return '%s. Time used: %.3f s.'%(time_str(t), elaps/((10**9) if LOCATE=='home' else 1))\n",
        "\n",
        "def get_timestamp():\n",
        "    return monotonic()\n",
        "    \n",
        "print(time_now())\n",
        "t0=get_timestamp()\n",
        "for i in range(1234567):\n",
        "    i=i\n",
        "print(time_now(t0))\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "['batches.meta', 'readme.html', 'data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5', 'test_batch']\n",
            "20200323-04:14:01\n",
            "20200323-04:14:01. Time used: 0.084 s.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPHm9-t7Dzre",
        "colab_type": "text"
      },
      "source": [
        "#使用免费的GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t6JccGBZD0Hm",
        "colab_type": "code",
        "outputId": "913b1bef-b357-4915-be90-ce318ea0ad5f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "if IDE == 'colab':\n",
        "  #使用免费的 GPU\n",
        "  #在打开的 Jupyter Notebook 中，选择菜单栏“代码执行程序（Runtime）”，“更改运行类型（Change runtime type）”，这时将看到以下弹出窗口：\n",
        "  # 确保“硬件加速器（Hardware accelerator）”设置为 GPU（默认为 CPU）。设置完毕后点击保存。\n",
        "  #但是，由于在线 GPU 资源有限，有时候可能会出现分配失败的提示。并且，谷歌允许你一次最多持续使用 12 小时的免费 GPU。\n",
        "  #检查是否真的开启了 GPU（即当前连接到了GPU实例），可以直接在 Jupyter Notebook 中运行以下命令：\n",
        "  %tensorflow_version 2.x\n",
        "  import tensorflow as tf\n",
        "  try:\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    # print(device_name)\n",
        "    if device_name != '/device:GPU:0':\n",
        "      raise SystemError('GPU device not found')\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "  except SystemError:      \n",
        "      print(SystemError)\n",
        "      print(\"获取gpu_device_name失败！\")\n",
        "      "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QAuiAA2pDJyA",
        "colab_type": "text"
      },
      "source": [
        "# display var"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ST8OskorDJyC",
        "colab_type": "code",
        "outputId": "c82356e4-f31b-4d27-ccd8-c5b9603c2663",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "import inspect\n",
        "import copy\n",
        "def retrieve_name_ex(var,level=0):    \n",
        "    stacks = inspect.stack()    \n",
        "    try:        \n",
        "        callFunc = stacks[level].function        \n",
        "        code = stacks[level+1].code_context[0]        \n",
        "        startIndex = code.index(callFunc)        \n",
        "        startIndex = code.index(\"(\", startIndex + len(callFunc)) + 1        \n",
        "        endIndex = code.index(\")\", startIndex)        \n",
        "        return code[startIndex:endIndex].strip()    \n",
        "    except:        \n",
        "        return \"\"\n",
        "\n",
        "def outputVar(var,level=1,index=-1,end_str='\\n'):               \n",
        "#     print(\"{} [0x{}] = {}\".format(retrieve_name_ex(var,1),var))   \n",
        "    if index==-1:\n",
        "        var_name=retrieve_name_ex(var,level)        \n",
        "    else:\n",
        "        var_name='%s[%d]'%(retrieve_name_ex(var,level),index)\n",
        "    val='{}.'.format(var)\n",
        "    print('%-10s[0x%012lx]=%-15s'%(var_name,id(var),val),end=end_str)\n",
        "    \n",
        "def output_var(var,level=1,index=-1,end_str='\\n'):               \n",
        "    if index==-1:\n",
        "        var_name=retrieve_name_ex(var,level)        \n",
        "    else:\n",
        "        var_name='%s[%d]'%(retrieve_name_ex(var,level),index)\n",
        "    val='{}.'.format(var)\n",
        "    print('%s = %s'%(var_name,val),end=end_str)\n",
        "\n",
        "def getVarName(var,level=1,index=-1):\n",
        "    if index==-1:\n",
        "        var_name=retrieve_name_ex(var,level)        \n",
        "    else:\n",
        "        var_name='%s[%d]'%(retrieve_name_ex(var,level),index)\n",
        "    return var_name\n",
        "\n",
        "def print_var(var,level=1,index=-1):\n",
        "    print(getVarName(var,2),'=',var)\n",
        "    \n",
        "a=[1,2,3]\n",
        "print_var(a)\n",
        "    \n",
        "def output_child(arr):\n",
        "    s=retrieve_name_ex(arr,1)\n",
        "    for i in range(len(arr)):\n",
        "        outputVar(arr[i],2,i,'')\n",
        "    print('\\n',end='')\n",
        "a=[[1,2],[2],[3]]\n",
        "b_sgn=a          # 赋值(相当于C++中的引用)\n",
        "b_spl=a[:]       # 浅拷贝\n",
        "b_dp=copy.deepcopy(a) # 深拷贝\n",
        "outputVar(a)\n",
        "outputVar(b_sgn)\n",
        "outputVar(b_spl)\n",
        "outputVar(b_dp)\n",
        "output_child(a)\n",
        "output_child(b_sgn)\n",
        "output_child(b_spl)\n",
        "output_child(b_dp)\n",
        "a[0].append(3)\n",
        "print('--- After a[0].append(3). ---')\n",
        "outputVar(a)\n",
        "outputVar(b_sgn)\n",
        "outputVar(b_spl)\n",
        "outputVar(b_dp)\n",
        "output_child(a)\n",
        "output_child(b_sgn)\n",
        "output_child(b_spl)\n",
        "output_child(b_dp)\n",
        "\n",
        "a[0]=1\n",
        "print('--- After a[0]=1. ---')\n",
        "outputVar(a)\n",
        "outputVar(b_sgn)\n",
        "outputVar(b_spl)\n",
        "outputVar(b_dp)\n",
        "output_child(a)\n",
        "output_child(b_sgn)\n",
        "output_child(b_spl)\n",
        "output_child(b_dp)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a = [1, 2, 3]\n",
            "a         [0x7f725131ef08]=[[1, 2], [2], [3]].\n",
            "b_sgn     [0x7f725131ef08]=[[1, 2], [2], [3]].\n",
            "b_spl     [0x7f725131ef48]=[[1, 2], [2], [3]].\n",
            "b_dp      [0x7f72513dab48]=[[1, 2], [2], [3]].\n",
            "a[0]      [0x7f725131ed08]=[1, 2].        a[1]      [0x7f725131ed88]=[2].           a[2]      [0x7f7306606748]=[3].           \n",
            "b_sgn[0]  [0x7f725131ed08]=[1, 2].        b_sgn[1]  [0x7f725131ed88]=[2].           b_sgn[2]  [0x7f7306606748]=[3].           \n",
            "b_spl[0]  [0x7f725131ed08]=[1, 2].        b_spl[1]  [0x7f725131ed88]=[2].           b_spl[2]  [0x7f7306606748]=[3].           \n",
            "b_dp[0]   [0x7f725131ee08]=[1, 2].        b_dp[1]   [0x7f725131e048]=[2].           b_dp[2]   [0x7f725131efc8]=[3].           \n",
            "--- After a[0].append(3). ---\n",
            "a         [0x7f725131ef08]=[[1, 2, 3], [2], [3]].\n",
            "b_sgn     [0x7f725131ef08]=[[1, 2, 3], [2], [3]].\n",
            "b_spl     [0x7f725131ef48]=[[1, 2, 3], [2], [3]].\n",
            "b_dp      [0x7f72513dab48]=[[1, 2], [2], [3]].\n",
            "a[0]      [0x7f725131ed08]=[1, 2, 3].     a[1]      [0x7f725131ed88]=[2].           a[2]      [0x7f7306606748]=[3].           \n",
            "b_sgn[0]  [0x7f725131ed08]=[1, 2, 3].     b_sgn[1]  [0x7f725131ed88]=[2].           b_sgn[2]  [0x7f7306606748]=[3].           \n",
            "b_spl[0]  [0x7f725131ed08]=[1, 2, 3].     b_spl[1]  [0x7f725131ed88]=[2].           b_spl[2]  [0x7f7306606748]=[3].           \n",
            "b_dp[0]   [0x7f725131ee08]=[1, 2].        b_dp[1]   [0x7f725131e048]=[2].           b_dp[2]   [0x7f725131efc8]=[3].           \n",
            "--- After a[0]=1. ---\n",
            "a         [0x7f725131ef08]=[1, [2], [3]]. \n",
            "b_sgn     [0x7f725131ef08]=[1, [2], [3]]. \n",
            "b_spl     [0x7f725131ef48]=[[1, 2, 3], [2], [3]].\n",
            "b_dp      [0x7f72513dab48]=[[1, 2], [2], [3]].\n",
            "a[0]      [0x000000a68ac0]=1.             a[1]      [0x7f725131ed88]=[2].           a[2]      [0x7f7306606748]=[3].           \n",
            "b_sgn[0]  [0x000000a68ac0]=1.             b_sgn[1]  [0x7f725131ed88]=[2].           b_sgn[2]  [0x7f7306606748]=[3].           \n",
            "b_spl[0]  [0x7f725131ed08]=[1, 2, 3].     b_spl[1]  [0x7f725131ed88]=[2].           b_spl[2]  [0x7f7306606748]=[3].           \n",
            "b_dp[0]   [0x7f725131ee08]=[1, 2].        b_dp[1]   [0x7f725131e048]=[2].           b_dp[2]   [0x7f725131efc8]=[3].           \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-u9a80QjDJyH",
        "colab_type": "text"
      },
      "source": [
        "$ P(A \\mid B) = \\frac{P(B \\mid A) , P(A)}{P(B)} $\n",
        "\n",
        "$ \\frac 1 2 $\n",
        "$\\vec{x}\\stackrel{\\mathrm{def}}{=} (x_1, ..., x_n)$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4cohITNDJyL",
        "colab_type": "text"
      },
      "source": [
        "## tag_print"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7CMTt9oDJyN",
        "colab_type": "code",
        "outputId": "18339bb0-02bb-4147-956b-a1cb34964d35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "def remove_sufix(s, redundance_flag):\n",
        "    '''去除字符串尾部多余的部分'''\n",
        "    index = s.find(redundance_flag)\n",
        "    if index >= 0:\n",
        "        return s[0:index-1]\n",
        "    else:\n",
        "        return s\n",
        "    \n",
        "def add_match_parentheses(s):\n",
        "    left_pt_cnt=0\n",
        "    right_pt_cnt=0\n",
        "    for c in s:\n",
        "        if c=='(':\n",
        "            left_pt_cnt += 1\n",
        "        elif c==')':\n",
        "            right_pt_cnt += 1\n",
        "    if left_pt_cnt - right_pt_cnt <=0:\n",
        "        return s\n",
        "    for i in range(left_pt_cnt - right_pt_cnt):\n",
        "        s += ')'\n",
        "    return s\n",
        "\n",
        "g_print_flag = False\n",
        "\n",
        "def tag_print(var, memo='', tag='', level_plus=0, display=True, big_list=False):\n",
        "    if display == False:\n",
        "        return\n",
        "    if tag == '':\n",
        "        tag = getVarName(var,level=2+level_plus)\n",
        "        if g_print_flag:\n",
        "            print('getVarName=',tag)\n",
        "        tag = remove_sufix(tag,getVarName(var))\n",
        "        tag = remove_sufix(tag,getVarName(memo))\n",
        "        tag = remove_sufix(tag,getVarName(display))\n",
        "        tag = remove_sufix(tag,getVarName(big_list))\n",
        "        tag = add_match_parentheses(tag)\n",
        "    enter_str_after_var = ''  \n",
        "    shape_str = '{shape}\\t'.format(shape= '-' )\n",
        "    if type(var) == np.ndarray or type(var) == np.matrix:\n",
        "        shape_str = '{shape}\\t'.format(shape=var.shape)        \n",
        "        if(len(var.shape) > 1 and var.shape[0] > 1):\n",
        "            enter_str_after_var = '\\n'  \n",
        "    if memo != '':\n",
        "        memo = '\\n' + memo\n",
        "    type_str = '{type}\\t'.format(type=type(var))\n",
        "      \n",
        "    print('{memo}\\n{type_str}{shape_str}{tag} = {enter}{mat}'.\n",
        "          format(memo=memo,type_str=type_str,shape_str=shape_str,tag=tag,mat=var,type=type(var),enter=enter_str_after_var))\n",
        "    \n",
        "def tp(var, memo='', tag='', level_plus=0, display=True, big_list=False):\n",
        "    tag_print(var=var, memo=memo, tag=tag, level_plus=1, display=display, big_list=big_list)\n",
        "    \n",
        "def tags_print(**vars):\n",
        "    for first_part,second_part in vars.items():\n",
        "        tag_print(tag=first_part,var=second_part)\n",
        "        \n",
        "def tps(**vars):\n",
        "    for first_part,second_part in vars.items():\n",
        "        tag_print(tag=first_part,var=second_part)\n",
        "    \n",
        "z0=0.5\n",
        "tp(z0)\n",
        "tp(np.mat(z0))\n",
        "a=np.array([[1,2,3],[4,5,6]])\n",
        "tp(a)\n",
        "tp(a*a)\n",
        "\n",
        "tp(a.dot(a.T))\n",
        "tp(a.T.dot(a))\n",
        "\n",
        "c=[[1,2],[3,4]]\n",
        "tp(c)\n",
        "mc=np.mat(c)\n",
        "tp(mc)\n",
        "tp(mc**2)\n",
        "b=list(range(10))\n",
        "ma=np.mat(a)\n",
        "tp(np.mat(a))\n",
        "mb=np.mat(b)\n",
        "# c=ma*ma.T\n",
        "tp(ma*ma.T)\n",
        "tp(ma.T*ma)\n",
        "tp(np.array(ma))\n",
        "tags_print(b=b,a=a)\n",
        "\n",
        "# def total(a=5,  **phonebook):\n",
        "# #     print('a', a)\n",
        "#     #遍历元组中的所有项目\n",
        "# #     for single_item in numbers:\n",
        "# #         print('single_item', single_item)\n",
        "#     #遍历字典中的所有项目\n",
        "#     for first_part, second_part in phonebook.items():\n",
        "#         print(first_part,second_part)\n",
        "# print(total(10,Jack=1123,John=2231,Inge=1560))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'float'>\t-\tz0 = 0.5\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tnp.mat(z0) = [[0.5]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\ta = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\ta*a = \n",
            "[[ 1  4  9]\n",
            " [16 25 36]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 2)\ta.dot(a.T) = \n",
            "[[14 32]\n",
            " [32 77]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(3, 3)\ta.T.dot(a) = \n",
            "[[17 22 27]\n",
            " [22 29 36]\n",
            " [27 36 45]]\n",
            "\n",
            "<class 'list'>\t-\tc = [[1, 2], [3, 4]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tmc = \n",
            "[[1 2]\n",
            " [3 4]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tmc**2 = \n",
            "[[ 7 10]\n",
            " [15 22]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 3)\tnp.mat(a) = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tma*ma.T = \n",
            "[[14 32]\n",
            " [32 77]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 3)\tma.T*ma = \n",
            "[[17 22 27]\n",
            " [22 29 36]\n",
            " [27 36 45]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\tnp.array(ma) = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n",
            "\n",
            "<class 'list'>\t-\tb = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\ta = \n",
            "[[1 2 3]\n",
            " [4 5 6]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mvbmHbQWDJyY",
        "colab_type": "text"
      },
      "source": [
        "# class CifarData"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ux8dBekCDJyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_data(filename):\n",
        "    \"\"\"read data from data file.\"\"\"\n",
        "    with open(filename, 'rb') as f:\n",
        "        data = pickle.load(f, encoding='bytes')\n",
        "        return data[b'data'], data[b'labels']\n",
        "\n",
        "# tensorflow.Dataset.\n",
        "class CifarData:\n",
        "    def __init__(self, filenames, need_shuffle):\n",
        "        all_data = []\n",
        "        all_labels = []\n",
        "        for filename in filenames:\n",
        "            data, labels = load_data(filename)\n",
        "            for item, label in zip(data, labels):\n",
        "                if label in [0, 1]:\n",
        "                    all_data.append(item)\n",
        "                    all_labels.append(label)\n",
        "        self._data = np.vstack(all_data)\n",
        "        self.orignal_data = self._data\n",
        "        self._data = self._data / 127.5 - 1\n",
        "        self._labels = np.hstack(all_labels)\n",
        "#         print(\"data.shape:  \",self._data.shape)\n",
        "#         print(\"labels.shape:\",self._labels.shape)\n",
        "        \n",
        "        self._num_examples = self._data.shape[0]\n",
        "        self._need_shuffle = need_shuffle\n",
        "        self._indicator = 0\n",
        "        if self._need_shuffle:\n",
        "            self._shuffle_data()            \n",
        "        self.len=self._num_examples\n",
        "            \n",
        "    def _shuffle_data(self):\n",
        "        # [0,1,2,3,4,5] -> [5,3,2,4,0,1]\n",
        "        p = np.random.permutation(self._num_examples)\n",
        "        self._data = self._data[p]\n",
        "        self._labels = self._labels[p]\n",
        "    \n",
        "    def next_batch(self, batch_size):\n",
        "        \"\"\"return batch_size examples as a batch.\"\"\"\n",
        "        end_indicator = self._indicator + batch_size\n",
        "        if end_indicator > self._num_examples:\n",
        "            if self._need_shuffle:\n",
        "                self._shuffle_data()\n",
        "                self._indicator = 0\n",
        "                end_indicator = batch_size\n",
        "            else:\n",
        "                raise Exception(\"have no more examples\")\n",
        "        if end_indicator > self._num_examples:\n",
        "            raise Exception(\"batch size is larger than all examples\")\n",
        "        batch_data = self._data[self._indicator: end_indicator]\n",
        "        batch_labels = self._labels[self._indicator: end_indicator]\n",
        "        self._indicator = end_indicator\n",
        "        return batch_data, batch_labels    \n",
        "    \n",
        "    def show_img(self,index):\n",
        "        if index>=self.len:\n",
        "            print('索引越界')\n",
        "            return\n",
        "        img=self.orignal_data[index]\n",
        "        img2=img.reshape((3,32,32))\n",
        "        img3=img2.transpose((1,2,0))\n",
        "#         imshow(img3)\n",
        "#         _img_=img.reshape((3,32,32))\n",
        "        plt.imshow(img3)\n",
        "        plt.show()\n",
        "        return    \n",
        "    \n",
        "import os\n",
        "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
        "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
        "\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "class_names=[\"airplane\",\"auto\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"];\n",
        "\n",
        "def TEST_class_CifarData_and_show_img():\n",
        "    for i in range(1):\n",
        "        print('\\nNo. %d: label[%d] %s' % (i, test_data._labels[i], class_names[test_data._labels[i]]))\n",
        "        test_data.show_img(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIbVvKyiDJyn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "64bc19de-a418-4ada-d630-8dac323c5f6f"
      },
      "source": [
        "\n",
        "# print(w)\n",
        "s=np.array([2,3,1])\n",
        "w=dict()\n",
        "for i in range(0,len(s)-1):\n",
        "    a=s[i+1]\n",
        "    b=s[i]\n",
        "    w[i]=np.random.rand(a,b)\n",
        "# print(w)\n",
        "z=dict()\n",
        "z[1]=np.random.rand(2,3)\n",
        "i=1\n",
        "# print('z[{i}]=\\n{zi}'.format(i=i,zi=z[i]))\n",
        "# print('a={a}'.format(a=3))\n",
        "a=np.random.rand(1,3)\n",
        "b=np.random.rand(3,2)\n",
        "c=a.dot(b)\n",
        "tag_print(c)\n",
        "a=list(range(5,0,-1))\n",
        "output_var(a)\n",
        "a[1]=np.zeros(2)\n",
        "output_var(a)\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'numpy.ndarray'>\t(1, 2)\tc = [[1.08639163 0.55711436]]\n",
            "a = [5, 4, 3, 2, 1].\n",
            "a = [5, array([0., 0.]), 3, 2, 1].\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39xTY2WtDJyr",
        "colab_type": "text"
      },
      "source": [
        "# BP"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8PdRVSwDJyt",
        "colab_type": "text"
      },
      "source": [
        "## sigmoid"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Lw_LRFwDJyx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "59c61dcd-d349-4f9d-ae2b-5230905774a8"
      },
      "source": [
        "def sigmoid(x):\n",
        "    y=1/(1+np.exp(-x))\n",
        "    return y\n",
        "\n",
        "def sigmoid_diff(x):\n",
        "    f=sigmoid(x)\n",
        "    diff=f-f*f\n",
        "    return diff\n",
        "\n",
        "x=np.array([[1,2,3]])\n",
        "print(x.shape)\n",
        "print(sigmoid(x))\n",
        "print(sigmoid_diff(x))\n",
        "print(np.transpose(x).shape)\n",
        "print(np.transpose(x))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 3)\n",
            "[[0.73105858 0.88079708 0.95257413]]\n",
            "[[0.19661193 0.10499359 0.04517666]]\n",
            "(3, 1)\n",
            "[[1]\n",
            " [2]\n",
            " [3]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "72lQGT2fDJy9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3ef39c8a-5564-4659-96ef-44d198acae94"
      },
      "source": [
        "d=dict()\n",
        "d[1]=1\n",
        "not(1 in d)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C7gLv1vDJzD",
        "colab_type": "text"
      },
      "source": [
        "## show_fun"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGNiiR3nDJzE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 567
        },
        "outputId": "cd812853-b2ea-428e-e0f5-223bc01b5120"
      },
      "source": [
        "DATA_DICT='data_dict'\n",
        "FIG_LABEL='label'\n",
        "X_LABEL='x'\n",
        "Y_LABEL='y'\n",
        "COLOR='color'\n",
        "\n",
        "    \n",
        "def show_dicts(dicts, figsize = (12,9), in_one_figure = True):\n",
        "    if in_one_figure:\n",
        "        plt.figure(figsize=figsize)\n",
        "    index = 0\n",
        "    plots=[]\n",
        "    plot_tags=[]\n",
        "    for d in dicts:       \n",
        "        if type(d)!=dict or not(DATA_DICT in d) or type(d[DATA_DICT])!=dict or len(d[DATA_DICT].items())==0:\n",
        "            continue\n",
        "        #使用[*dict.keys()]可将dict.keys()转换为list类型，也可直接使用list(dict.keys())进行转换\n",
        "        plt.plot([*(d[DATA_DICT].keys())], [*(d[DATA_DICT].values())],color=d[COLOR],label=d[Y_LABEL])  \n",
        "        \n",
        "        if not in_one_figure:\n",
        "            if X_LABEL in d:\n",
        "                plt.xlabel(d[X_LABEL])\n",
        "            if Y_LABEL in d:\n",
        "                plt.ylabel(d[Y_LABEL])\n",
        "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=0,ncol=3, borderaxespad=0.)\n",
        "\n",
        "def show_dict(d,figsize=(12,9),color='blue',y_label='Y'):\n",
        "    tmp_d=dict()\n",
        "    tmp_d[DATA_DICT]=d\n",
        "    tmp_d[COLOR]=color\n",
        "    tmp_d[Y_LABEL]=y_label\n",
        "    dicts=[0]\n",
        "    dicts[0]=tmp_d\n",
        "    show_dicts(dicts,figsize=figsize)\n",
        "    \n",
        "def draw_axis(x_from,x_to,y_from,y_to):\n",
        "    color='black'\n",
        "    linewidth=0.5    \n",
        "    plt.vlines(0,y_to,y_from,color = color, linewidth = linewidth)\n",
        "    plt.hlines(0,x_from,x_to,color = color, linewidth = linewidth)\n",
        "\n",
        "def init_func_dicts(n):\n",
        "    y=list(range(n))\n",
        "    for i in range(n):\n",
        "        y[i]=dict()\n",
        "        y[i][DATA_DICT]=dict()\n",
        "    return y\n",
        "\n",
        "def TEST_show_fun():\n",
        "    y = init_func_dicts(5)\n",
        "    for x in np.linspace(-0.5,0.999,100):\n",
        "        y[0][DATA_DICT][x] = -np.log(1 - x)\n",
        "    y[0][COLOR] = 'red'\n",
        "    y[0][Y_LABEL] = 'y=-np.log(1-x)'\n",
        "    for x in np.linspace(0.001,1.5,100):\n",
        "        y[1][DATA_DICT][x] = -np.log(x)\n",
        "    y[1][COLOR] = 'blue'\n",
        "    y[1][Y_LABEL] = 'y=-np.log(x)'\n",
        "\n",
        "    show_dicts(y,figsize=(7,4))\n",
        "    aux_color = 'black'\n",
        "    aux_linewidth = 0.5\n",
        "    aux_linestyle = '-.'\n",
        "    draw_axis(-0.5,1.5,-1,7)\n",
        "    plt.vlines(1,-0.5,7,color = aux_color, linewidth = aux_linewidth, linestyle=aux_linestyle)\n",
        "    plt.annotate(\"x=1\",(1,-0.5),xytext=(0.95,-1))\n",
        "    plt.show()\n",
        "\n",
        "    y = init_func_dicts(5)\n",
        "    x_from = -7\n",
        "    x_to = 7\n",
        "    for x in np.linspace(x_from,x_to,1000):\n",
        "        y[0][DATA_DICT][x] = 1 / (1 + np.exp(-x))\n",
        "    y[0][COLOR] = 'green'\n",
        "    y[0][Y_LABEL] = 'sigmoid(x)=1/(1+exp(-x))'\n",
        "    show_dicts([y[0]],figsize=(7,4),in_one_figure=True)\n",
        "    draw_axis(x_from,x_to,-0.5,1.5)\n",
        "    plt.hlines(1,x_from,x_to,color = aux_color, linewidth = aux_linewidth, linestyle=aux_linestyle)\n",
        "    plt.annotate(\"y=1\",(-5,1) ,xytext=(-6.5,0.9))\n",
        "    plt.show()\n",
        "\n",
        "if IDE == 'JUPYTER' or IDE=='colab':\n",
        "    TEST_show_fun()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAETCAYAAABnSkJLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAboAAAETCAYAAABA5MOjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npqATERG/pqATERG/pqATERG/9v8BQO7hrgPiFXsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 504x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb-4szmhDJzK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "c5ee1fb7-c882-4eb5-a90a-23ec4bdf4bee"
      },
      "source": [
        "a=np.array([1,2,3])\n",
        "tp(a*a)\n",
        "b=np.array([[1,2,3],[3,4,5]])\n",
        "# ma_1=np.mat([1,2,3])\n",
        "# tp(ma_1)\n",
        "# tp(ma_1[0,2])\n",
        "# ma=np.mat(a).T\n",
        "# mb=np.mat(b[1]).T\n",
        "# tp(ma)\n",
        "# tp(mb)\n",
        "# tp(ma/mb)\n",
        "\n",
        "# ya = np.mat(b[:,2])\n",
        "# tp(np.mat(b))\n",
        "\n",
        "tp(b)\n",
        "tp(np.mat(b[:,1]))\n",
        "mb=np.mat(b)\n",
        "tp(mb)\n",
        "tp(np.mat(mb[:,1]))\n",
        "# df_dev_dx = np.zeros([2,3])\n",
        "# tp(df_dev_dx)\n",
        "# tp(ma**2)#矩阵乘幂\n",
        "# tp(a)\n",
        "# tp(a*a)\n",
        "# tp(a.T*a)\n",
        "# tp(ma)\n",
        "# tp(np.array(ma))\n",
        "# tp(np.array(ma.tolist()))\n",
        "# c=np.array(ma.tolist())\n",
        "# tp(c)\n",
        "# tp(c*c)\n",
        "# tp(c.T*c)\n",
        "# tp(c*c.T)\n",
        "# tp(c.T.dot(c))\n",
        "# tp(c.dot(c.T))\n",
        "\n",
        "# tp(mb)\n",
        "# tp(np.diag(ma*mb.T))\n",
        "# tp(np.array(ma))\n",
        "# tp(np.array(mb).T)\n",
        "# tp((np.array(ma)*np.array(mb).T))\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'numpy.ndarray'>\t(3,)\ta*a = [1 4 9]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2, 3)\tb = \n",
            "[[1 2 3]\n",
            " [3 4 5]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 2)\tnp.mat(b[:,1]) = [[2 4]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 3)\tmb = \n",
            "[[1 2 3]\n",
            " [3 4 5]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 1)\tnp.mat(mb[:,1]) = \n",
            "[[2]\n",
            " [4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYVoC7odDJzN",
        "colab_type": "text"
      },
      "source": [
        "## 函数求导"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWKNmb7rDJzN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2442d2b0-2a91-4097-c254-1005dbc677cf"
      },
      "source": [
        "\n",
        "# 计算损失函数求导\n",
        "# from sympy import *\n",
        "import sympy as sy\n",
        "\n",
        "def sigmoid_sy(x):\n",
        "    y = 1 / (1 + sy.exp(-x))\n",
        "    return y\n",
        "\n",
        "def sigmoid_diff(x):\n",
        "    f = sigmoid(x)\n",
        "    diff = f - f * f\n",
        "    return diff\n",
        "\n",
        "# def covert_sigle_to_array(x):\n",
        "#     '''将单个数转换成矩阵形式'''\n",
        "#     x = np.array(x)\n",
        "#     if len(x.shape)==0:\n",
        "#         x=np.array([x])\n",
        "#     return x\n",
        "\n",
        "x = sy.symbols(\"x\")  # 符号x，自变量\n",
        "y = x ** 2 + 3 * x\n",
        "dify = sy.diff(y,x) #求导\n",
        "# print(dify) #打印导数#给定x值，求对应导数的值\n",
        "                # print(dify.subs('x',1))\n",
        "z = sy.symbols('z')\n",
        "y = sy.symbols('y')\n",
        "L = sy.symbols('L')\n",
        "\n",
        "L = -y * sy.log(sigmoid_sy(z)) - (1 - y) * (sy.log(1 - sigmoid_sy(z)))\n",
        "dL_python = sy.diff(L,z)\n",
        "\n",
        "tp(L)\n",
        "tp(sy.diff(L,z))\n",
        "\n",
        "# dL_alan=-y*(1-sigmoid(z))+(1-y)*sigmoid(z)\n",
        "\n",
        "z0=0.7\n",
        "y0=1\n",
        "\n",
        "z1 = np.mat([0.7,0.2,0.5]).T\n",
        "y1 = np.mat([1,0,1]).T\n",
        "\n",
        "z2 = np.mat([[0.7,0.2,0.5],[0.6,0.3,0.8]]).T\n",
        "y2 = np.mat([[1,0,1],[1,1,0]]).T\n",
        "\n",
        "tags_print(z0=z0,y0=y0,z1=z1,y1=y1,z2=z2,y2=y2)\n",
        "\n",
        "def multiply_pow(a,n):\n",
        "    a=np.mat(a)\n",
        "    r=1\n",
        "    for i in range(abs(n)):\n",
        "        r = np.multiply(r, a)\n",
        "    if n<0:\n",
        "        r=1/r\n",
        "    return r\n",
        "\n",
        "# tp(multiply_pow([1,2,3],3))\n",
        "    \n",
        "def dLdz_py(y,z):\n",
        "    y=np.mat(y)\n",
        "    z=np.mat(z)\n",
        "    r = np.multiply(-y, np.exp(-z)/(1 + np.exp(-z))) \\\n",
        "        + np.multiply(1-y, \\\n",
        "                       np.exp(-z)/(np.multiply(1 - 1/(1 + np.exp(-z)), \\\n",
        "                                            multiply_pow(1 + np.exp(-z), 2))))\n",
        "#     -y*exp(-z)/(1 + exp(-z)) \\\n",
        "#         + (-y + 1) * \\\n",
        "#             exp(-z) / \\\n",
        "#                 ((1 - 1/(1 + exp(-z))) * (1 + exp(-z))**2)\n",
        "    return r\n",
        "\n",
        "def dLdz_alan(y,z):\n",
        "    y=np.mat(y)\n",
        "    z=np.mat(z)\n",
        "    dldz = np.multiply(-y, 1 - sigmoid(z)) + np.multiply(1 - y, sigmoid(z))\n",
        "    return dldz\n",
        "\n",
        "def Loss(y,z, get_average=False):\n",
        "    y = np.mat(y)\n",
        "    z = np.mat(z)\n",
        "    a = sigmoid(z)    \n",
        "    r = -y.T * (np.log(sigmoid(z))) - (1 - y.T) * (np.log(1 - sigmoid(z)))\n",
        "    if get_average:\n",
        "        r=np.average(r)\n",
        "    return r\n",
        "\n",
        "tag_print(Loss(y0,z0))\n",
        "tag_print(L.subs(y,y0).subs(z,z0))\n",
        "          \n",
        "tag_print(Loss(y1,z1))\n",
        "\n",
        "\n",
        "def dydz(f, x, rate,need_print=False): \n",
        "    '''通过[f(x1)-f(x1+delta)]/delta (delta为微量，一般取 0.0001*x1 或更小)这种近似方式求f在x1处的导数，以验证求导公式'''\n",
        "    \n",
        "    # x是自变量组成的向量或矩阵(一个样本的输入x构成一个列向量；\n",
        "    # 多个样本的输入构成一个矩阵，其中一列表示一个样本的输入)\n",
        "    x = np.mat(x)\n",
        "    f1 = f(x)\n",
        "    if need_print:\n",
        "        tps(x=x,f1=f1)\n",
        "\n",
        "    row = x.shape[0]\n",
        "    col = x.shape[1]\n",
        "    df_dev_dx = np.zeros([row,col])\n",
        "    for j in range(col):# x的每一列代表一个样本的输入，此处按列逐样本计算损失函数对自变量的导数\n",
        "        \n",
        "        # 列向量的每个元素是一个未知数，通过(f2-f1)/(x2-x1)这种方式近似计算f在x1处的导数，\n",
        "        # 一次只能计算f对一个自变量的导数 (因为f是多个自变量的函数，如果多个自变量同时变化，\n",
        "        # 则没法区分出f的变化与具体某个变量的关系)。所以需要逐变量(此处为列向量中的每一行)计算近似导数\n",
        "        for i in range(row):\n",
        "            if need_print:                \n",
        "                print('\\nBefore df_dev_dx.i,j=[{i},{j}]\\n'.format(i=i,j=j))\n",
        "            x1=np.mat(x[:,j]);# 列向量矩阵\n",
        "            if need_print:\n",
        "                tp(x1)\n",
        "            x2 = copy.deepcopy(x1)\n",
        "            if need_print:                                \n",
        "                tp(x2)\n",
        "            x2[i,0] = x2[i, 0] * (1 + rate)\n",
        "            f2 = f(x2, col = j)# x的每一列代表一个样本的输入，此处逐样本计算损失函数，所以只需输入其中一列即可\n",
        "            df = f2[0,0] - f1[j,0]\n",
        "            dx = x2 - x1\n",
        "            if need_print:                                \n",
        "                tps(x2=x2,f2=f2,df=df,dx=dx)\n",
        "            df_dev_dx[i, j] = (df / dx[i,0])\n",
        "            if need_print:                \n",
        "                tps(df_dev_dx=df_dev_dx)                \n",
        "    return np.mat(df_dev_dx)\n",
        "    \n",
        "    \n",
        "def fun_loss(y, need_print=False):        \n",
        "    def loss(z, col=-1):\n",
        "        ya=np.mat(y)\n",
        "        if need_print:\n",
        "            tp(ya,memo='in loss()')\n",
        "        if col>=0:\n",
        "            ya = np.mat(ya[:,col])\n",
        "            if need_print:\n",
        "                tp(ya,memo='in loss() after ya = np.mat(ya[:,col])')\n",
        "        z = np.mat(z)\n",
        "        a = sigmoid(z)   \n",
        "        r = -ya.T * (np.log(a)) - (1 - ya.T) * (np.log(1 - a))\n",
        "        r_diag = np.mat(np.diag(r)).T\n",
        "        return r_diag\n",
        "    return loss\n",
        "\n",
        "rate = 0.000001\n",
        "\n",
        "\n",
        "print('\\n------------- y2 z2 -------------')\n",
        "tp(dLdz_py(y2,z2))\n",
        "tp(dLdz_alan(y2,z2))\n",
        "tp(dydz(fun_loss(y2,need_print=False),z2,rate,need_print=False), tag='dydz(fun_loss(y2),z2,rate)')\n",
        "\n",
        "\n",
        "print('\\n------------- y1 z1 -------------')\n",
        "tp(dLdz_py(y1,z1))\n",
        "tp(dLdz_alan(y1,z1))\n",
        "tp(dLdz_alan(y2[:,1],z2[:,1]), tag='dLdz_alan(y2[:,1]),z2[:,1])')\n",
        "tp(dydz(fun_loss(y1),z1,rate), tag='dydz(fun_loss(y1),z1,rate)')\n",
        "tp(dydz(fun_loss(y2[:,1]),z2[:,1],rate), tag='dydz(fun_loss(y2[:,1]),z2[:,1],rate)')\n",
        "\n",
        "print('\\n------------- y0 z0 -------------')\n",
        "tp(dLdz_py(y0,z0))\n",
        "tp(dLdz_alan(y0,z0))\n",
        "tp(dydz(fun_loss(y0),z0,rate))\n",
        "\n",
        "\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'sympy.core.add.Add'>\t-\tL = -y*log(1/(1 + exp(-z))) - (-y + 1)*log(1 - 1/(1 + exp(-z)))\n",
            "\n",
            "<class 'sympy.core.add.Add'>\t-\tsy.diff(L,z) = -y*exp(-z)/(1 + exp(-z)) + (-y + 1)*exp(-z)/((1 - 1/(1 + exp(-z)))*(1 + exp(-z))**2)\n",
            "\n",
            "<class 'float'>\t-\tz0 = 0.7\n",
            "\n",
            "<class 'int'>\t-\ty0 = 1\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tz1 = \n",
            "[[0.7]\n",
            " [0.2]\n",
            " [0.5]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\ty1 = \n",
            "[[1]\n",
            " [0]\n",
            " [1]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tz2 = \n",
            "[[0.7 0.6]\n",
            " [0.2 0.3]\n",
            " [0.5 0.8]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\ty2 = \n",
            "[[1 1]\n",
            " [0 1]\n",
            " [1 0]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tLoss(y0,z0) = [[0.40318605]]\n",
            "\n",
            "<class 'sympy.core.numbers.Float'>\t-\tL.subs(y,y0) = 0.403186048885458\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tLoss(y1,z1) = [[1.6754019]]\n",
            "\n",
            "------------- y2 z2 -------------\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdLdz_py(y2,z2) = \n",
            "[[-0.33181223 -0.35434369]\n",
            " [ 0.549834   -0.42555748]\n",
            " [-0.37754067  0.68997448]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdLdz_alan(y2,z2) = \n",
            "[[-0.33181223 -0.35434369]\n",
            " [ 0.549834   -0.42555748]\n",
            " [-0.37754067  0.68997448]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdydz(fun_loss(y2),z2,rate) = \n",
            "[[-0.33181215 -0.35434363]\n",
            " [ 0.54983402 -0.42555745]\n",
            " [-0.37754061  0.68997457]]\n",
            "\n",
            "------------- y1 z1 -------------\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdLdz_py(y1,z1) = \n",
            "[[-0.33181223]\n",
            " [ 0.549834  ]\n",
            " [-0.37754067]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdLdz_alan(y1,z1) = \n",
            "[[-0.33181223]\n",
            " [ 0.549834  ]\n",
            " [-0.37754067]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdLdz_alan(y2[:,1]),z2[:,1]) = \n",
            "[[-0.35434369]\n",
            " [-0.42555748]\n",
            " [ 0.68997448]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdydz(fun_loss(y1),z1,rate) = \n",
            "[[-0.33181215]\n",
            " [ 0.54983402]\n",
            " [-0.37754061]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 1)\tdydz(fun_loss(y2[:,1]),z2[:,1],rate) = \n",
            "[[-0.35434363]\n",
            " [-0.42555745]\n",
            " [ 0.68997457]]\n",
            "\n",
            "------------- y0 z0 -------------\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tdLdz_py(y0,z0) = [[-0.33181223]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tdLdz_alan(y0,z0) = [[-0.33181223]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(1, 1)\tdydz(fun_loss(y0)) = [[-0.33181215]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxXRS6j7DJzR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "fa281d96-37fe-4f52-c2de-85e18226940f"
      },
      "source": [
        "a=np.array([[1,2],[3,4]])\n",
        "tag_print(a.dot(a))\n",
        "tag_print(a[1]*a[0])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'numpy.ndarray'>\t(2, 2)\ta.dot(a) = \n",
            "[[ 7 10]\n",
            " [15 22]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(2,)\ta[1]*a[0] = [3 8]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_JBPpFCDJzT",
        "colab_type": "text"
      },
      "source": [
        "## BP反向推导算法"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TQEXpqToDJzU",
        "colab_type": "text"
      },
      "source": [
        "### FP前向推导"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56nS2yNGDJzZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "08ac7ad0-4558-44be-dac2-66e8bea0016c"
      },
      "source": [
        "\n",
        "   \n",
        "def gene_input_data(sample_count, x_size, y_size, x_min=10, x_max=99, y_min=0, y_max=1):\n",
        "    x=np.mat(np.random.randint(x_min,x_max+1,(sample_count,x_size)))\n",
        "    y=np.mat(np.random.randint(y_min,y_max+1,(sample_count,y_size)))\n",
        "    return x,y\n",
        "\n",
        "\n",
        "def gene_rand_w(nn_struct): \n",
        "    w_n=len(nn_struct)-1\n",
        "    weights=list(range(0,w_n))\n",
        "    for i in range(0,w_n):\n",
        "        weights[i]=np.mat(np.random.rand(nn_struct[i+1],nn_struct[i]))\n",
        "    return weights\n",
        "\n",
        "def nn_fp(input_x, n, w, need_print=False):    \n",
        "    z=list(range(0,n))\n",
        "    a=list(range(0,n))\n",
        "    z[0]=copy.deepcopy(input_x)    \n",
        "    a[0]=copy.deepcopy(input_x)\n",
        "    if need_print:\n",
        "        tag_print(z[0])\n",
        "        tag_print(a[0])\n",
        "    for i in range(1,n):\n",
        "        z[i]=w[i-1] * (a[i-1])\n",
        "        a[i]=sigmoid(z[i])        \n",
        "        if need_print:\n",
        "            print('\\n--------- i = {i}---------'.format(i=i))\n",
        "            tag_print(w[i-1],tag='w[{i}]'.format(i=i-1))\n",
        "            tag_print(a[i-1],tag='a[{i}]'.format(i=i-1))\n",
        "            tag_print(z[i],tag='z[{i}]'.format(i=i))\n",
        "            tag_print(a[i],tag='a[{i}]'.format(i=i))\n",
        "    return z,a;\n",
        "\n",
        "def get_data(data,row_from,row_cnt):\n",
        "    return (np.mat(data)[row_from:row_from+row_cnt, :]).T\n",
        "\n",
        "def show_list(the_list):\n",
        "    tag = getVarName(the_list,level=2)\n",
        "    for i in range(len(the_list)):\n",
        "        tp(the_list[i],tag='{tag}[{i}]'.format(tag=tag, i=i))\n",
        "    return\n",
        "\n",
        "sample_count=2\n",
        "x_size=3\n",
        "y_size=2\n",
        "data_x,data_y=gene_input_data(sample_count=sample_count, x_size=x_size, y_size=y_size, x_min=10,x_max=12)\n",
        "tps(data_x=data_x, data_y=data_y)\n",
        "        \n",
        "nn_node_of_layels=np.array([data_x.shape[1],4,2,data_y.shape[0]])\n",
        "nn_layels_count=len(nn_node_of_layels)\n",
        "tp(nn_node_of_layels)\n",
        "\n",
        "sample_from=0\n",
        "sample_cnt=sample_count\n",
        "x_in=get_data(data_x,sample_from,sample_cnt)\n",
        "y_in=get_data(data_y,sample_from,sample_cnt)\n",
        "weights=gene_rand_w(nn_node_of_layels)\n",
        "if False:\n",
        "    show_list(weights)\n",
        "    tps(x_in=x_in,y_in=y_in)\n",
        "z,a=nn_fp(input_x=x_in, n=nn_layels_count, w=weights, need_print=False);\n",
        "if False:\n",
        "    show_list(z)\n",
        "    show_list(a)\n"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'numpy.matrix'>\t(2, 3)\tdata_x = \n",
            "[[12 12 12]\n",
            " [10 10 11]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(2, 2)\tdata_y = \n",
            "[[1 0]\n",
            " [1 1]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(4,)\tnn_node_of_layels = [3 4 2 2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k__X4-0DDJzi",
        "colab_type": "text"
      },
      "source": [
        "### BP算法相关公式\n",
        "\n",
        "为便于书写，下列公式均按照神经网络从1层开始编号，输出层为n层，与程序代码中0至n-1编号略有不同\n",
        "\n",
        "${{\\bf{\\delta }}^{(n)}} = \\frac{{d\\,{\\mathop{\\rm Loss}\\nolimits} }}{{d{{\\bf{z}}^{(n)}}}} =  - {\\bf{y}} \\circ (1 - {\\mathop{\\rm sigmoid}\\nolimits} {{\\bf{z}}^{(n)}}) + (1 - {\\bf{y}}) \\circ {\\mathop{\\rm sigmoid}\\nolimits} {{\\bf{z}}^{(n)}}$\n",
        "\n",
        "${{\\mathbf{\\delta }}^{(i)}}=[f({{\\mathbf{z}}^{(i)}})-{{f}^{2}}({{\\mathbf{z}}^{(i)}})]\\circ {{[{{({{\\mathbf{\\delta }}^{(i+1)}})}^{\\operatorname{T}}}{{\\mathbf{W}}^{(i)}}]}^{\\operatorname{T}}}$\n",
        "\n",
        "$\\frac{\\partial L}{\\partial {{\\mathbf{W}}^{(i)}}}=\\left[ \\begin{matrix}\n",
        "   \\frac{\\partial L}{\\partial w_{11}^{(i)}} & \\cdots  & \\frac{\\partial L}{\\partial w_{1{{s}_{i}}}^{(i)}}  \\\\\n",
        "   \\vdots  & \\ddots  & \\vdots   \\\\\n",
        "   \\frac{\\partial L}{\\partial w_{{{s}_{i+1}}1}^{(i)}} & \\cdots  & \\frac{\\partial L}{\\partial w_{{{s}_{i+1}}{{s}_{i}}}^{(i)}}  \\\\\n",
        "\\end{matrix} \\right]=\\left[ \\begin{matrix}\n",
        "   \\delta _{1}^{(i+1)}a_{1}^{(i)} & \\cdots  & \\delta _{1}^{(i+1)}a_{{{s}_{i}}}^{(i)}  \\\\\n",
        "   \\vdots  & \\ddots  & \\vdots   \\\\\n",
        "   \\delta _{{{s}_{i+1}}}^{(i+1)}a_{1}^{(i)} & \\cdots  & \\delta _{{{s}_{i+1}}}^{(i+1)}a_{{{s}_{i}}}^{(i)}  \\\\\n",
        "\\end{matrix} \\right]={{\\mathbf{\\delta }}^{(i+1)}}{{[{{\\mathbf{a}}^{(i)}}]}^{\\operatorname{T}}}\\in \\mathbb{R}({{s}_{i+1}}\\times 1)(1\\times {{s}_{i}})=\\mathbb{R}({{s}_{i+1}}\\times {{s}_{i}})$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2oi-YWpDJzi",
        "colab_type": "text"
      },
      "source": [
        "### BP算法代码"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvIIhFTHDJzj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "9d047e03-da5f-423d-b5b7-e0502d13c9f7"
      },
      "source": [
        "### 函数\n",
        "tp(dLdz_alan(y2,z2))\n",
        "tp(dydz(fun_loss(y2,need_print=False),z2,rate,need_print=False), tag='dydz(fun_loss(y2),z2,rate)')\n",
        "\n",
        "def nn_bp(y, z, a, w, n, learn_rate, need_print=False):    \n",
        "    delta=list(range(0,n)) # 误差因子\n",
        "    dLdw=list(range(0,n-1))\n",
        "    \n",
        "    delta[n-1]=dLdz_alan(y, z[n-1])\n",
        "    if need_print:\n",
        "        tp(delta[n-1],tag='delta[{i}]'.format(i=n-1))\n",
        "    for i in range(n-2,-1,-1): # 相当于 n-2 至 0\n",
        "        # 计算顺序：误差因子delta(i)、损失函数对权重w(i)的偏导数dLdw、按梯度下降法更新w(i)\n",
        "        \n",
        "        if need_print:  \n",
        "            print('\\n\\n')\n",
        "            tps(i=i)\n",
        "            tp(delta[i+1],tag='delta[{i}]'.format(i=i+1))\n",
        "            tp(w[i],tag='w[{i}]'.format(i=i))            \n",
        "        # 误差因子delta(i)\n",
        "        dz  = sigmoid(z[i]) - multiply_pow(sigmoid(z[i]), 2)\n",
        "        delta_multi_w = delta[i+1].T * w[i] # 注意此处不能先更新w，再使用其来计算误差因子\n",
        "        if need_print:            \n",
        "            tp(dz, tag='dz  = sigmoid(z[i]) - multiply_pow(sigmoid(z[i]), 2)')\n",
        "            tp(delta_multi_w, tag= 'delta[i+1].T * w[i]')\n",
        "        delta[i]= np.multiply(dz, delta_multi_w.T)\n",
        "    \n",
        "        if need_print:            \n",
        "            tp(delta[i], tag='delta[i]= np.multiply(dz, delta_multi_w)')\n",
        "        \n",
        "        # 损失函数对权重w(i)的偏导数dLdw\n",
        "        dLdw[i] = delta[i+1] * a[i].T\n",
        "        \n",
        "        # 按梯度下降法更新w(i)\n",
        "        w[i] = w[i] - learn_rate * dLdw[i]\n",
        "        \n",
        "    return w\n",
        "\n",
        "        \n",
        "\n",
        "\n",
        "def nn_train(data_x, data_y, nn_node_of_layels, train_steps, learn_rate=0.05, display_times=10, need_print=False):\n",
        "    nn_layels_count=len(nn_node_of_layels)\n",
        "    sample_from = 0\n",
        "    sample_cnt = sample_count\n",
        "    x_in=get_data(data_x, sample_from, sample_cnt)\n",
        "    y_in=get_data(data_y, sample_from, sample_cnt)\n",
        "    weights = gene_rand_w(nn_node_of_layels)\n",
        "    if False:\n",
        "        tps(x_in=x_in,y_in=y_in)\n",
        "    step_loss=dict()\n",
        "    z, a = nn_fp(input_x=x_in, n=nn_layels_count, w=weights, need_print=False);\n",
        "    if False:\n",
        "        tp(z[nn_layels_count-1])\n",
        "    step_loss[0] = Loss(y_in, z[nn_layels_count-1], get_average=True)\n",
        "    for step in range(1, train_steps+1):\n",
        "        weights = nn_bp(y=y_in, z=z, a=a, w=weights, n=nn_layels_count, learn_rate=learn_rate, need_print=False)\n",
        "        z, a = nn_fp(input_x=x_in, w=weights, n=nn_layels_count, need_print=False);\n",
        "        loss = Loss(y_in, z[nn_layels_count-1], get_average=True)\n",
        "        step_loss[step] = loss\n",
        "        \n",
        "        if step % (train_steps/display_times)==0:\n",
        "            tp(step_loss[step],tag='step_loss[{i}]'.format(i=step))\n",
        "        \n",
        "        if False:\n",
        "            show_list(z)\n",
        "            show_list(a)\n",
        "    if need_print:\n",
        "        for step in range(len(step_loss)):\n",
        "            tp(step_loss[step],tag='step_loss[{i}]'.format(i=step))\n",
        "    show_dict(step_loss,y_label='Loss')\n",
        "    if need_print:\n",
        "        tp(step_loss[train_steps])\n",
        "    return step_loss\n",
        "\n",
        "\n",
        "sample_count=50\n",
        "x_size=15\n",
        "y_size=2\n",
        "data_x,data_y = gene_input_data(sample_count=sample_count, x_size=x_size, y_size=y_size, x_min=10,x_max=50)\n",
        "# tps(data_x=data_x, data_y=data_y)\n",
        "        \n",
        "nn_node_of_layels=np.array([data_x.shape[1],10,10,10,data_y.shape[1]])\n",
        "tp(nn_node_of_layels)\n",
        "\n",
        "\n",
        "step_loss = nn_train(data_x = data_x, data_y = data_y, nn_node_of_layels = nn_node_of_layels, train_steps = 60, learn_rate = 0.05, need_print=False)\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdLdz_alan(y2,z2) = \n",
            "[[-0.33181223 -0.35434369]\n",
            " [ 0.549834   -0.42555748]\n",
            " [-0.37754067  0.68997448]]\n",
            "\n",
            "<class 'numpy.matrix'>\t(3, 2)\tdydz(fun_loss(y2),z2,rate) = \n",
            "[[-0.33181215 -0.35434363]\n",
            " [ 0.54983402 -0.42555745]\n",
            " [-0.37754061  0.68997457]]\n",
            "\n",
            "<class 'numpy.ndarray'>\t(5,)\tnn_node_of_layels = [15 10 10 10  2]\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[6] = 3.097535905132964\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[12] = 2.0431839670102576\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[18] = 1.3823232482668986\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[24] = 1.3822907265851787\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[30] = 1.3822907255484183\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[36] = 1.382290725548361\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[42] = 1.382290725548361\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[48] = 1.382290725548361\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[54] = 1.3822907255483612\n",
            "\n",
            "<class 'numpy.float64'>\t-\tstep_loss[60] = 1.3822907255483607\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAJECAYAAAASUjxzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzv8PTMbKhFLn7xgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x648 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqQn-Kx6DJzl",
        "colab_type": "text"
      },
      "source": [
        "# nn_tensorflow_graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhiyxCaZDJzm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "acadc7fc-e2be-4811-c8c6-5ffcab4a8f1a"
      },
      "source": [
        "# wj 20190524\n",
        "tf.reset_default_graph()\n",
        "# x_in: (None,3072)\n",
        "x_in=tf.placeholder(tf.float32,[None,3072])\n",
        "# y_in: (None)\n",
        "y_in=tf.placeholder(tf.int32,[None])\n",
        "w=tf.get_variable('w',[x_in.shape[-1],1],initializer=tf.random_normal_initializer(0,1))\n",
        "b=tf.get_variable('b',[1],initializer=tf.constant_initializer(0.0))\n",
        "# y_out: (None,3072)*(3072,1)=(None,1)\n",
        "y_out=tf.matmul(x_in,w)+b\n",
        "py=tf.nn.sigmoid(y_out)\n",
        "# py_reshaped: (None)\n",
        "py_reshaped=tf.reshape(py,[-1])\n",
        "loss=tf.reduce_mean(tf.square(py_reshaped-tf.cast(y_in,tf.float32)))\n",
        "predict=py_reshaped>0.5\n",
        "predict_correct=tf.equal(tf.cast(predict,tf.int32),y_in)\n",
        "accuracy=tf.reduce_mean(tf.cast(predict_correct,tf.float32))\n",
        "\n",
        "with tf.name_scope('train_op'):\n",
        "    train_op=tf.train.AdamOptimizer(1e-3).minimize(loss)\n",
        "    \n",
        "init=tf.global_variables_initializer()\n",
        "\n",
        "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
        "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
        "\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "class_names=[\"airplane\",\"auto\",\"bird\",\"cat\",\"deer\",\"dog\",\"frog\",\"horse\",\"ship\",\"truck\"];\n",
        "print(time_now())\n",
        "# train_steps=10000\n",
        "# xs=20\n",
        "# min_train_batch_size=1\n",
        "# # train_batch_size= train_data.len*xs//train_steps\n",
        "# train_batch_size=128\n",
        "# train_batch_size= (train_batch_size>train_data.len)and train_data.len or train_batch_size\n",
        "# train_batch_size= (train_batch_size<min_train_batch_size)and min_train_batch_size or train_batch_size\n",
        "# # print('train_batch_size = ',train_batch_size)\n",
        "\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-58f42a5b64bd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreset_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# x_in: (None,3072)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mx_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3072\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# y_in: (None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0my_in\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplaceholder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'reset_default_graph'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGNclu9qDJzo",
        "colab_type": "text"
      },
      "source": [
        "## show_dicts 曲线图"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cmMyPJbGDJzp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "DICT_KEY='dic'\n",
        "FIG_LABEL='label'\n",
        "X_LABEL='x'\n",
        "Y_LABEL='y'\n",
        "\n",
        "def show_dicts(dicts, figsize = (12,9), in_one_figure = True):\n",
        "    if in_one_figure:\n",
        "        plt.figure(figsize=figsize)\n",
        "    index = 0\n",
        "    for d in dicts:          \n",
        "        if not in_one_figure:\n",
        "            index += 1\n",
        "            plt.figure(num=index,figsize=figsize)\n",
        "        plt.plot(d[DICT_KEY].keys(), d[DICT_KEY].values())\n",
        "        if not in_one_figure:\n",
        "            if X_LABEL in d:\n",
        "                plt.xlabel(d[X_LABEL])\n",
        "            if Y_LABEL in d:\n",
        "                plt.ylabel(d[Y_LABEL])\n",
        "    plt.show()\n",
        "\n",
        "train_filenames = [os.path.join(CIFAR_DIR, 'data_batch_%d' % i) for i in range(1, 6)]\n",
        "test_filenames = [os.path.join(CIFAR_DIR, 'test_batch')]\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "def train_1(train_steps, batch_size, \n",
        "            watch_times = 10, test_times = 50, max_not_progress = 3, print_watch = False):\n",
        "    if print_watch :\n",
        "        print('----- Start at %s'%(time_now()))\n",
        "        print('Train steps: %lu, Train batch size: %lu, Test times: %lu' % \n",
        "              (train_steps, batch_size, test_times))\n",
        "    time_begin=monotonic()\n",
        "    loss_dict = dict()\n",
        "    acc_dict = dict()\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        for i in range(1, train_steps + 1):\n",
        "            # Train\n",
        "            batch_data, batch_labels = train_data.next_batch(batch_size)            \n",
        "            [loss_val, acc_val, _] = sess.run([loss, accuracy, train_op], feed_dict = {\n",
        "                x_in: batch_data, y_in: batch_labels})\n",
        "            if i % (train_steps // test_times) == 0:\n",
        "                # Test\n",
        "                test_data = CifarData(test_filenames, False)\n",
        "                test_batch_data, test_batch_labels = test_data.next_batch(test_data.len)                \n",
        "                [loss_val, acc_val] = sess.run([loss, accuracy], feed_dict = {\n",
        "                    x_in: test_batch_data, y_in: test_batch_labels})\n",
        "                if i % (train_steps // watch_times) == 0:\n",
        "                    if print_watch :\n",
        "                        print('curr_step: %-6lu, loss_val: %5.4f, acc_val: %5.4f'%(i, loss_val, acc_val))\n",
        "                loss_dict[i] = loss_val\n",
        "                acc_dict[i]  = acc_val\n",
        "    if print_watch :\n",
        "        print('----- End at %s'%(time_now(time_begin)))\n",
        "    time_end = monotonic()\n",
        "    elaps = time_end - time_begin\n",
        "    return loss_dict, acc_dict, elaps\n",
        "\n",
        "def TEST_train_1():\n",
        "    loss_dict, acc_dict, elaps = train_1(train_steps = 5000, batch_size = 20, test_times = 6, watch_times = 2, print_watch = True)\n",
        "    dicts = [dict([(DICT_KEY, loss_dict), (FIG_LABEL, 'loss_fig'), (X_LABEL, 'step'), (Y_LABEL, 'loss')]), \n",
        "           dict([(DICT_KEY, acc_dict),  (FIG_LABEL, 'acc_fig'),  (X_LABEL, 'step'), (Y_LABEL, 'accuracy')])]\n",
        "    show_dicts(dicts = dicts, figsize = (16,5), in_one_figure = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml6nwzIaDJzr",
        "colab_type": "text"
      },
      "source": [
        "## train_and_analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kh9qFY7ZDJzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_and_analysis(train_steps,batch_size,test_times,\n",
        "                       watch_times=10,figsize=(9,12),in_one_figure=True):\n",
        "    \n",
        "    loss_dict, acc_dict, elaps = train_1(train_steps = train_steps, batch_size = batch_size, \n",
        "                                  watch_times = watch_times, test_times = test_times, print_watch = True)\n",
        "    \n",
        "    dicts=[dict([(DICT_KEY, loss_dict), (FIG_LABEL, 'loss_fig'), (X_LABEL, 'step'), (Y_LABEL, 'loss')]), \n",
        "           dict([(DICT_KEY, acc_dict),  (FIG_LABEL, 'acc_fig'),  (X_LABEL, 'step'), (Y_LABEL, 'accuracy')])]\n",
        "    \n",
        "    show_dicts(dicts = dicts, figsize = figsize, in_one_figure = in_one_figure)\n",
        "\n",
        "    return loss_dict,acc_dict\n",
        "\n",
        "# train_steps=100000\n",
        "# batch_size=4\n",
        "# test_times=200\n",
        "# train_and_analysis(train_steps = train_steps, batch_size = batch_size, test_times = test_times)\n",
        "train_data = CifarData(train_filenames, True)\n",
        "test_data = CifarData(test_filenames, False)\n",
        "\n",
        "def TEST_train_and_analysis():\n",
        "    for i in range(4,5):\n",
        "        epoch = 1\n",
        "        batch_size = 2 ** i\n",
        "        train_steps = int(epoch * train_data.len / batch_size * (math.log(batch_size) if batch_size > 3 else 1))\n",
        "        test_times = 4\n",
        "        watch_times = 2\n",
        "        loss_dict,acc_dict = train_and_analysis(train_steps = train_steps, batch_size = batch_size, \n",
        "                                                test_times = test_times, watch_times = watch_times,\n",
        "                                                figsize = (16,6), in_one_figure = False)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZrHhZBItDJzw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#wj\n",
        "def train(train_steps,batch_size,watch_times=10,max_not_progress=3,print_watch=False):\n",
        "    time_begin=monotonic()\n",
        "    watch_period = train_steps//watch_times\n",
        "    accuracy_dict=dict()\n",
        "    not_progress = 0\n",
        "    with tf.Session() as sess:\n",
        "        sess.run(init)\n",
        "        if print_watch :\n",
        "            print('***** Start at %s'%(time_now()))\n",
        "            print('Train steps: %6u \\t Train batch size: %6u' % (train_steps, batch_size))    \n",
        "        for i in range(1,train_steps+1):        \n",
        "            data,labels=train_data.next_batch(batch_size)\n",
        "            loss_val,accuracy_val,_=sess.run([loss,accuracy,train_op],feed_dict={x_in:data,y_in:labels})            \n",
        "            \n",
        "            if i % ((watch_period==0)and 1 or watch_period) ==0 or i==train_steps :    \n",
        "                if print_watch :\n",
        "                    print('Train: No. %5u, accuracy = %4.5f, loss_val = %4.5f' % (i,accuracy_val,loss_val))    \n",
        "                test_data = CifarData(test_filenames, False)\n",
        "                data,labels=test_data.next_batch(test_data.len)\n",
        "                his_max = (0 if (len(accuracy_dict)==0) else max(accuracy_dict.values()))\n",
        "                accuracy_dict[i],_ = sess.run([accuracy,loss],feed_dict={x_in:data, y_in:labels})\n",
        "                if print_watch :\n",
        "                    print('Test:  No. %5u, accuracy = %4.5f ***' % (i,accuracy_dict[i]))    \n",
        "                if accuracy_dict[i] <= his_max:\n",
        "                    not_progress+=1\n",
        "                if max_not_progress != 0 and not_progress >= max_not_progress:\n",
        "                    break\n",
        "    if print_watch :\n",
        "        print('***** End at %s'%(time_now()))\n",
        "    time_end=monotonic()\n",
        "    elaps = time_end - time_begin\n",
        "    return max(accuracy_dict.values()),elaps,accuracy_dict\n",
        "\n",
        "def TEST_train():\n",
        "    print('--------- BEGIN %s---------' % (time_now()))\n",
        "    begin_time = get_timestamp()\n",
        "    for i in range(6,7):\n",
        "        batch_size_para = 2 ** i\n",
        "    #     steps = 100 * 10000\n",
        "        steps = 2000\n",
        "        acc,elaps,accuracy_dict = train(train_steps=steps,batch_size=batch_size_para,watch_times=50,max_not_progress=20,print_watch=False)\n",
        "        print('batch_size=%3d,acc=%4.5f,use_steps=%7d,elaps=%5ds' % (batch_size_para, acc, max(accuracy_dict.keys()), elaps / ((10 ** 9) if LOCATE == 'home' else 1)))\n",
        "    print('---------- END %s----------' % (time_now(begin_time)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYQ0v8VHDJzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x=[5,1.2,5.2,1.5,4.4,3]\n",
        "a=tf.nn.softmax(x)\n",
        "aa = tf.Session().run(a)\n",
        "print(aa)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MTUwYpg_DJz1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=range(12)\n",
        "print('a.type',type(a))\n",
        "a=list(a)\n",
        "print('a.type',type(a))\n",
        "na=np.array(a)\n",
        "ta=tf.convert_to_tensor(a)\n",
        "print('ta.type',type(ta),ta.shape)\n",
        "ta2=tf.reshape(ta,(-1,1))\n",
        "print('ta2.type',type(ta2),ta2.shape)\n",
        "ta3=tf.reshape(ta2,[-1])\n",
        "print('ta3.type',type(ta3),ta3.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mzUvkZnLDJz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a=1\n",
        "my_list=['Jie','Kate','Jing']\n",
        "print(my_list,a)\n",
        "def func_20190525(the_list,a):\n",
        "    a=2\n",
        "    the_list[0]='Alan'\n",
        "    print(the_list,a)\n",
        "func_20190525(my_list,a)\n",
        "print(my_list,a)\n",
        "list2=my_list\n",
        "print('list2:',list2)\n",
        "print('my_list:',my_list)\n",
        "list2.append('Alan K. Wen')\n",
        "print('list2:',list2)\n",
        "print('my_list:',my_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwG4JUYpDJz-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy\n",
        "a=[[1,2],[2],[3]]\n",
        "b0=a # 赋值\n",
        "b1=a[:] # 浅拷贝\n",
        "b2=deepcopy(a) # 深拷贝\n",
        "print('addr a,b0,b1,b2',[id(x) for x in [a,b0,b1,b2]])\n",
        "print('addr a[i]',[id(x) for x in a])\n",
        "print('addr b0[i]',[id(x) for x in b0])\n",
        "print('addr b1[i]',[id(x) for x in b1])\n",
        "print('addr b2[i]',[id(x) for x in b2])\n",
        "a[0].append(1)\n",
        "'''不可变的对象修改会开辟新的空间，可变的对象修改不会开辟新空间。也进一步证明了浅拷贝仅仅是复制了容器中元素的地址。'''\n",
        "# 　　1. 赋值是将一个对象的地址赋值给一个变量，让变量指向该地址（旧瓶装旧酒）。\n",
        "# 　　2. 浅拷贝是在另一块地址中创建一个新的变量或容器，但是容器内的元素的地址均是源对象的元素的地址的拷贝。也就是说新的容器中指向了旧的元素（新瓶装旧酒）。\n",
        "# 　　3. 深拷贝是在另一块地址中创建一个新的变量或容器，同时容器内的元素的地址也是新开辟的，仅仅是值相同而已，是完全的副本。也就是说（新瓶装新酒）。\n",
        "print('--- After a[0].append(1). ---')\n",
        "print('a:',a)\n",
        "print('b0:',b0)\n",
        "print('b1:',b1)\n",
        "print('b2:',b2)\n",
        "print('addr a[i]',[id(x) for x in a])\n",
        "print('addr b0[i]',[id(x) for x in b0])\n",
        "print('addr b1[i]',[id(x) for x in b1])\n",
        "print('addr b2[i]',[id(x) for x in b2])\n",
        "a[0]=1\n",
        "print('--- After a[0]=1. ---')\n",
        "print('a:',a)\n",
        "print('b0:',b0)\n",
        "print('b1:',b1)\n",
        "print('b2:',b2)\n",
        "print('addr a[i]',[id(x) for x in a])\n",
        "print('addr b0[i]',[id(x) for x in b0])\n",
        "print('addr b1[i]',[id(x) for x in b1])\n",
        "print('addr b2[i]',[id(x) for x in b2])\n",
        "print('\\n',time_now())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mWlCeVpaDJ0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('\\n----------END---------{time}-------------\\n'.format(time=time_now()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDRJt-51DJ0E",
        "colab_type": "text"
      },
      "source": [
        "# END"
      ]
    }
  ]
}